<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>Project site of Jelle Smet</title><link href="http://smetj.net/" rel="alternate"></link><link href="None/feeds/all-en.atom.xml" rel="self"></link><id>http://smetj.net/</id><updated>2013-11-17T20:36:00+01:00</updated><entry><title>Submit Elasticsearch metrics to Graphite</title><link href="http://smetj.net/submit-elasticsearch-metrics-to-graphite.html" rel="alternate"></link><updated>2013-11-17T20:36:00+01:00</updated><author><name>smetj</name></author><id>tag:smetj.net,2013-11-17:submit-elasticsearch-metrics-to-graphite.html</id><summary type="html">&lt;p&gt;If you're running an &lt;a class="reference external" href="http://www.elasticsearch.org"&gt;Elasticsearch&lt;/a&gt; cluster you might want to keep track of
the metrics it produces.  In this article I will explain how you can aggregate
the metrics of an Elasticsearch cluster and submit them to Graphite for later
analysis.&lt;/p&gt;
&lt;p&gt;&lt;/p&gt;
&lt;div class="section" id="prerequisites"&gt;
&lt;h2&gt;Prerequisites&lt;/h2&gt;
&lt;p&gt;You need to have following software installed:&lt;/p&gt;
&lt;p&gt;Main software (installable from Pypi)&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;a class="reference external" href="https://github.com/smetj/metricfactory"&gt;Metricfactory&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Additional modules (Install from source)&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;a class="reference external" href="https://github.com/smetj/wishboneModules/tree/master/wb_input_httprequest"&gt;wb_input_httprequest&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="https://github.com/smetj/wishboneModules/tree/master/wb_output_tcp"&gt;wb_output_tcp&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This &lt;a class="reference external" href="https://wishbone.readthedocs.org/en/latest/installation.html"&gt;document&lt;/a&gt; describes how to install the different aspects of Wishbone
and its modules.&lt;/p&gt;
&lt;p&gt;Once installed you should have the &lt;em&gt;metricfactory&lt;/em&gt; executable available.&lt;/p&gt;
&lt;pre class="literal-block"&gt;
$ metricfactory list
&lt;/pre&gt;
&lt;/div&gt;
&lt;div class="section" id="elasticsearch"&gt;
&lt;h2&gt;Elasticsearch&lt;/h2&gt;
&lt;p&gt;Elasticsearch has a HTTP based CRUD API which allows us to poll metrics.
The available metrics resources are:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;a class="reference external" href="http://localhost:9200/_cluster/state"&gt;http://localhost:9200/_cluster/state&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="http://localhost:9200/_stats"&gt;http://localhost:9200/_stats&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Polling these resources returns a JSON formatted document containing metrics
of different Elasticsearch parts.&lt;/p&gt;
&lt;p&gt;The &lt;a class="reference external" href="https://github.com/smetj/wishboneModules/tree/master/wb_input_httprequest"&gt;wb_input_httprequest&lt;/a&gt; module will help us to fetch those metrics into
our metricfactory setup.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="decode-elasticsearch-metrics"&gt;
&lt;h2&gt;Decode Elasticsearch metrics&lt;/h2&gt;
&lt;p&gt;That JSON document with metrics has to be converted into the Metricfactory
&lt;a class="reference external" href="http://wishbone.readthedocs.org/en/latest/router.html#format"&gt;standard metric format&lt;/a&gt;.  Once converted it can be processed by other
metricfactory modules.  In this article we will convert the metrics into a
Graphite format using the &lt;a class="reference external" href="http://wishbone.readthedocs.org/en/latest/modules.html#graphite"&gt;Graphite builtin&lt;/a&gt; module of Wishbone.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="bootstrapfile"&gt;
&lt;h2&gt;Bootstrapfile&lt;/h2&gt;
&lt;p&gt;Metricfactory needs to be invoked with a bootstrap file which defines the
functionality and eventflow of the server:&lt;/p&gt;
&lt;table class="highlighttable"&gt;&lt;tr&gt;&lt;td class="linenos"&gt;&lt;div class="linenodiv"&gt;&lt;pre&gt; 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45&lt;/pre&gt;&lt;/div&gt;&lt;/td&gt;&lt;td class="code"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;---
modules:
  httprequest_one:
    module: wishbone.input.httprequest
    arguments:
      url: &amp;quot;http://elasticsearch-001:9200/_cluster/nodes/stats&amp;quot;
      interval: 1

  httprequest_two:
    module: wishbone.input.httprequest
    arguments:
      url: &amp;quot;http://elasticsearch-001:9200/_stats&amp;quot;
      interval: 1

  funnel:
    module: wishbone.builtin.flow.funnel

  decode:
    module: metricfactory.decoder.elasticsearch
    arguments:
      source: lhi

  encode:
    module: wishbone.builtin.metrics.graphite
    arguments:
      prefix: application.elasticsearch.
      script: false

  output_screen:
    module: wishbone.builtin.output.stdout

  output_tcp:
    module: wishbone.output.tcp
    arguments:
      host: graphite-001
      port: 2013

routingtable:
  - httprequest_one.outbox  -&amp;gt; funnel.one
  - httprequest_two.outbox  -&amp;gt; funnel.two
  - funnel.outbox           -&amp;gt; decode.inbox
  - decode.outbox           -&amp;gt; encode.inbox
  - encode.outbox           -&amp;gt; output_tcp.inbox
  #- encode.outbox           -&amp;gt; output_screen.inbox
...
&lt;/pre&gt;&lt;/div&gt;
&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;p&gt;Lets run over the different sections of this bootstrap file.&lt;/p&gt;
&lt;p&gt;The routingtable (line 38) determines how modules are connected to each other
and therefor determine the flow of events.&lt;/p&gt;
&lt;p&gt;The &lt;em&gt;httprequest_one&lt;/em&gt; and &lt;em&gt;httprequest_two&lt;/em&gt; instances poll the urls (line 6,
12) which return the required metrics.  The pages are requested with an
interval of 1 second (line 7, 13).&lt;/p&gt;
&lt;p&gt;The results from both these input modules go over the &lt;em&gt;funnel&lt;/em&gt; module (line
15) to the &lt;em&gt;decode&lt;/em&gt; module instance (line 18), where the ES format is
converted to the generic metric format.  The &lt;em&gt;decode&lt;/em&gt; instance is initialized
using the source argument (line 21) which fills the source value of the
generic metric data format.  This requirement wouldn't be necessary if this
&lt;a class="reference external" href="https://github.com/elasticsearch/elasticsearch/issues/4179"&gt;enhancement request&lt;/a&gt; is done.&lt;/p&gt;
&lt;p&gt;The decoded events are then converted into the required Graphite format by the
&lt;em&gt;encode&lt;/em&gt;  module instance (line 23).  This module is initiated with a prefix
argument which puts a prefix (line 26) in front of the metric name.&lt;/p&gt;
&lt;p&gt;Events then go to the output_tcp module which submits the metrics into
Graphite itself.&lt;/p&gt;
&lt;p&gt;If you want to play around with the metric name formatting, you can write the
metrics to STDOUT first by altering the metric stream to the &lt;em&gt;output_screen&lt;/em&gt;
modules instance by uncommenting line 44 and commenting line 43.&lt;/p&gt;
&lt;p&gt;To start the server, save the above bootstrap configuration to a file and
execute following command:&lt;/p&gt;
&lt;blockquote&gt;
$ metricfactory debug --config bootstrap.yaml&lt;/blockquote&gt;
&lt;/div&gt;
</summary><category term="monitoringlove"></category><category term="graphite"></category><category term="metricfactory"></category><category term="metrics"></category><category term="elasticsearch"></category></entry><entry><title>Anything to MQTT</title><link href="http://smetj.net/anything-to-mqtt.html" rel="alternate"></link><updated>2013-11-08T23:00:00+01:00</updated><author><name>smetj</name></author><id>tag:smetj.net,2013-11-08:anything-to-mqtt.html</id><summary type="html">&lt;p&gt;In this blog post I would like to demonstrate the how easy it is to setup a
Wishbone server which allows you to send data from bash to a MQTT broker.&lt;/p&gt;
&lt;p&gt;&lt;/p&gt;
&lt;p&gt;To install Wishbone you can follow the instructions found in the project
&lt;a class="reference external" href="http://wishbone.readthedocs.org/en/latest/installation.html"&gt;documentation&lt;/a&gt;.&lt;/p&gt;
&lt;div class="section" id="our-setup"&gt;
&lt;h2&gt;Our setup&lt;/h2&gt;
&lt;p&gt;Have a server up and running with following properties:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Listens on 3 different named pipes.&lt;/li&gt;
&lt;li&gt;Each named pipe has a certain routing key associated with it.&lt;/li&gt;
&lt;li&gt;Data submitted into the named pipe is routed to a MQTT broker using the
routing key associated with the named pipe.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The following bootstrap file starts a server with those properties:&lt;/p&gt;
&lt;table class="highlighttable"&gt;&lt;tr&gt;&lt;td class="linenos"&gt;&lt;div class="linenodiv"&gt;&lt;pre&gt; 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59&lt;/pre&gt;&lt;/div&gt;&lt;/td&gt;&lt;td class="code"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;  ---
  modules:
      input_red:
          module: wishbone.input.namedpipe
          arguments:
              path: /tmp/wishbone_red

      input_green:
          module: wishbone.input.namedpipe
          arguments:
              path: /tmp/wishbone_green

      input_blue:
          module: wishbone.input.namedpipe
          arguments:
              path: /tmp/wishbone_blue

      header_red:
          module: wishbone.builtin.function.header
          arguments:
              key: mqtt
              header:
                  topic: color/red

      header_green:
          module: wishbone.builtin.function.header
          arguments:
              key: mqtt
              header:
                  topic: color/green

      header_blue:
          module: wishbone.builtin.function.header
          arguments:
              key: mqtt
              header:
                  topic: color/blue

      funnel:
          module: wishbone.builtin.flow.funnel

      mqtt:
          module: wishbone.output.mqtt
          arguments:
              host: rabbitmq

  routingtable:

      - input_red.outbox        -&amp;gt; header_red.inbox
      - header_red.outbox       -&amp;gt; funnel.one

      - input_green.outbox      -&amp;gt; header_green.inbox
      - header_green.outbox     -&amp;gt; funnel.two

      - input_blue.outbox       -&amp;gt; header_blue.inbox
      - header_blue.outbox      -&amp;gt; funnel.three

      - funnel.outbox           -&amp;gt; mqtt.inbox
  ...
&lt;/pre&gt;&lt;/div&gt;
&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;div class="section" id="breakdown"&gt;
&lt;h3&gt;Breakdown&lt;/h3&gt;
&lt;p&gt;Let's break down the different parts of this bootstrap file and start with the
modules section:&lt;/p&gt;
&lt;p&gt;The named pipes are created by initializing 3 instances of the
&lt;em&gt;wishbone.input.namedpipe&lt;/em&gt; module (line 4, 9, 14).  Each instance is assigned
a name: input_red, input_green and input_blue respectively (line 3, 8, 13).
The only argument defined for these instances is the path of the named pipe
(line 6, 11, 16)&lt;/p&gt;
&lt;p&gt;For each event submitted to the named pipe, we have to add the routing key to
the header of the event.  This is required at a later stage when the event
enters the &lt;em&gt;mqtt&lt;/em&gt; module. 3 instances of the header module are initiated named
header_red, header_green, header_blue respectively (line 18, 25, 32).
Depending on through which header module instance an event travels the
information is stored under a key called &lt;em&gt;mqtt&lt;/em&gt; (line 21, 28, 35).  Each of
these values contain a one element dictionary with the topic name (line 23,
30, 37) using the format the &lt;em&gt;mqtt&lt;/em&gt; module expects.&lt;/p&gt;
&lt;p&gt;In Wishbone you cannot connect multiple queues to 1 queue.  This is by design.
Queues always have a &amp;quot;one to one&amp;quot; relationship.  Since all data submitted to
the 3 named pipes has to go to 1 MQTT, we could in theory have 3 dedicated
mqtt module instances but that would be a waste.  Therefor we initialize the
&lt;em&gt;funnel&lt;/em&gt; module.  The &lt;em&gt;funnel&lt;/em&gt; module allows multiple input queues and merges
those input queues into its output queue, which allows us to only having to
define 1 output module.&lt;/p&gt;
&lt;p&gt;Finally we have the MQTT output module which is initialized using the name
&lt;em&gt;mqtt&lt;/em&gt; (line 42).  The &lt;em&gt;mqtt&lt;/em&gt; submits incoming events towards an MQTT server.
The only argument we require to initialize the module is the hostname or
address of the server (line 45).  The mqtt output module expects for each
incoming event some data in the header of the event, so it knows which routing
key to use when submitting the event.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="the-routing-table"&gt;
&lt;h3&gt;The routing table&lt;/h3&gt;
&lt;p&gt;The routing table (line 47) defines which queues are connected towards each
other which basically defines the flow of events throughout the different
modules.  If we would graphically represent the defines routing table it would
look like this:&lt;/p&gt;
&lt;p&gt;&lt;a class="reference external" href="pics/anything-to-mqtt/diagram.png"&gt;&lt;img alt="diagram" src="pics/anything-to-mqtt/diagram.png" /&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Each &lt;em&gt;named pipe&lt;/em&gt; module instance is connected to its dedicated &lt;em&gt;header&lt;/em&gt;
module instance.  Each &lt;em&gt;header&lt;/em&gt; module instance is connected to the &lt;em&gt;funnel&lt;/em&gt;
module instance.  The names of the incoming queues of the funnel can be chosen
freely (line 50, 53, 56).  The moment a connection is made, the queue is
automatically created.&lt;/p&gt;
&lt;p&gt;The output of the &lt;em&gt;funnel&lt;/em&gt; module instance is then connected to the &lt;em&gt;mqtt&lt;/em&gt;
module instance, which submits the incoming events to the outside world (line
58).&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="running-the-setup"&gt;
&lt;h2&gt;Running the setup&lt;/h2&gt;
&lt;p&gt;Save the above bootstrap to a file.  The start the Wishbone setup in the
foreground using the bootstrap file by executing:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
$ wishbone debug --config anything_to_mqtt.yaml
&lt;/pre&gt;
&lt;p&gt;From CLI we can now submit data into the MQTT server by writing to one of the
named pipes:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
$  echo &amp;quot;ho ho ho, santa is here&amp;quot; &amp;gt; /tmp/wishbone_red
&lt;/pre&gt;
&lt;/div&gt;
&lt;div class="section" id="final-thoughts"&gt;
&lt;h2&gt;Final thoughts&lt;/h2&gt;
&lt;p&gt;While this setup as such does not have much practical use, I hope to have
demonstrated flexibility of the Wishbone framework and what kind of solutions
can be built with it.  More input (and other) modules are available on
&lt;a class="reference external" href="https://github.com/smetj/wishboneModules"&gt;Github&lt;/a&gt; offering more combinations and possibilities which might suit your
specific needs.&lt;/p&gt;
&lt;/div&gt;
</summary><category term="wishbone"></category><category term="mqtt"></category><category term="python"></category></entry><entry><title>Submit Nagios metrics to Graphite with ModGearman and MetricFactory revisited</title><link href="http://smetj.net/submit-nagios-metrics-to-graphite-with-modgearman-and-metricfactory-revisited.html" rel="alternate"></link><updated>2013-11-07T23:00:00+01:00</updated><author><name>smetj</name></author><id>tag:smetj.net,2013-11-07:submit-nagios-metrics-to-graphite-with-modgearman-and-metricfactory-revisited.html</id><summary type="html">&lt;p&gt;When it comes down to monitoring Nagios is still the weapon of choice for
many. &amp;nbsp;I would have abandoned it if there weren't projects like &lt;a class="reference external" href="http://mathias-kettner.de/checkmk_livestatus.html"&gt;Livestatus&lt;/a&gt;,
&lt;a class="reference external" href="http://labs.consol.de/lang/en/nagios/mod-gearman/"&gt;Mod_Gearman&lt;/a&gt;&amp;nbsp;and&amp;nbsp;&lt;a class="reference external" href="http://www.thruk.org/"&gt;Thruk&lt;/a&gt;&amp;nbsp;which to my opinion should never be missing from
any Nagios setup.  Mod_Gearman, the framework which makes Nagios scalable, has
a feature which stores the performance data produced by the Nagios plugins
into a &lt;a class="reference external" href="http://gearman.org/"&gt;Gearman&lt;/a&gt;&amp;nbsp;queue. &amp;nbsp;Graphing that performance data with &lt;a class="reference external" href="http://graphite.wikidot.com/"&gt;Graphite&lt;/a&gt; is a
straightforward job with &lt;a class="reference external" href="https://github.com/smetj/metricfactory"&gt;Metricfactory&lt;/a&gt;.&lt;/p&gt;
&lt;div class="section" id="performance-data"&gt;
&lt;h2&gt;Performance data&lt;/h2&gt;
&lt;p&gt;Mod_Gearman is a Nagios addon which spreads the Nagios plugin execution over a
farm of worker nodes. &amp;nbsp;This allows you to build a scalable Nagios setup quite
effectively. &amp;nbsp;The workers execute the Nagios plugins and submit the produced
results back into the Gearman master server. &amp;nbsp;A Nagios broker module then
consumes the submitted check results from the Gearman master and submits the
check results into Nagios for further processing. &amp;nbsp;The broker module can
optionally submit the &lt;a class="reference external" href="http://nagios.sourceforge.net/docs/3_0/perfdata.html"&gt;performance data&lt;/a&gt;&amp;nbsp;back into a dedicated Gearman queue
ready to be consumed by an external process which in our case is going to be
Metricfactory. &amp;nbsp;Metricfactory will convert the performance data into the
proper format and submit that into Graphite.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="mod-gearman"&gt;
&lt;h2&gt;Mod_Gearman&lt;/h2&gt;
&lt;p&gt;The Mod_Gearman project has quite extensive &lt;a class="reference external" href="http://labs.consol.de/lang/en/nagios/mod-gearman/"&gt;documentation
available&lt;/a&gt;&amp;nbsp;but these are the relevant parameters:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
perfdata=yes
&lt;/pre&gt;
&lt;p&gt;Setting the value to &lt;em&gt;yes&lt;/em&gt; makes the broker module write the
performance data to the&amp;nbsp;&lt;em&gt;perfdata&lt;/em&gt; queue.&lt;/p&gt;
&lt;pre class="literal-block"&gt;
perfdata_mode=1
&lt;/pre&gt;
&lt;p&gt;Setting the value to&amp;nbsp;&lt;em&gt;1&lt;/em&gt; makes sure that performance data doesn't pile up
endlessly in the queue when Metricfactory isn't consuming. &amp;nbsp;It's basically a
precaution which prevents the queue to fill up to a point all available system
memory is consumed. &amp;nbsp;Setting the value to&amp;nbsp;&lt;em&gt;2&lt;/em&gt; will append all performance
data to the queue without overwriting old data. &amp;nbsp;When enabled you can execute
the&amp;nbsp;&lt;em&gt;gearman_top&lt;/em&gt; command and you should see the&amp;nbsp;&lt;em&gt;perfdata&lt;/em&gt; queue appear:&lt;/p&gt;
&lt;p&gt;&lt;a class="reference external" href="../pics/submit-nagios-metrics-to-graphite-with-modgearman-and-metricfactory/gearman_top.png"&gt;&lt;img alt="gearman_top" src="../pics/submit-nagios-metrics-to-graphite-with-modgearman-and-metricfactory/gearman_top.png" /&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;The Jobs Waiting column indicates how many performance data is currently
stored in the queue. &amp;nbsp;Ideally this should be 0 or as low as possible and never
grow otherwise that might indicate the performance data is not consumed fast
enough. Keep in mind that not all Nagios plugins produce performance data. &amp;nbsp;If
you want to be sure whether a plugin produces performance data, have a look in
Thruk (or other Nagios interface) and verify in the service or host details
whether &lt;em&gt;Performance Data&lt;/em&gt; actually contains valid perfdata.&lt;/p&gt;
&lt;p&gt;&lt;a class="reference external" href="../pics/submit-nagios-metrics-to-graphite-with-modgearman-and-metricfactory/perfdata.png"&gt;&lt;img alt="perfdata" src="../pics/submit-nagios-metrics-to-graphite-with-modgearman-and-metricfactory/perfdata.png" /&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="metricfactory"&gt;
&lt;h2&gt;Metricfactory&lt;/h2&gt;
&lt;div class="section" id="installation"&gt;
&lt;h3&gt;Installation&lt;/h3&gt;
&lt;p&gt;You can install Metricfactory and its dependencies from Pypi using
&lt;em&gt;easy_install&lt;/em&gt;:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
$ easy_install metricfactory
&lt;/pre&gt;
&lt;p&gt;You will require some extra Wishbone modules which can not be installed as
separate Pypi packages yet. Checkout the repository from &lt;a class="reference external" href="https://github.com/smetj/metricfactory"&gt;Github&lt;/a&gt; and install
the module manually.&lt;/p&gt;
&lt;pre class="literal-block"&gt;
$ git checkout https://github.com/smetj/wishboneModules.git
&lt;/pre&gt;
&lt;p&gt;Install wb_input_gearmand&lt;/p&gt;
&lt;pre class="literal-block"&gt;
$ cd wishboneModules/wb_input_gearmand
$ python setup.py install
&lt;/pre&gt;
&lt;p&gt;Install wb_output_tcp&lt;/p&gt;
&lt;pre class="literal-block"&gt;
$ cd wishboneModules/wb_output_tcp
$ python setup.py install
&lt;/pre&gt;
&lt;/div&gt;
&lt;div class="section" id="quick-introduction"&gt;
&lt;h3&gt;Quick introduction&lt;/h3&gt;
&lt;p&gt;Metricfactory makes use of Wishbone to build an pipeline of modules through
which events travel and change.  The setup of the Metricfactory server is
described in a bootstrapfile.  A bootstrap file contains which modules to
initialize and which path data has to follow througout these modules.&lt;/p&gt;
&lt;p&gt;The idea behind a MetricFactory server is that it accepts metrics, converts
them into a common format, which on its turn can be processed and/or converted
again into another format.&lt;/p&gt;
&lt;p&gt;We will gradually build up our solution by going through each step.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="consume-perfdata"&gt;
&lt;h3&gt;Consume perfdata&lt;/h3&gt;
&lt;p&gt;First let's have a look how the perfdata looks
like when consuming it without modifications:&lt;/p&gt;
&lt;table class="highlighttable"&gt;&lt;tr&gt;&lt;td class="linenos"&gt;&lt;div class="linenodiv"&gt;&lt;pre&gt; 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29&lt;/pre&gt;&lt;/div&gt;&lt;/td&gt;&lt;td class="code"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;---
modules:
    gearmand:
        module: wishbone.input.gearman
        arguments:
            hostlist:
                - server-001
            secret: changemechangeme
            queue: perfdata
            workers: 5

    decode:
        module: metricfactory.decoder.modgearman

    encode:
        module: wishbone.builtin.metrics.graphite
        arguments:
            prefix: nagios.
            script: false

    stdout:
        module: wishbone.builtin.output.stdout

routingtable:

    - gearmand.outbox   -&amp;gt; stdout.inbox
    # - decode.outbox     -&amp;gt; encode.inbox
    # - encode.outbox     -&amp;gt; stdout.inbox
...
&lt;/pre&gt;&lt;/div&gt;
&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;p&gt;Depending on your environment you will have to adapt some of the variables in
the boostrap file. The &lt;em&gt;hostlist&lt;/em&gt; variable (line 6) is a list of the
Gearmand servers from which the&amp;nbsp;&lt;em&gt;perfdata&lt;/em&gt;&amp;nbsp; has to be consumed. &amp;nbsp;Usually this
is a list containing just 1 server. &amp;nbsp;In some special cases you might add more
servers here but that's in our case not likely.&lt;/p&gt;
&lt;p&gt;The secret variable (line 8) should contain the pre-shared encryption key
allowing you to decrypt the information consumed from Gearmand. &amp;nbsp;Worth to
mention there is no authentication, but without the decryption key you wont be
able to read the data coming from the Gearmand server.&lt;/p&gt;
&lt;p&gt;The number of workers variable (line 10) determines how many workers should
consume the&amp;nbsp;&lt;em&gt;perfdata&lt;/em&gt; queue. &amp;nbsp;If you notice perdata isn't consumed fast
enough, you could bump this number to a higher value. &amp;nbsp;In this case keep an
eye on the the CPU usage of Metricfactory due to the decrypting. If you notice
Metricfactory can't keep up because of high cpu usage then another strategy
might be to leave this numer on 1 and start Metricfactory with the
&lt;em&gt;--instances x&lt;/em&gt; parameter, where x is the number of parallel processes.&lt;/p&gt;
&lt;p&gt;In this example we have connected the &lt;em&gt;gearmand.output&lt;/em&gt; queue to the
&lt;em&gt;stdout.inbox&lt;/em&gt; (line 26).  As a result, the perfdata will flow from the
gearmand module directly to the stdout module.&lt;/p&gt;
&lt;p&gt;Start metricfactory in the foreground and verify whether you get the expected
output:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
$ metricfactory debug --config modgearmand2graphite.yaml
DATATYPE::HOSTPERFDATA  TIMET::1383777750 HOSTNAME::aaaaaaaaaaaaa HOSTPERFDATA::rta=15.589ms;3000.000;5000.000;0; pl=0%;80;100;;  HOSTCHECKCOMMAND::check:host.alive!(null) HOSTSTATE::0  HOSTSTATETYPE::1
DATATYPE::HOSTPERFDATA  TIMET::1383777750 HOSTNAME::bbbbbbbbbbbbb HOSTPERFDATA::rta=16.776ms;3000.000;5000.000;0; pl=0%;80;100;;  HOSTCHECKCOMMAND::check:host.alive!(null) HOSTSTATE::0  HOSTSTATETYPE::1
DATATYPE::HOSTPERFDATA  TIMET::1383777750 HOSTNAME::ccccccccccccc HOSTPERFDATA::rta=16.559ms;3000.000;5000.000;0; pl=0%;80;100;;  HOSTCHECKCOMMAND::check:host.alive!(null) HOSTSTATE::0  HOSTSTATETYPE::1
DATATYPE::HOSTPERFDATA  TIMET::1383777750 HOSTNAME::ddddddddddddd HOSTPERFDATA::rta=16.381ms;3000.000;5000.000;0; pl=0%;80;100;;  HOSTCHECKCOMMAND::check:host.alive!(null) HOSTSTATE::0  HOSTSTATETYPE::1
...snip...
&lt;/pre&gt;
&lt;/div&gt;
&lt;div class="section" id="decode-nagios-format-into-generic-format"&gt;
&lt;h3&gt;Decode Nagios format into generic format&lt;/h3&gt;
&lt;p&gt;The next step is to decode the perfdata into a common format.&lt;/p&gt;
&lt;table class="highlighttable"&gt;&lt;tr&gt;&lt;td class="linenos"&gt;&lt;div class="linenodiv"&gt;&lt;pre&gt; 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29&lt;/pre&gt;&lt;/div&gt;&lt;/td&gt;&lt;td class="code"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;---
modules:
    gearmand:
        module: wishbone.input.gearman
        arguments:
            hostlist:
                - server-001
            secret: changemechangeme
            queue: perfdata
            workers: 5

    decode:
        module: metricfactory.decoder.modgearman

    encode:
        module: wishbone.builtin.metrics.graphite
        arguments:
            prefix: nagios.
            script: false

    stdout:
        module: wishbone.builtin.output.stdout

routingtable:

    - gearmand.outbox   -&amp;gt; decode.inbox
    - decode.outbox     -&amp;gt; stdout.inbox
    # - encode.outbox     -&amp;gt; stdout.inbox
...
&lt;/pre&gt;&lt;/div&gt;
&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;p&gt;We have already defined the correct modules, so it's only a matter of changing
the data flow (line 26, 27).&lt;/p&gt;
&lt;pre class="literal-block"&gt;
$ metricfactory debug --config modgearmand2graphite.yaml
('1383778474', 'nagios', 'aaaaaaaaaaaaa', 'hostcheck.rta', '0.000', 'ms', ('check:host.alive', 'hostcheck'))
('1383778474', 'nagios', 'bbbbbbbbbbbbb', 'hostcheck.pl', '100', '%', ('check:host.alive', 'hostcheck'))
...snip...
&lt;/pre&gt;
&lt;/div&gt;
&lt;div class="section" id="encode-generic-format-to-graphite-format"&gt;
&lt;h3&gt;Encode generic format to Graphite format&lt;/h3&gt;
&lt;p&gt;The next step is to convert the generic format into Graphite format.  That
what the &lt;em&gt;wishbone.builtin.metrics.graphite&lt;/em&gt; module does, which is in our
example initiated with name encode.  The is a builtin module because Wishbone
can export its internal metrics to Graphite.&lt;/p&gt;
&lt;table class="highlighttable"&gt;&lt;tr&gt;&lt;td class="linenos"&gt;&lt;div class="linenodiv"&gt;&lt;pre&gt; 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29&lt;/pre&gt;&lt;/div&gt;&lt;/td&gt;&lt;td class="code"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;---
modules:
    gearmand:
        module: wishbone.input.gearman
        arguments:
            hostlist:
                - server-001
            secret: changemechangeme
            queue: perfdata
            workers: 5

    decode:
        module: metricfactory.decoder.modgearman

    encode:
        module: wishbone.builtin.metrics.graphite
        arguments:
            prefix: nagios.
            script: false

    stdout:
        module: wishbone.builtin.output.stdout

routingtable:

    - gearmand.outbox   -&amp;gt; decode.inbox
    - decode.outbox     -&amp;gt; encode.inbox
    - encode.outbox     -&amp;gt; stdout.inbox
...
&lt;/pre&gt;&lt;/div&gt;
&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;p&gt;We can activate this step by altering the routing table appropriately (line
27, 28).&lt;/p&gt;
&lt;p&gt;Running metricfactory with this bootstrap file gives us following results:
(hostnames have been obfuscated)&lt;/p&gt;
&lt;pre class="literal-block"&gt;
$ metricfactory debug --config modgearmand2graphite.yaml
nagios.aaaaaaaaaaaaaaa.hostcheck.pl 100 1383859655
nagios.bbbbbbbbbbbbbbb.hostcheck.rta 0.000 1383859655
nagios.ccccccccccccccc.hostcheck.pl 100 1383859655
nagios.ddddddddddddddd.hostcheck.rta 128.370 1383859663
nagios.eeeeeeeeeeeeeee.hostcheck.pl 0 1383859663
nagios.fffffffffffffff.hostcheck.rta 213.073 1383859663
nagios.ggggggggggggggg.memory_and_swap_usage.memusedpercent 16 1383859695
nagios.hhhhhhhhhhhhhhh.memory_and_swap_usage.swapusedpercent 0 1383859695
nagios.iiiiiiiiiiiiiii.memory_and_swap_usage.memused 1178 1383859695
nagios.jjjjjjjjjjjjjjj.memory_and_swap_usage.swapused 0 1383859695
...snip...
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="write-to-graphite"&gt;
&lt;h2&gt;Write to Graphite&lt;/h2&gt;
&lt;p&gt;Writing metrics to STDOUT is nice to see how results look like but that's not
what we want.  The next step is to write the Graphite metrics into Graphite.
For this we require the &lt;em&gt;wishbone.output.tcp&lt;/em&gt; module which we initiate with
name &lt;em&gt;tcpout&lt;/em&gt; in the following bootstrap file:&lt;/p&gt;
&lt;table class="highlighttable"&gt;&lt;tr&gt;&lt;td class="linenos"&gt;&lt;div class="linenodiv"&gt;&lt;pre&gt; 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35&lt;/pre&gt;&lt;/div&gt;&lt;/td&gt;&lt;td class="code"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;---
modules:
    gearmand:
        module: wishbone.input.gearman
        arguments:
            hostlist:
                - server-001
            secret: changemechangeme
            queue: perfdata
            workers: 5

    decode:
        module: metricfactory.decoder.modgearman

    encode:
        module: wishbone.builtin.metrics.graphite
        arguments:
            prefix: nagios.
            script: false

    stdout:
        module: wishbone.builtin.output.stdout

    tcpout:
        module: wishbone.output.tcp
        arguments:
            host: graphite-001
            port: 2013

routingtable:

    - gearmand.outbox   -&amp;gt; decode.inbox
    - decode.outbox     -&amp;gt; encode.inbox
    - encode.outbox     -&amp;gt; tcpout.inbox
...
&lt;/pre&gt;&lt;/div&gt;
&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;p&gt;You can leave the &lt;em&gt;stdout&lt;/em&gt; module in here for convenience. As long it doesn't
occur in the &lt;em&gt;routingtable&lt;/em&gt; definition it doesn't serve a purpose.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="conclusion"&gt;
&lt;h2&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;We have covered how to setup Metricfactory to consume metric data from
ModGearman and submit that to Graphite. &amp;nbsp;We covered in detail how data
changes when traveling through the different modules to get a better
understanding of the whole process.&lt;/p&gt;
&lt;/div&gt;
</summary><category term="monitoringlove"></category><category term="graphite"></category><category term="metricfactory"></category><category term="metrics"></category><category term="nagios"></category><category term="mod_gearman"></category></entry><entry><title>Load balance and high availability patterns using Wishbone</title><link href="http://smetj.net/loadbalance-and-ha-patterns-using-wishbone.html" rel="alternate"></link><updated>2013-11-02T22:48:00+01:00</updated><author><name>smetj</name></author><id>tag:smetj.net,2013-11-02:loadbalance-and-ha-patterns-using-wishbone.html</id><summary type="html">&lt;p&gt;In this article I would like to explore the possibilities of creating a TCP
based event proxy which balances events to one or more TCP backends.  For this
we will run through a couple of scenarios in which we highlight different
approaches.&lt;/p&gt;
&lt;p&gt;&lt;/p&gt;
&lt;div class="section" id="installation"&gt;
&lt;h2&gt;Installation&lt;/h2&gt;
&lt;p&gt;For the below mentioned scenarios we need to have 3 components installed:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;a class="reference external" href="https://github.com/smetj/wishbone"&gt;Wishbone&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="https://github.com/smetj/wishboneModules/tree/master/wb_output_tcp"&gt;wb_output_tcp&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="https://github.com/smetj/wishboneModules/tree/master/wb_input_tcp"&gt;wb_input_tcp&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Wishbone itself can be installed through pypi while the two TCP modules have
to be installed from Github.&lt;/p&gt;
&lt;p&gt;When everything is installed correctly you should be able to execute the following:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
(python-2.7.5)[smetj&amp;#64;indigo ~]$ wishbone list
&lt;/pre&gt;
&lt;p&gt;You should at least see the two tcp modules.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;The bootstrap files used throughout this article can be downloaded from
Github_.&lt;/strong&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="introduction"&gt;
&lt;h2&gt;Introduction&lt;/h2&gt;
&lt;p&gt;The bootstrap files used for the following scenarios can be downloaded from
&lt;a class="reference external" href="https://github.com/smetj/experiments/tree/master/blog/loadbalance-and-ha-patterns-using-wishbone"&gt;here&lt;/a&gt;.  In order to complete the examples you require a working Wishbone
setup along with the 2 TCP modules and a working installation of &lt;a class="reference external" href="http://nmap.org/ncat"&gt;nc&lt;/a&gt; and
&lt;a class="reference external" href="http://www.ivarch.com/programs/pv.shtml"&gt;pv&lt;/a&gt; which both are in general available through your package manager.&lt;/p&gt;
&lt;p&gt;The scenarios focus on simplicity over practical use in order to highlight the
different aspects Wishbone offers.&lt;/p&gt;
&lt;p&gt;The bootstrap files are configured to make use of Graphite to store Wishbone
specific metrics.  This is particularly handy to have some insight about the
dataflow inside Wishbone.  If you don't wish to make use of this you can omit
the &amp;quot;metrics&amp;quot; part of each bootstrap file.&lt;/p&gt;
&lt;p&gt;Each scenario requires a set of servers servers.  The easiest is to create a
new terminal/console for each of them so they run separately from each other
in the foreground.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="scenario-i-simple-setup"&gt;
&lt;h2&gt;Scenario I - Simple setup&lt;/h2&gt;
&lt;p&gt;In this first scenario we will create 1000 events and pipe them via Wishbone
to some external TCP service.  Each line is one event.  We want to verify
whether we have received all events we have send.&lt;/p&gt;
&lt;table class="highlighttable"&gt;&lt;tr&gt;&lt;td class="linenos"&gt;&lt;div class="linenodiv"&gt;&lt;pre&gt; 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29&lt;/pre&gt;&lt;/div&gt;&lt;/td&gt;&lt;td class="code"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;  ---
  metrics:
    graphite:
      module: wishbone.builtin.metrics.graphite

  modules:

    graphite_server:
      module: wishbone.output.tcp
      arguments:
        host: graphite-001
        port: 2013

    input:
      module: wishbone.input.tcp
      arguments:
        port: 10000

    output:
      module: wishbone.output.tcp
      arguments:
        port: 20000

  routingtable:
    #metric stream
    - graphite.outbox         -&amp;gt; graphite_server.inbox
    #organize event stream
    - input.outbox            -&amp;gt; output.inbox
  ...
&lt;/pre&gt;&lt;/div&gt;
&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;p&gt;In the first console we start our destination server on port 20000.  In the
bootstrap file we have defined that events will be submitted that port (line
24).  We pipe the input it receives to pv, in order to have some basic metrics
available about incoming data after which we write the incoming data to a file
in order to verify the generated data and received data is equal.&lt;/p&gt;
&lt;div class="section" id="output-console"&gt;
&lt;h3&gt;Output console&lt;/h3&gt;
&lt;!--  --&gt;
&lt;blockquote&gt;
$ nc -kl 20000|pv -l &amp;gt; scenario_1.output&lt;/blockquote&gt;
&lt;/div&gt;
&lt;div class="section" id="wishbone-console"&gt;
&lt;h3&gt;Wishbone console&lt;/h3&gt;
&lt;p&gt;In the second console,  In another console we start the wishbone server.&lt;/p&gt;
&lt;!--  --&gt;
&lt;blockquote&gt;
$ wishbone debug --config scenario_1.yaml&lt;/blockquote&gt;
&lt;/div&gt;
&lt;div class="section" id="input-console"&gt;
&lt;h3&gt;Input console&lt;/h3&gt;
&lt;p&gt;In the third console we first generate the data file, take the hash from it
and then send it to wishbone on port 10000.&lt;/p&gt;
&lt;!--  --&gt;
&lt;blockquote&gt;
$ for c in $(seq 1 10000);do echo hello ;done &amp;gt; scenario_1.input&lt;/blockquote&gt;
&lt;p&gt;We take the hash value of our input file:&lt;/p&gt;
&lt;!--  --&gt;
&lt;blockquote&gt;
&lt;div class="line-block"&gt;
&lt;div class="line"&gt;$ sha256sum scenario_1.input&lt;/div&gt;
&lt;div class="line"&gt;7ad0a3fa03c69b6af08ebbede9e20dad2687b5b46481543733152b2ca661e333&lt;/div&gt;
&lt;/div&gt;
&lt;/blockquote&gt;
&lt;p&gt;Now we send the content of that file to Wishbone:&lt;/p&gt;
&lt;!--  --&gt;
&lt;blockquote&gt;
$ cat scenario_1.input | nc localhost 10000&lt;/blockquote&gt;
&lt;/div&gt;
&lt;div class="section" id="verifying-the-results"&gt;
&lt;h3&gt;Verifying the results&lt;/h3&gt;
&lt;p&gt;In the &lt;em&gt;output&lt;/em&gt; console we can now stop the server by pressing ctrl+c.  If all
went well, &lt;em&gt;scenario_1.output&lt;/em&gt; has the same checksum as the input file we have
generated on the &lt;em&gt;input&lt;/em&gt; console.&lt;/p&gt;
&lt;p&gt;If we go take a look to Graphite, we can conclude 10000 events arrived in the
&lt;strong&gt;input&lt;/strong&gt; module's &lt;strong&gt;outbox&lt;/strong&gt; queue and 10000 events arrived in the &lt;strong&gt;output&lt;/strong&gt;
module's &lt;strong&gt;inbox&lt;/strong&gt; queue.  This is consistent to the routing table we have
defined.&lt;/p&gt;
&lt;p&gt;&lt;img alt="scenario_1_graphite" class="align-top" src="pics/loadbalance-and-ha-patterns-using-wishbone/scenario_1_graphite.png" /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="conclusion"&gt;
&lt;h3&gt;Conclusion&lt;/h3&gt;
&lt;p&gt;Nothing fancy, simple and straightforward functionality.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="scenario-ii-loadbalance-over-multiple-destinations"&gt;
&lt;h2&gt;Scenario II - Loadbalance over multiple destinations&lt;/h2&gt;
&lt;p&gt;In this scenario we repeat the setup of scenario I but we will spread the
events over 2 destinations.  For this we need to add the &lt;a class="reference external" href="https://wishbone.readthedocs.org/en/latest/modules.html#roundrobin"&gt;roundrobin&lt;/a&gt; module
and one more output module (line 27).&lt;/p&gt;
&lt;table class="highlighttable"&gt;&lt;tr&gt;&lt;td class="linenos"&gt;&lt;div class="linenodiv"&gt;&lt;pre&gt; 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39&lt;/pre&gt;&lt;/div&gt;&lt;/td&gt;&lt;td class="code"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;  ---
  metrics:
    graphite:
      module: wishbone.builtin.metrics.graphite

  modules:

    graphite_server:
      module: wishbone.output.tcp
      arguments:
        host: graphite-001
        port: 2013

    input:
      module: wishbone.input.tcp
      arguments:
        port: 10000

    roundrobin:
      module: wishbone.builtin.flow.roundrobin

    output_1:
      module: wishbone.output.tcp
      arguments:
        port: 20000

    output_2:
      module: wishbone.output.tcp
      arguments:
        port: 20001

  routingtable:
    #metric stream
    - graphite.outbox         -&amp;gt; graphite_server.inbox
    #organize event stream
    - input.outbox            -&amp;gt; roundrobin.inbox
    - roundrobin.one          -&amp;gt; output_1.inbox
    - roundrobin.two          -&amp;gt; output_2.inbox
  ...
&lt;/pre&gt;&lt;/div&gt;
&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;p&gt;The way events stream from one module to the other is defined in the routing
table (line 32).  By default, the  &lt;a class="reference external" href="https://wishbone.readthedocs.org/en/latest/modules.html#roundrobin"&gt;roundrobin&lt;/a&gt; module has only 1 inbox
queue.  when connecting other queues to the module we can choose whatever name
we assign to these queues (line 37 and 38).&lt;/p&gt;
&lt;p&gt;The second external TCP server is going to listen on port 20001 (line 30).
The plan is to split the 10000 events over these 2 TCP servers.&lt;/p&gt;
&lt;div class="section" id="output-console-1"&gt;
&lt;h3&gt;Output console 1&lt;/h3&gt;
&lt;!--  --&gt;
&lt;blockquote&gt;
$ nc -kl 20000|pv -l &amp;gt; scenario_2_1.output&lt;/blockquote&gt;
&lt;/div&gt;
&lt;div class="section" id="output-console-2"&gt;
&lt;h3&gt;Output console 2&lt;/h3&gt;
&lt;!--  --&gt;
&lt;blockquote&gt;
$ nc -kl 20001|pv -l &amp;gt; scenario_2_2.output&lt;/blockquote&gt;
&lt;/div&gt;
&lt;div class="section" id="id1"&gt;
&lt;h3&gt;Wishbone console&lt;/h3&gt;
&lt;!--  --&gt;
&lt;blockquote&gt;
$ wishbone debug --config scenario_2.yaml&lt;/blockquote&gt;
&lt;/div&gt;
&lt;div class="section" id="id2"&gt;
&lt;h3&gt;Input console&lt;/h3&gt;
&lt;p&gt;We create again a file containing 10000 events:&lt;/p&gt;
&lt;!--  --&gt;
&lt;blockquote&gt;
$ for c in $(seq 1 10000);do echo hello ;done &amp;gt; scenario_2.input&lt;/blockquote&gt;
&lt;p&gt;We take the hash value of our input file:&lt;/p&gt;
&lt;!--  --&gt;
&lt;blockquote&gt;
&lt;div class="line-block"&gt;
&lt;div class="line"&gt;$ sha256sum scenario_2.input&lt;/div&gt;
&lt;div class="line"&gt;7ad0a3fa03c69b6af08ebbede9e20dad2687b5b46481543733152b2ca661e333&lt;/div&gt;
&lt;/div&gt;
&lt;/blockquote&gt;
&lt;p&gt;Now we send the content of that file to Wishbone:&lt;/p&gt;
&lt;!--  --&gt;
&lt;blockquote&gt;
$ cat scenario_1.input | nc localhost 10000&lt;/blockquote&gt;
&lt;/div&gt;
&lt;div class="section" id="id3"&gt;
&lt;h3&gt;Verifying the results&lt;/h3&gt;
&lt;p&gt;The events have been split equally over both destinations:&lt;/p&gt;
&lt;!--  --&gt;
&lt;blockquote&gt;
&lt;div class="line-block"&gt;
&lt;div class="line"&gt;$ wc -l scenario_2_1.output scenario_2_2.output&lt;/div&gt;
&lt;div class="line"&gt;5000 scenario_2_1.output&lt;/div&gt;
&lt;div class="line"&gt;5000 scenario_2_2.output&lt;/div&gt;
&lt;div class="line"&gt;10000 total&lt;/div&gt;
&lt;/div&gt;
&lt;/blockquote&gt;
&lt;p&gt;The combined hash of both files &lt;em&gt;scenario_2_1.output&lt;/em&gt; and
&lt;em&gt;scenario_2_2.output&lt;/em&gt; using following command:&lt;/p&gt;
&lt;!--  --&gt;
&lt;blockquote&gt;
&lt;div class="line-block"&gt;
&lt;div class="line"&gt;$ cat scenario_2_1.output scenario_2_2.output |sha256sum&lt;/div&gt;
&lt;div class="line"&gt;7ad0a3fa03c69b6af08ebbede9e20dad2687b5b46481543733152b2ca661e333  -&lt;/div&gt;
&lt;/div&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;div class="section" id="id4"&gt;
&lt;h3&gt;Conclusion&lt;/h3&gt;
&lt;p&gt;Adding additional destinations is just a matter of adding more (output)
modules and connect them appropriately in the routing table to the roundrobin
module.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="scenario-iii-loadbalance-and-failover"&gt;
&lt;h2&gt;Scenario III - Loadbalance and failover&lt;/h2&gt;
&lt;p&gt;Obviously, everything works out when all destinations are in working order. In
reality this is not always going to be the case. In this scenario we will
explore how Wishbone deals with different types of outages.&lt;/p&gt;
&lt;div class="section" id="destination-unavailable-when-initializing-wishbone"&gt;
&lt;h3&gt;destination unavailable when initializing Wishbone&lt;/h3&gt;
&lt;p&gt;If you repeat scenario II with only 1 TCP server available, you will notice
that all events will arrive in the destination which is alive.  This behavior
is described in the &lt;a class="reference external" href="http://wishbone.readthedocs.org/en/latest/patterns.html#starting-state"&gt;Wishbone output module patterns documentation&lt;/a&gt;.  An
output module's input queue is not accepting any input until it determines it
can write events to the outside world.  The module retries every second to
establish a successful connection.  Once done, the input queue is unlocked and
further data is accepted.  In this situation we don't seem to have a problem.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="destination-becomes-unavailable-after-initializing-wishbone"&gt;
&lt;h3&gt;destination becomes unavailable after initializing Wishbone&lt;/h3&gt;
&lt;p&gt;If however a destination becomes unavailable after the module is already
accepting data, we might end up in a different situation.&lt;/p&gt;
&lt;p&gt;Repeat scenario II but with that difference you interrupt one of both
destinations while data is being transmitted.  After all events are submitted
let's check how many events we have received:&lt;/p&gt;
&lt;!--  --&gt;
&lt;blockquote&gt;
&lt;div class="line-block"&gt;
&lt;div class="line"&gt;$ wc -l scenario_3_1.output scenario_3_2.output&lt;/div&gt;
&lt;div class="line"&gt;647208 scenario_3_1.output&lt;/div&gt;
&lt;div class="line"&gt;302444 scenario_3_2.output&lt;/div&gt;
&lt;div class="line"&gt;949652 total&lt;/div&gt;
&lt;/div&gt;
&lt;/blockquote&gt;
&lt;p&gt;So we come short 50348 messages at this stage. Where are they?&lt;/p&gt;
&lt;p&gt;If we have a look in Graphite to the metrics Wishbone has produced we can see
that metric wishbone.queue.output_2.inbox.size has a value of 50347.  These
messages are stuck in Wishbone and are not going anywhere as long as
destination 2 is offline.  What happened is that messages were initially
allowed to come into the &lt;em&gt;output_2&lt;/em&gt; module until that destination became
unavailable after which the inbox of &lt;em&gt;output_2&lt;/em&gt; got locked.&lt;/p&gt;
&lt;p&gt;&lt;img alt="scenario_3_graphite" src="pics/loadbalance-and-ha-patterns-using-wishbone/scenario_3_graphite.png" /&gt;&lt;/p&gt;
&lt;p&gt;If sum up all number we still come short 1 message.  It is safe to presume
this message did arrive in nc but wasn't yet written to disk since we have
interrupted the running server.  Using the metrics Wishbone receives we can
sum the total number of messages which passed the queue
&lt;em&gt;wishbone.queue.output_1.inbox.out_total&lt;/em&gt; and
&lt;em&gt;wishbone.queue.output_2.inbox.out_total&lt;/em&gt; which is 949654.  Add to this the
number of messages being stuck output_2 &lt;em&gt;wishbone.queue.output_2.inbox.size&lt;/em&gt;
then we have 1000001.  From this number we have to deduct 1 because it's
required to pop a message from a queue in order to try to submit it.  That one
message is put back in the module's inbox queue.&lt;/p&gt;
&lt;p&gt;At least we have all our messages accounted for, but it's still not a
desirable situation.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="the-solution"&gt;
&lt;h3&gt;The solution&lt;/h3&gt;
&lt;p&gt;To mitigate this, we can initialize the output modules with a argument which
alters the way it deals with messages which failed to go out.  That behavior
is described in the output module patterns &lt;a class="reference external" href="http://wishbone.readthedocs.org/en/latest/patterns.html#handle-failed-and-successful-events"&gt;documentation&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;img alt="scenario_3" class="align-top" src="pics/loadbalance-and-ha-patterns-using-wishbone/scenario_3_combo.png" /&gt;&lt;/p&gt;
&lt;p&gt;Basically, it boils down to this: In this bootstrap file we initiate the
output_2 module by setting the failed argument to true (line 35).  That
creates a &lt;em&gt;failed&lt;/em&gt; queue in which all failed events arrive.  This failed queue
is in its turn connected (line 46-47) to the funnel module (line 19), which
allows the failed events to flow to a working output.  Since the failing
output's inbox queue is locked for incoming events, it will be drained from
all events.&lt;/p&gt;
&lt;p&gt;When repeating our last scenario using this bootstrap file, we have according
to Graphite no queues anymore containing stuck messages.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="id5"&gt;
&lt;h2&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;Going through the above scenarios we have seen that Wishbone's module and
queue connectivity is a very flexible approach to design and define
alternative message flows.  The module registration and event flow syntax
facilitates easy modification of existing setups with new functionality.  By
submitting Wishbone metrics into Graphite we have a view on the internal
message flow and allows us to verify and confirm assumptions we make about the
message flow.&lt;/p&gt;
&lt;/div&gt;
</summary><category term="messaging"></category><category term="events"></category><category term="wishbone"></category><category term="python"></category></entry><entry><title>Testing Graphite with MetricFactory revisited</title><link href="http://smetj.net/testing-graphite-with-metricfactory-revisited.html" rel="alternate"></link><updated>2013-10-20T20:42:00+02:00</updated><author><name>smetj</name></author><id>tag:smetj.net,2013-10-20:testing-graphite-with-metricfactory-revisited.html</id><summary type="html">&lt;p&gt;In this post we revisit a previously posted article on how we can test and
stress test a Graphite setup. This is basically a rewrite of that article
since the Wishbone and MetricFactory software have meanwhile changed
enough to dedicate a new article to it.&lt;/p&gt;
&lt;p&gt;Our end-goal still stands.  We want to test and understand the behavior of a
Graphite setup by writing metrics into it using different scenarios.&lt;/p&gt;
&lt;div class="section" id="installation"&gt;
&lt;h2&gt;Installation&lt;/h2&gt;
&lt;p&gt;Installing metricfactory is a matter of checking out the project from
Git and running the installer. &amp;nbsp;All dependencies should be downloaded
automatically.&lt;/p&gt;
&lt;pre class="literal-block"&gt;
$ git clone https://github.com/smetj/metricfactory
$ cd metricfactory
$ sudo python setup.py install
&lt;/pre&gt;
&lt;p&gt;An additional &lt;a class="reference external" href="https://github.com/smetj/wishboneModules"&gt;Wishbone module&lt;/a&gt;:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;a class="reference external" href="https://github.com/smetj/wishboneModules/tree/master/wb_output_tcp"&gt;https://github.com/smetj/wishboneModules/tree/master/wb_output_tcp&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;pre class="literal-block"&gt;
$ git clone https://github.com/smetj/wishboneModules
$ cd wishboneModules/wb_output_tcp/
$ sudo python setup.py install
&lt;/pre&gt;
&lt;p&gt;One or more of following packages might be required to successfully
finish the install:&lt;/p&gt;
&lt;blockquote&gt;
gcc, gcc-c++, make, python-devel, Cython&lt;/blockquote&gt;
&lt;p&gt;Once installed you can execute following command:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
$ metricfactory list
$ metricfactory list --group metricfactory.encoder
$ metricfactory list --group metricfactory.decoder
$ metricfactory list --group metricfactory.test
&lt;/pre&gt;
&lt;p&gt;That should return a list of all available modules. &amp;nbsp;You should see at
least tcp, hammer and graphite.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="bootstrap"&gt;
&lt;h2&gt;Bootstrap&lt;/h2&gt;
&lt;p&gt;Starting Metricfactory requires a bootstrap file. &amp;nbsp;A bootstrap file is a YAML
formatted file containing the configuration of which modules to initiate and
which path events will follow through these module instances.&lt;/p&gt;
&lt;p&gt;All bootstrap files used throughout this article can be found &lt;a class="reference external" href="https://github.com/smetj/experiments/blob/master/metricfactory/hammerGraphite"&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="scenario-1-submit-fixed-number-of-metrics-to-graphite"&gt;
&lt;h2&gt;Scenario 1: Submit fixed number of metrics to graphite.&lt;/h2&gt;
&lt;p&gt;Let's say we have a Graphite setup of 1 carbon-relay instance which forwards
metrics to 1 or more carbon instances. &amp;nbsp;We want to see how Graphite behaves
under a predictable load.&lt;/p&gt;
&lt;table class="highlighttable"&gt;&lt;tr&gt;&lt;td class="linenos"&gt;&lt;div class="linenodiv"&gt;&lt;pre&gt; 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25&lt;/pre&gt;&lt;/div&gt;&lt;/td&gt;&lt;td class="code"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;---
modules:

    hammer:
        module: metricfactory.test.hammer
        arguments:
            batch: 1
            batch_size: 100
            set_size: 100
            value: 1000

    encodegraphite:
        module: wishbone.builtin.metrics.graphite

    tcp:
        module: wishbone.output.tcp
        arguments:
            host: graphite-001
            port: 2013

routingtable:

    - hammer.outbox             -&amp;gt; encodegraphite.inbox
    - encodegraphite.outbox     -&amp;gt; tcp.inbox
...
&lt;/pre&gt;&lt;/div&gt;
&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;p&gt;The hammer module (line 4) is the module which generates metrics in a generic
format. The module is initialized to produce 1 batch (line 7) of metrics
consisting out of 100 unique sets (line 8) each containing 100 metrics
(line9). This means 10000 unique metrics are generated. Batch (line 7)
determines how many times we want to regenerate this collection of metrics.  A
value of 0 would mean indefinitely.  The sleep parameter (not used, default 1)
determines the time in seconds between each batch. The value parameter (line
10) determines the maximum value the random generated metric value can be.&lt;/p&gt;
&lt;p&gt;The routing table (line 21) tells us events are traveling through the modules
in following order:&lt;/p&gt;
&lt;blockquote&gt;
hammer -&amp;gt; encodegraphite -&amp;gt; tcp&lt;/blockquote&gt;
&lt;p&gt;The tcp module (line 15) submits the metrics over TCP to the destination
defined with the host (line 18) and port (line 19)&lt;/p&gt;
&lt;p&gt;Start the server in the foreground using following command:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
$ metricfactory debug --config hammer_scenario_1.yaml
&lt;/pre&gt;
&lt;p&gt;You can stop by pressing ctrl+c.&lt;/p&gt;
&lt;p&gt;&lt;a class="reference external" href="pics/testing-graphite-with-metricfactory-revisited-001.png"&gt;&lt;img alt="graphite1" src="pics/testing-graphite-with-metricfactory-revisited-001.png" /&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;When reviewing the metricsReceived values of both the carbon.relay as
carbon.cache we see we have received the expected amount of metrics.&lt;/p&gt;
&lt;p&gt;Keep in mind since each generated metric is unique, &lt;strong&gt;10000 wsp files&lt;/strong&gt; are
created. It's likely that after running this test,  you will only find a
subset of the generated data stored in Graphite.  This is because Graphite
does rate limiting and is not creating all wsp files in order not to hammer
the disks.  You might want to tweak Graphite to meet your expectations and
rerun the above setup to test your setup.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="scenario-2-submit-a-fixed-number-of-metrics-to-2-carbon-relays"&gt;
&lt;h2&gt;Scenario 2: Submit a fixed number of metrics to 2 carbon-relays&lt;/h2&gt;
&lt;p&gt;Let's say we have a setup with 2 carbon relays with multiple carbon-caches
behind that.  In this case you might want to verify whether you can really
afford to loose a relay node.  We can use the same approach as we did in
scenario 1 and produce and submit a known number of metrics.&lt;/p&gt;
&lt;p&gt;The below bootstrap file is setup in such a way that produced metrics are
spread over 2 tcp destinations.  You might want to execute a couple of runs
while killing parts of your Graphite setup to verify it behaves as expected
and whether there is no metric loss.&lt;/p&gt;
&lt;table class="highlighttable"&gt;&lt;tr&gt;&lt;td class="linenos"&gt;&lt;div class="linenodiv"&gt;&lt;pre&gt; 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45&lt;/pre&gt;&lt;/div&gt;&lt;/td&gt;&lt;td class="code"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;---
modules:

    hammer:
        module: metricfactory.test.hammer
        arguments:
            batch: 10
            batch_size: 100
            set_size: 100
            value: 1000
            sleep: 1

    encodegraphite:
        module: wishbone.builtin.metrics.graphite

    funnel:
        module: wishbone.builtin.flow.funnel

    balance:
        module: wishbone.builtin.flow.roundrobin

    tcp1:
        module: wishbone.output.tcp
        arguments:
            host: graphite-001
            port: 2013

    tcp2:
        module: wishbone.output.tcp
        arguments:
            host: graphite-002
            port: 2013

routingtable:

    - hammer.outbox             -&amp;gt; encodegraphite.inbox
    - encodegraphite.outbox     -&amp;gt; funnel.two

    - funnel.outbox             -&amp;gt; balance.inbox
    - balance.one               -&amp;gt; tcp1.inbox
    - balance.two               -&amp;gt; tcp2.inbox

    - tcp1.failed               -&amp;gt; funnel.one
    - tcp2.failed               -&amp;gt; funnel.three
...
&lt;/pre&gt;&lt;/div&gt;
&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;p&gt;Start the server in the foreground using following command:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
$ metricfactory debug --config hammer_scenario_2.yaml
&lt;/pre&gt;
&lt;p&gt;You can stop by pressing ctrl+c.&lt;/p&gt;
&lt;p&gt;The above example will send 10 batches (line 7) of 100 sets (line 8) of 100
metrics (line 9) resulting into 100000 unique metrics.  Between each batch
10000 metrics we wait 1 second (line 11).&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="scenario-3-determine-the-maximum-throughput-of-metrics"&gt;
&lt;h2&gt;Scenario 3: Determine the maximum throughput of metrics&lt;/h2&gt;
&lt;p&gt;Let's say we want to have a ballpark number of how many metrics per second our
Graphite instance is able to receive.&lt;/p&gt;
&lt;p&gt;For this we use the below bootstrap file:&lt;/p&gt;
&lt;table class="highlighttable"&gt;&lt;tr&gt;&lt;td class="linenos"&gt;&lt;div class="linenodiv"&gt;&lt;pre&gt; 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25&lt;/pre&gt;&lt;/div&gt;&lt;/td&gt;&lt;td class="code"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;---
modules:

    hammer:
        module: metricfactory.test.hammer
        arguments:
            batch: 0
            batch_size: 100
            set_size: 100
            value: 1000

    encodegraphite:
        module: wishbone.builtin.metrics.graphite

    tcp:
        module: wishbone.output.tcp
        arguments:
            host: graphite-001
            port: 2013

routingtable:

    - hammer.outbox             -&amp;gt; encodegraphite.inbox
    - encodegraphite.outbox     -&amp;gt; tcp.inbox
...
&lt;/pre&gt;&lt;/div&gt;
&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;p&gt;By setting the batch argument (line 10) to 0, we indefinitely send the defined
batch.  If we overflow Metricfactory because we can't write metrics out fast
enough , throttling will be enabled automatically.&lt;/p&gt;
&lt;p&gt;You could even start X amount of similar parallel processes by using the
--instances parameter when bootstrapping:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
$ metricfactory debug --config hammer_scenario_3.yaml --instances 4
&lt;/pre&gt;
&lt;p&gt;&lt;img alt="graphite3" src="pics/scenario_3.png" /&gt;&lt;/p&gt;
&lt;p&gt;As you can see we're maxing out the cpu usage of the relay server while
processing on average 1117000 metrics/s.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="conclusion"&gt;
&lt;h2&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;Generating a predictable number of metrics can be practical to verify whether
Graphite behaves as expected in different scenarios.  It becomes even more
meaningful when you have a more complex environment with a number of relays
with sharding and duplication policies. &amp;nbsp;By generating batches of continuous
mertics it's possible to get an idea about the throughput of your Graphite
setup.&lt;/p&gt;
&lt;/div&gt;
</summary><category term="monitoringlove"></category><category term="graphite"></category><category term="metricfactory"></category><category term="python"></category></entry><entry><title>Installing PyPy with Gevent and virtualenv on Fedora</title><link href="http://smetj.net/installing-pypy-with-gevent-and-virtualenv-on-fedora.html" rel="alternate"></link><updated>2013-06-05T01:26:00+02:00</updated><author><name>smetj</name></author><id>tag:smetj.net,2013-06-05:installing-pypy-with-gevent-and-virtualenv-on-fedora.html</id><summary type="html">&lt;p&gt;PyPy has been on my radar for a while but I have never really brought
myself to the point of actually trying it. &amp;nbsp;Recently, a notification
caught to my attention stating PyPy 2.0.2 was released and had support
to run Gevent. &amp;nbsp;Good news! I was looking at speed improvements for
my&amp;nbsp;&lt;a class="reference external" href="https://github.com/smetj/wishbone"&gt;Wishbone library&lt;/a&gt; and decided to spend some effort into getting
PyPy with Gevent up and running. &amp;nbsp;The information available explaining
how to setup Gevent in PyPy is rather sparse which might be a bit time
consuming when you have to figure out the bits and pieces. &amp;nbsp;After some
tinkering I got PyPy with Gevent up and running within virtualenv on a
Fedora host. &amp;nbsp;Here are my notes, It might be useful for you to and save
some previous time:&lt;/p&gt;
&lt;p&gt;Before you proceed make sure you have read the
&amp;quot;&lt;a class="reference external" href="http://pypy.org/download.html#building-from-source"&gt;building-from-source&lt;/a&gt;&amp;quot; instructions from the PyPy site.&lt;/p&gt;
&lt;div class="section" id="compiling"&gt;
&lt;h2&gt;Compiling&lt;/h2&gt;
&lt;p&gt;PyPy has some binaries available but they can only be used on Ubuntu so
we'll have to download the source and compile from scratch.&lt;/p&gt;
&lt;p&gt;Start by &lt;a class="reference external" href="http://pypy.org/download.html"&gt;downloading the source&lt;/a&gt; and unpack the tarball.&lt;/p&gt;
&lt;pre class="literal-block"&gt;
$ tar -xvjf pypy-2.0.2-src.tar.bz2
&lt;/pre&gt;
&lt;p&gt;Before starting to compile make sure we have all required libraries
installed:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
$ yum install openssl-devel libffi-devel ncurses-devel expat-devel bzip2-devel
&lt;/pre&gt;
&lt;p&gt;Move into our unpacked directory and start the compilation. &amp;nbsp;In the
below examples we use the Python version which comes with your os to run
the compilation process.&lt;/p&gt;
&lt;pre class="literal-block"&gt;
$ cd pypy-2.0.2-src/pypy/goal
$ python ../../rpython/bin/rpython --opt=jit targetpypystandalone.py
&lt;/pre&gt;
&lt;p&gt;The compilation process is fairly lengthy. &amp;nbsp;It took +- 90 minutes(!) on
my laptop for the process to finish.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="prepare-the-installation"&gt;
&lt;h2&gt;Prepare the installation&lt;/h2&gt;
&lt;p&gt;When the compilation has finished we should have a file called
&lt;em&gt;pypy-c&lt;/em&gt; in the current directory.&lt;/p&gt;
&lt;p&gt;Best is to move the complete install to the /opt/ directory and
rename the directory appropriately.&lt;/p&gt;
&lt;pre class="literal-block"&gt;
$ mv pypy-2.0.2-src /opt/pypy-2.0.2
&lt;/pre&gt;
&lt;p&gt;Now let's use virtualenv to create an isolated instance of PyPy, keeping
your freshly compiled one clean:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
$ virtualenv -p /opt/pypy-2.0.2/pypy/goal/pypy-c ~/pypy-2.0.2
$ . ~/pypy-2.0.2/bin/activate
&lt;/pre&gt;
&lt;/div&gt;
&lt;div class="section" id="gevent"&gt;
&lt;h2&gt;Gevent&lt;/h2&gt;
&lt;p&gt;First make sure you have following library installed:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
$ yum install libev-devel
&lt;/pre&gt;
&lt;p&gt;Install the &lt;a class="reference external" href="https://pypi.python.org/pypi/cffi"&gt;cffi&lt;/a&gt; module:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
(pypy-2.0.2)$ pip install cffi
&lt;/pre&gt;
&lt;p&gt;Install a &lt;a class="reference external" href="https://github.com/schmir/gevent"&gt;version of Gevent&lt;/a&gt; which has been modified to run on PyPy.
&amp;nbsp;Make sure we install Gevent inside our virtualenv:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
$ git clone https://github.com/schmir/gevent.git
$ cd gevent
$ git checkout pypy-hacks
$ . ~/pypy-2.0.2/bin/activate
(pypy-2.0.2)$ pypy setup.py install
&lt;/pre&gt;
&lt;p&gt;Now we need one last modification which implements gevent.core as cffi
module:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
$ git clone https://github.com/gevent-on-pypy/pypycore.git
$ cd pypycore
$ . ~/pypy-2.0.2/bin/activate
(pypy-2.0.2)$ CFLAGS=-O2 pip install -e .
&lt;/pre&gt;
&lt;p&gt;If setup.py complains it can not locate &lt;strong&gt;ev.h&lt;/strong&gt; it's possible the library
search path isn't complete. &amp;nbsp;In that case add the directory containing &lt;strong&gt;ev.h&lt;/strong&gt;
to the &lt;strong&gt;include_dirs&lt;/strong&gt; variable in pypycore.py (line 215).  The result would
look similar to example:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
&amp;quot;&amp;quot;&amp;quot;, include_dirs=[include_dir,&amp;quot;/usr/include/libev&amp;quot;], libraries=[&amp;quot;ev&amp;quot;])
&lt;/pre&gt;
&lt;/div&gt;
&lt;div class="section" id="test"&gt;
&lt;h2&gt;Test&lt;/h2&gt;
&lt;p&gt;Before starting &lt;em&gt;PyPy&lt;/em&gt; we have to make sure gevent uses the right
gevent.core:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
$ export GEVENT_LOOP=pypycore.loop
&lt;/pre&gt;
&lt;p&gt;Now start PyPy and execute some gevent code:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
$ . ~/pypy-2.0.2/bin/activate
(pypy-2.0.2)$ pypy
Python 2.7.3 (5acfe049a5b0cd0de158f62553a98f5ef364fd29, Jun 01 2013, 08:37:22)
[PyPy 2.0.2 with GCC 4.7.2 20121109 (Red Hat 4.7.2-8)] on linux2
Type &amp;quot;help&amp;quot;, &amp;quot;copyright&amp;quot;, &amp;quot;credits&amp;quot; or &amp;quot;license&amp;quot; for more information.
And now for something completely different: ``PyPy 1.3 released (windows
binaries included)''
&amp;gt;&amp;gt;&amp;gt;&amp;gt; import gevent
&amp;gt;&amp;gt;&amp;gt;&amp;gt; for _ in xrange(100):
....     gevent.spawn(gevent.sleep, 1)
&lt;/pre&gt;
&lt;/div&gt;
&lt;div class="section" id="conclusion"&gt;
&lt;h2&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;As you can see setting up PyPy with Gevent requires a bit of work.  Once setup
into a virtualenv it's really easy to use, experiment and rebuild.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Have a lot of fun running Gevent on PyPy!&lt;/em&gt;&lt;/p&gt;
&lt;/div&gt;
</summary><category term="python"></category><category term="gevent"></category><category term="pypy"></category></entry><entry><title>Submit Nagios metrics to Graphite with ModGearman and MetricFactory</title><link href="http://smetj.net/submit-nagios-metrics-to-graphite-with-modgearman-and-metricfactory.html" rel="alternate"></link><updated>2013-05-10T15:59:00+02:00</updated><author><name>smetj</name></author><id>tag:smetj.net,2013-05-10:submit-nagios-metrics-to-graphite-with-modgearman-and-metricfactory.html</id><summary type="html">&lt;div class="section" id="this-article-is-superseded"&gt;
&lt;h2&gt;&lt;strong&gt;This article is superseded&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;Read &lt;a class="reference external" href="http://smetj.net/submit-nagios-metrics-to-graphite-with-modgearman-and-metricfactory-revisited.html"&gt;Submit Nagios metrics to Graphite with ModGearman and MetricFactory revisited&lt;/a&gt; instead.&lt;/p&gt;
&lt;p&gt;&lt;/p&gt;
&lt;p&gt;When it comes down to monitoring Nagios is still the weapon of choice
for many. &amp;nbsp;I would have abandoned it if there weren't projects like
&lt;a class="reference external" href="http://mathias-kettner.de/checkmk_livestatus.html"&gt;Livestatus&lt;/a&gt;,&amp;nbsp;&lt;a class="reference external" href="http://labs.consol.de/lang/en/nagios/mod-gearman/"&gt;Mod_Gearman&lt;/a&gt;&amp;nbsp;and&amp;nbsp;&lt;a class="reference external" href="http://www.thruk.org/"&gt;Thruk&lt;/a&gt;&amp;nbsp;which to my opinion should
never be missing from any Nagios setup. &amp;nbsp;Mod_Gearman, the framework
which makes Nagios scalable, has a feature which stores the performance
data produced by the Nagios plugins into a &lt;a class="reference external" href="http://gearman.org/"&gt;Gearman&lt;/a&gt;&amp;nbsp;queue. &amp;nbsp;Graphing
that performance data with &lt;a class="reference external" href="http://graphite.wikidot.com/"&gt;Graphite&lt;/a&gt; is a straightforward job with
&lt;a class="reference external" href="https://github.com/smetj/metricfactory"&gt;Metricfactory&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="performance-data"&gt;
&lt;h2&gt;Performance data&lt;/h2&gt;
&lt;p&gt;Mod_Gearman is a Nagios addon which spreads the Nagios plugin execution
over a farm of worker nodes. &amp;nbsp;This allows you to build a scalable Nagios
setup quite effectively. &amp;nbsp;The workers execute the Nagios plugins and
submit the produced results back into the Gearman master server. &amp;nbsp;A
Nagios broker module then consumes the submitted check results from the
Gearman master and submits the check results into Nagios for further
processing. &amp;nbsp;The broker module can optionally submit the &lt;a class="reference external" href="http://nagios.sourceforge.net/docs/3_0/perfdata.html"&gt;performance
data&lt;/a&gt;&amp;nbsp;back into a dedicated Gearman queue ready to be consumed by an
external process which in our case is going to be Metricfactory.
&amp;nbsp;Metricfactory will convert the performance data into the proper format
and submit that into Graphite.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="mod-gearman"&gt;
&lt;h2&gt;Mod_Gearman&lt;/h2&gt;
&lt;p&gt;The Mod_Gearman project has quite extensive &lt;a class="reference external" href="http://labs.consol.de/lang/en/nagios/mod-gearman/"&gt;documentation
available&lt;/a&gt;&amp;nbsp;but these are the relevant parameters:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
perfdata=yes
&lt;/pre&gt;
&lt;p&gt;Setting the value to&amp;nbsp;&lt;em&gt;yes&lt;/em&gt; makes the broker module write the
performance data to the&amp;nbsp;&lt;em&gt;perfdata&lt;/em&gt; queue.&lt;/p&gt;
&lt;pre class="literal-block"&gt;
perfdata_mode=1
&lt;/pre&gt;
&lt;p&gt;Setting the value to&amp;nbsp;&lt;em&gt;1&lt;/em&gt; makes sure that performance data doesn't pile
up endlessly in the queue when Metricfactory isn't consuming. &amp;nbsp;It's
basically a precaution which prevents the queue to fill up to a point
all available system memory is consumed. &amp;nbsp;Setting the value to&amp;nbsp;&lt;em&gt;2&lt;/em&gt;
will append all performance data to the queue without overwriting old
data. &amp;nbsp;When enabled you can execute the&amp;nbsp;&lt;em&gt;gearman_top&lt;/em&gt; command and you
should see the&amp;nbsp;&lt;em&gt;perfdata&lt;/em&gt; queue appear:&lt;/p&gt;
&lt;p&gt;&lt;a class="reference external" href="pics/gearman_top.png"&gt;&lt;img alt="gearman_top" src="pics/gearman_top.png" /&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;The Jobs Waiting column indicates how many performance data is currently
stored in the queue. &amp;nbsp;Ideally this should be 0 or as low as possible and
never grow otherwise that might indicate the performance data is not
consumed fast enough. Keep in mind that not all Nagios plugins produce
performance data. &amp;nbsp;If you want to be sure whether a plugin produces
performance data, have a look in Thruk (or other Nagios interface) and
verify in the service or host details whether &lt;em&gt;Performance Data&lt;/em&gt;
actually contains valid perfdata.&lt;/p&gt;
&lt;p&gt;&lt;a class="reference external" href="pics/perfdata.png"&gt;&lt;img alt="perfdata" src="pics/perfdata.png" /&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="metricfactory"&gt;
&lt;h2&gt;Metricfactory&lt;/h2&gt;
&lt;p&gt;You can download Metricfactory from &lt;a class="reference external" href="https://github.com/smetj/metricfactory"&gt;Github&lt;/a&gt; and get it up an running
quite easily by following the installation instructions. &amp;nbsp;In our case,
you will require some additional modules which you can install from Pypi
using the&amp;nbsp;&lt;em&gt;easy_install&lt;/em&gt;command:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
$ easy_install wb_gearmand
$ easy_install wb_tcpclient
$ easy_install wb_tippingbucket
$ easy_install wb_stdout
&lt;/pre&gt;
&lt;p&gt;When all went well you should be able to execute (&lt;a class="reference external" href="http://ascii.io/a/3101"&gt;ascii.io
screencast&lt;/a&gt;):&lt;/p&gt;
&lt;pre class="literal-block"&gt;
$ metricfactory list
&lt;/pre&gt;
&lt;/div&gt;
&lt;div class="section" id="configuration"&gt;
&lt;h2&gt;Configuration&lt;/h2&gt;
&lt;p&gt;Metricfactory uses bootstrap files which define the modules to load and
how events will flow through the chain. &amp;nbsp;You can download a base example
&lt;a class="reference external" href="https://github.com/smetj/experiments/blob/master/metricfactory/modgearman2graphite/modgearman2graphite.json"&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;pre class="literal-block"&gt;
{
  &amp;quot;metrics&amp;quot;: {
    &amp;quot;enable&amp;quot;: true,
    &amp;quot;group&amp;quot;: &amp;quot;wishbone.metrics&amp;quot;,
    &amp;quot;interval&amp;quot;: 10,
    &amp;quot;module&amp;quot;: &amp;quot;Log&amp;quot;,
    &amp;quot;variables&amp;quot;: {
    }
  },
  &amp;quot;bootstrap&amp;quot;: {
    &amp;quot;modgearman&amp;quot;: {
      &amp;quot;group&amp;quot;: &amp;quot;wishbone.iomodule&amp;quot;,
      &amp;quot;module&amp;quot;: &amp;quot;Gearmand&amp;quot;,
      &amp;quot;variables&amp;quot;: {
        &amp;quot;hostnames&amp;quot;: [ &amp;quot;your.gearmand.server.hostname&amp;quot; ],
        &amp;quot;secret&amp;quot;: &amp;quot;changemechangeme&amp;quot;,
        &amp;quot;workers&amp;quot;: 1
      }
    },
    &amp;quot;decodemodgearman&amp;quot;: {
      &amp;quot;group&amp;quot;: &amp;quot;metricfactory.decoder&amp;quot;,
      &amp;quot;module&amp;quot;: &amp;quot;ModGearman&amp;quot;,
      &amp;quot;variables&amp;quot;: {
      }
    },
    &amp;quot;encodegraphite&amp;quot;: {
      &amp;quot;group&amp;quot;: &amp;quot;metricfactory.encoder&amp;quot;,
      &amp;quot;module&amp;quot;: &amp;quot;Graphite&amp;quot;,
      &amp;quot;variables&amp;quot;: {
        &amp;quot;prefix&amp;quot;:&amp;quot;nagios&amp;quot;
      }
    },
    &amp;quot;buffer&amp;quot;: {
      &amp;quot;group&amp;quot;: &amp;quot;wishbone.module&amp;quot;,
      &amp;quot;module&amp;quot;: &amp;quot;TippingBucket&amp;quot;,
      &amp;quot;variables&amp;quot;: {
        &amp;quot;events&amp;quot;: 1000,
        &amp;quot;age&amp;quot;: 60
      }
    },
    &amp;quot;tcpout&amp;quot;: {
      &amp;quot;group&amp;quot;: &amp;quot;wishbone.iomodule&amp;quot;,
      &amp;quot;module&amp;quot;: &amp;quot;TCPClient&amp;quot;,
      &amp;quot;variables&amp;quot;: {
        &amp;quot;pool&amp;quot;: [&amp;quot;your.graphite.relay1:2013&amp;quot;,&amp;quot;your.graphite.relay2:2013&amp;quot;]
      }
    },
    &amp;quot;stdout&amp;quot;: {
      &amp;quot;group&amp;quot;: &amp;quot;wishbone.module&amp;quot;,
      &amp;quot;module&amp;quot;: &amp;quot;STDOUT&amp;quot;,
      &amp;quot;variables&amp;quot;: {
        &amp;quot;purge&amp;quot;:true
      }
    }
  },
  &amp;quot;routingtable&amp;quot;: {
    &amp;quot;modgearman.inbox&amp;quot;: [ &amp;quot;decodemodgearman.inbox&amp;quot; ],
    &amp;quot;decodemodgearman.outbox&amp;quot;: [ &amp;quot;encodegraphite.inbox&amp;quot; ],
    &amp;quot;encodegraphite.outbox&amp;quot;: [ &amp;quot;tcpout.inbox&amp;quot; ]
  }
}
&lt;/pre&gt;
&lt;p&gt;Depending on your environment you will have to adapt some of the
variables in the boostrap file. The &lt;em&gt;hostnames&lt;/em&gt; variable (line 15) is a
list of the Gearmand servers from which the&amp;nbsp;&lt;em&gt;perfdata&lt;/em&gt;&amp;nbsp; has to be
consumed. &amp;nbsp;Usually this is a list containing just 1 server. &amp;nbsp;In some
special cases you might add more servers here but that's in our case not
likely.&lt;/p&gt;
&lt;p&gt;The secret variable (line 16) should contain the pre-shared encryption
key allowing you to decrypt the information consumed from Gearmand.
&amp;nbsp;Worth to mention there is no authentication, but without the decryption
key you wont be able to read the data coming from the Gearmand server.&lt;/p&gt;
&lt;p&gt;The number of workers variable (line 17) determines how many workers
should consume perfdata from the&amp;nbsp;&lt;em&gt;perfdata&lt;/em&gt; queue. &amp;nbsp;If you notice
perdata isn't consumed fast enough, you could bump this number to a
higher value. &amp;nbsp;In this case keep an eye on the the CPU usage of
Metricfactory due to the decrypting. &amp;nbsp;If you notice Metricfactory can't
keep up because of high cpu usage then another strategy might be to
leave this numer on 1 and start Metricfactory with the &lt;em&gt;--instances x&lt;/em&gt;
parameter, where x is the number of parallel processes.&lt;/p&gt;
&lt;p&gt;In this configuration, the &lt;em&gt;buffer&lt;/em&gt; instance of the TippingBucket module
will flush when 1000 metrics (line 27) are in the buffer or when the
last metric added to the buffer is 60 seconds (line 38) old. &amp;nbsp;This
allows you to control the size of the data per outgoing connection to
Graphite. &amp;nbsp;It's more efficient to group and submit metrics instead of
making a connection to Graphite per metric.&lt;/p&gt;
&lt;p&gt;The &lt;em&gt;tcpout&lt;/em&gt; instance is initiated in this example with the addresses of
2 Graphite relay servers (line 45). &amp;nbsp;When defining more than 1 address
in the &lt;em&gt;pool&lt;/em&gt; list then the client will randomly select one of the
addresses until a successful connect is done. To test, you can start
Metricfactory in debug mode to keep it from forking in the background
and by enabling the &lt;em&gt;--loglevel debug&lt;/em&gt;&amp;nbsp;parameter:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
$ metricfactory debug --config modgearmand2graphite.json --loglevel debug
&lt;/pre&gt;
&lt;p&gt;&lt;a class="reference external" href="http://ascii.io/a/3102"&gt;ascii.io screencast&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="converting-nagios-format-to-graphite-format"&gt;
&lt;h2&gt;Converting Nagios format to graphite format&lt;/h2&gt;
&lt;p&gt;Graphite stores the metrics in a tree-like hierarchical manner using a
dotted naming scheme. Somehow we will have to convert the Nagios metrics
into this format. &amp;nbsp;Metricfactory converts the metrics coming from an
external source into a common Metricfactory format. &amp;nbsp;From this format
it's straightforward to convert them into another format. Unfortunately,
many years of Nagios plugin development has lead to all kinds of metric
name formats. &amp;nbsp;This&amp;nbsp;inconsistency is something we will have to deal
with. Consider following examples:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
rta=1.274ms;3000.000;5000.000;0; pl=0%;80;100;;
&lt;/pre&gt;
&lt;pre class="literal-block"&gt;
/=1351MB;3426;3627;0;4031 /dev=0MB;3046;3225;0;3584 /dev/shm=0MB;3054;3233;0;3593 /boot=26MB;205;217;0;242 /tmp=16MB;427;452;0;503 /var=1430MB;6853;7256;0;8063 /var/tmp=16MB;427;452;0;503
&lt;/pre&gt;
&lt;pre class="literal-block"&gt;
MemUsedPercent=7%;98;102;0;100 SwapUsedPercent=0%;80;90;0;100 MemUsed=486MB;;;0;7187 SwapUsed=0MB;;;0;204
&lt;/pre&gt;
&lt;p&gt;The names of metrics in the first example are rta and pl respectively.
&amp;nbsp;In the second example the metric names are the paths of mount points
containing slashes. &amp;nbsp;The 3rd example has metric names with mixed
uppercase and lowercase. &amp;nbsp;Although the decode.gearman module does some
basic metric name sanitation, it's perfectly possible to write a
Wishbone module and plug it into your MetricFactory chain to convert the
metric names into whatever your like but covering that topic is out of
scope of this article. To get an idea how our data looks like after each
module we're going to alter the &lt;em&gt;routing table&lt;/em&gt; in the bootstrap file
accordingly. &amp;nbsp;If you take look at our bootstrap file, you notice we have
an additional module initiated called &lt;em&gt;stdout&lt;/em&gt; (line&amp;nbsp;48) which is not
included in our &lt;em&gt;routing table&lt;/em&gt;. &amp;nbsp;The&amp;nbsp;&lt;em&gt;stdout&lt;/em&gt; module prints, as you
might guess, incoming events to STDOUT. &amp;nbsp;Let's go over each step to see
how our data looks like:&lt;/p&gt;
&lt;div class="section" id="data-coming-from-wishbone-iomodule-gearmand"&gt;
&lt;h3&gt;Data coming from wishbone.iomodule.Gearmand&lt;/h3&gt;
&lt;p&gt;To print the data coming from Mod_Gearman to STDOUT we change our
routing table to the following:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
&amp;quot;routingtable&amp;quot;: {
    &amp;quot;modgearman.inbox&amp;quot;: [ &amp;quot;stdout.inbox&amp;quot; ]
  }
&lt;/pre&gt;
&lt;p&gt;Start Metricfactory in the foreground (&lt;a class="reference external" href="http://ascii.io/a/3120"&gt;ascii.io
screencast&lt;/a&gt;):&lt;/p&gt;
&lt;pre class="literal-block"&gt;
$ metricfactory debug --config modgearmand2graphite.json --loglevel debug
&lt;/pre&gt;
&lt;p&gt;Example host performance data:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
DATATYPE::HOSTPERFDATA TIMET::1368178733   HOSTNAME::host_339  HOSTPERFDATA::rta=0.091ms;3000.000;5000.000;0; pl=0%;80;100;;   HOSTCHECKCOMMAND::check:host.alive!(null)   HOSTSTATE::0    HOSTSTATETYPE::1
&lt;/pre&gt;
&lt;p&gt;Example service performance data:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
DATATYPE::SERVICEPERFDATA  TIMET::1368178797   HOSTNAME::localhost SERVICEDESC::Gearman Queues SERVICEPERFDATA::'check_results_waiting'=0;10;100;0 'check_results_running'=0 'check_results_worker'=1;25;50;0 'host_waiting'=0;10;100;0 'host_running'=0 'host_worker'=10;25;50;0 'hostgroup_localhost_waiting'=0;10;100;0 'hostgroup_localhost_running'=1 'hostgroup_localhost_worker'=10;25;50;0 'perfdata_waiting'=0;10;100;0 'perfdata_running'=0 'perfdata_worker'=1;25;50;0 'service_waiting'=0;10;100;0 'service_running'=0 'service_worker'=10;25;50;0 'worker_nagios-001_waiting'=0;10;100;0 'worker_nagios-001_running'=0 'worker_nagios-001_worker'=1;25;50;0   SERVICECHECKCOMMAND::check:app.gearman.master   SERVICESTATE::0 SERVICESTATETYPE::1
&lt;/pre&gt;
&lt;/div&gt;
&lt;div class="section" id="data-coming-from-metricfactory-decoder-modgearman"&gt;
&lt;h3&gt;Data coming from metricfactory.decoder.ModGearman&lt;/h3&gt;
&lt;p&gt;So the data coming from Mod_Gearman needs to be converted into the
common Metricfactory internal format. &amp;nbsp;For this we use a module from the
metricfactory.decoder group, in this case ModGearman.&lt;/p&gt;
&lt;p&gt;Change the routing table to following configuration:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
&amp;quot;routingtable&amp;quot;: {
    &amp;quot;modgearman.inbox&amp;quot;: [ &amp;quot;decodemodgearman.inbox&amp;quot; ],
    &amp;quot;decodemodgearman.outbox&amp;quot;: [ &amp;quot;stdout.inbox&amp;quot; ]
}
&lt;/pre&gt;
&lt;p&gt;Start Metricfactory in the foreground (&lt;a class="reference external" href="http://ascii.io/a/3121"&gt;ascii.io
screencast&lt;/a&gt;):&lt;/p&gt;
&lt;pre class="literal-block"&gt;
$ metricfactory debug --config modgearmand2graphite.json --loglevel debug
&lt;/pre&gt;
&lt;p&gt;Example host perfdata:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
{'name': 'rta', 'tags': ['check:host_alive!(null)', 'hostcheck'], 'value': '0.155', 'source': 'host_409', 'time': '1368179085', 'units': 'ms', 'type': 'nagios'}
&lt;/pre&gt;
&lt;p&gt;Example service perfdata:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
{'name': 'perfdata_waiting', 'tags': ['check:app_gearman_master', 'gearman_queues'], 'value': '0', 'source': 'localhost', 'time': '1368179129', 'units': '', 'type': 'nagios'}
&lt;/pre&gt;
&lt;p&gt;The ModGearman decoder module filters out some characters from different
parts&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="data-coming-from-metricfactory-encoder-graphite"&gt;
&lt;h3&gt;Data coming from metricfactory.encoder.Graphite&lt;/h3&gt;
&lt;p&gt;Now we have to convert the metrics from the internal Metricfactory
format into a the Graphite format. &amp;nbsp;The&amp;nbsp;&lt;em&gt;encodegraphite&lt;/em&gt; module has a
parameter&amp;nbsp;&lt;em&gt;prefix&lt;/em&gt; (line 30) which allows you to define a prefix for
the name of each metric to store in Graphite. &amp;nbsp;With this configuration,
each metric will start with &amp;quot;&lt;em&gt;nagios.&lt;/em&gt;&amp;quot;.&lt;/p&gt;
&lt;p&gt;Change the routing table to following configuration:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
&amp;quot;routingtable&amp;quot;: {
    &amp;quot;modgearman.inbox&amp;quot;: [ &amp;quot;decodemodgearman.inbox&amp;quot; ],
    &amp;quot;decodemodgearman.outbox&amp;quot;: [ &amp;quot;encodegraphite.inbox&amp;quot; ],
    &amp;quot;encodegraphite.outbox&amp;quot;: [ &amp;quot;stdout.inbox&amp;quot; ]
  }
&lt;/pre&gt;
&lt;p&gt;Start Metricfactory in the foreground (&lt;a class="reference external" href="http://ascii.io/a/3122"&gt;ascii.io
screencast&lt;/a&gt;):&lt;/p&gt;
&lt;pre class="literal-block"&gt;
$ metricfactory debug --config modgearmand2graphite.json --loglevel debug
&lt;/pre&gt;
&lt;p&gt;Example:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
nagios.host_260.hostcheck.pl 0 1368179289
nagios.host_26.hostcheck.rta 0.133 1368179289
nagios.host_26.hostcheck.pl 0 1368179289
nagios.host_256.hostcheck.rta 0.123 1368179289
nagios.localhost.gearman_queues.service_running 0 1368179329
nagios.localhost.gearman_queues.service_worker 9 1368179329
nagios.localhost.gearman_queues.worker_nagios-001_waiting 0 1368179329
nagios.localhost.gearman_queues.worker_nagios-001_running 0 1368179329
nagios.localhost.gearman_queues.worker_nagios-001_worker 1 136817932
&lt;/pre&gt;
&lt;p&gt;As you can see the Graphite encoder module had to make some assumptions.
&amp;nbsp;In case the metric type is Nagios (the internal format contains this
information) then the hostchecks always have the word&amp;nbsp;&lt;em&gt;hostcheck&lt;/em&gt; in
the metric name as you can see in the above example. &amp;nbsp;When the data is a
Nagios servicecheck, then the service description is included in the
metric name.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="graphite"&gt;
&lt;h2&gt;Graphite&lt;/h2&gt;
&lt;p&gt;Typically Nagios schedules checks every 5 minutes. &amp;nbsp;This doesn't really
result in high resolution metrics and is often used as a point of
critique. &amp;nbsp;Keep this in mind when you define a Graphite retention
policy. &amp;nbsp;In the example configuration we use&amp;nbsp;&lt;em&gt;nagios&lt;/em&gt; as a prefix
(line 30), so you could use a Whisper retention policy similar to:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
[nagios]
priority = 100
pattern = ^nagios\.
retentions = 300:2016
&lt;/pre&gt;
&lt;p&gt;Make sure the Nagios execution interval corresponds properly to
the&amp;nbsp;&lt;em&gt;retentions&lt;/em&gt;&amp;nbsp;parameter to prevent gaps.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="conclusion"&gt;
&lt;h2&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;We have covered how to setup Metricfactory to consume metric data from
ModGearman and submit that to Graphite. &amp;nbsp;We covered in detail how data
changes when traveling through the different modules to get a better
understanding of the whole process.&lt;/p&gt;
&lt;/div&gt;
</summary><category term="monitoringlove"></category><category term="graphite"></category><category term="metricfactory"></category><category term="metrics"></category></entry><entry><title>Testing Graphite with MetricFactory</title><link href="http://smetj.net/testing-graphite-with-metricfactory.html" rel="alternate"></link><updated>2013-04-28T22:14:00+02:00</updated><author><name>smetj</name></author><id>tag:smetj.net,2013-04-28:testing-graphite-with-metricfactory.html</id><summary type="html">&lt;div class="section" id="this-article-is-superseded"&gt;
&lt;h2&gt;&lt;strong&gt;This article is superseded&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;Read &lt;a class="reference external" href="http://smetj.net/testing-graphite-with-metricfactory-revisited.html"&gt;Testing Graphite with MetricFactory revisited&lt;/a&gt; instead.&lt;/p&gt;
&lt;p&gt;&lt;/p&gt;
&lt;p&gt;Graphite is great. &amp;nbsp;Not only because it's a great piece of software but
also because of the community around it which brings forth all kinds of
metrics goodness. &amp;nbsp;Although it's pretty straightforward to get Graphite
up and running on one node, it gets a bit more complex to get it up and
running in a clustered/sharded/federated mode. &amp;nbsp;I found &lt;a class="reference external" href="http://bitprophet.org/blog/2013/03/07/graphite/"&gt;Jeff
Forcier's Clustering Graphite&lt;/a&gt; and &lt;a class="reference external" href="http://rcrowley.org/articles/federated-graphite.html"&gt;Richard Crowley's Federated
Graphite&lt;/a&gt;&amp;nbsp;to be very helpful. &amp;nbsp;Once you have your clustered Graphite
setup up and running you might want to test its behavior and get
acquainted with its different settings and modules before going to
production. &amp;nbsp;That's where &lt;a class="reference external" href="https://github.com/smetj/metricfactory"&gt;Metricfactory&lt;/a&gt;&amp;nbsp;might help you out.&lt;/p&gt;
&lt;p&gt;Metricfactory is a modular framework based on &lt;a class="reference external" href="https://github.com/smetj/wishbone"&gt;Wishbone&lt;/a&gt; aimed to
quickly assemble servers which process metrics in one way or the other.
&amp;nbsp;So why not use it to generate random metrics and write them to Graphite
in a controlled way? &amp;nbsp;With this article I would like to take you through
a couple of use cases.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="installation"&gt;
&lt;h2&gt;Installation&lt;/h2&gt;
&lt;p&gt;Installing metricfactory is a matter of checking out the project from
Git and running the installer. &amp;nbsp;All dependencies should be downloaded
automatically.&lt;/p&gt;
&lt;pre class="literal-block"&gt;
$ git clone https://github.com/smetj/metricfactory
$ cd metricfactory
$ sudo python setup.py install
&lt;/pre&gt;
&lt;p&gt;We will also require some extra &lt;a class="reference external" href="https://github.com/smetj/wishboneModules"&gt;Wishbone modules&lt;/a&gt;:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
$ sudo easy_install wb_tippingbucket
$ sudo easy_install wb_tcpclient
&lt;/pre&gt;
&lt;p&gt;One or more of following packages might be required to successfully
finish the install:&lt;/p&gt;
&lt;blockquote&gt;
gcc, gcc-c++, make, python-devel, Cython&lt;/blockquote&gt;
&lt;p&gt;Once installed you can execute following command:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
$ metricfactory list
&lt;/pre&gt;
&lt;p&gt;That should return a list of all available modules. &amp;nbsp;You should see at
least TCPClient, TippingBucket, Hammer and Graphite.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="bootstrap"&gt;
&lt;h2&gt;Bootstrap&lt;/h2&gt;
&lt;p&gt;Starting Metricfactory requires a bootstrap file. &amp;nbsp;A bootstrap file is a
JSON formatted file containing the configuration of which modules to
initiate and which path events will follow through these module
instances.&lt;/p&gt;
&lt;p&gt;A base bootstrap file you can found &lt;a class="reference external" href="https://github.com/smetj/experiments/blob/master/metricfactory/hammerGraphite/hammer.json"&gt;here&lt;/a&gt;. &amp;nbsp;We will be adapting it to
suit our needs. &amp;nbsp;Going through the content it should give you an idea
what the possibilities are.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="scenario-1-submit-unbuffered-unique-metrics-to-carbon-relay"&gt;
&lt;h2&gt;Scenario 1: Submit unbuffered unique metrics to carbon-relay.&lt;/h2&gt;
&lt;p&gt;Let's say we have 1 carbon-relay instance running which forwards our
metrics to 1 or more carbon instance. &amp;nbsp;We want to verify whether all our
metrics actually arrive. &amp;nbsp;Each metric will be submitted as a separate
TCP connection. &amp;nbsp;This is quite inefficient, we should bundle metrics and
submit them in bulk but for the sake of testing we'll do so.&lt;/p&gt;
&lt;pre class="literal-block"&gt;
{
  &amp;quot;metrics&amp;quot;: {
    &amp;quot;enable&amp;quot;: true,
    &amp;quot;group&amp;quot;: &amp;quot;wishbone.metrics&amp;quot;,
    &amp;quot;interval&amp;quot;: 60,
    &amp;quot;module&amp;quot;: &amp;quot;Log&amp;quot;,
    &amp;quot;variables&amp;quot;: {
    }
  },
  &amp;quot;bootstrap&amp;quot;: {
    &amp;quot;hammer&amp;quot;: {
      &amp;quot;group&amp;quot;: &amp;quot;metricfactory.test&amp;quot;,
      &amp;quot;module&amp;quot;: &amp;quot;Hammer&amp;quot;,
      &amp;quot;variables&amp;quot;: {
        &amp;quot;mode&amp;quot;:&amp;quot;sequential&amp;quot;,
        &amp;quot;total&amp;quot;:0,
        &amp;quot;sleep&amp;quot;:0,
        &amp;quot;host&amp;quot;:100,
        &amp;quot;metric&amp;quot;:100,
        &amp;quot;value&amp;quot;:10000000
      }
    },
    &amp;quot;encodegraphite&amp;quot;: {
      &amp;quot;group&amp;quot;: &amp;quot;metricfactory.encoder&amp;quot;,
      &amp;quot;module&amp;quot;: &amp;quot;Graphite&amp;quot;,
      &amp;quot;variables&amp;quot;: {
        &amp;quot;prefix&amp;quot;:&amp;quot;hammer&amp;quot;
      }
    },
    &amp;quot;buffer&amp;quot;: {
      &amp;quot;group&amp;quot;: &amp;quot;wishbone.module&amp;quot;,
      &amp;quot;module&amp;quot;: &amp;quot;TippingBucket&amp;quot;,
      &amp;quot;variables&amp;quot;: {
        &amp;quot;events&amp;quot;: 100,
        &amp;quot;age&amp;quot;: 10
      }
    },
    &amp;quot;tcpout&amp;quot;: {
      &amp;quot;group&amp;quot;: &amp;quot;wishbone.iomodule&amp;quot;,
      &amp;quot;module&amp;quot;: &amp;quot;TCPClient&amp;quot;,
      &amp;quot;variables&amp;quot;: {
        &amp;quot;pool&amp;quot;: [&amp;quot;graphite-001:2013&amp;quot;]
      }
    }
  },
  &amp;quot;routingtable&amp;quot;: {
    &amp;quot;hammer.inbox&amp;quot;: [ &amp;quot;encodegraphite.inbox&amp;quot; ],
    &amp;quot;encodegraphite.outbox&amp;quot;: [ &amp;quot;tcpout.inbox&amp;quot; ]
  }
}
&lt;/pre&gt;
&lt;p&gt;The hammer module (line 11) is the module which actually generates the
metrics. &amp;nbsp;We initialize the module in sequential mode (line 15). &amp;nbsp;That
means each individual metric is unique in terms of
&lt;em&gt;hostname.metricname&lt;/em&gt;. &amp;nbsp;The amount of metrics to generate is determined
by the host (line 18) and metric (line 19) variables. &amp;nbsp;This means we're
generating 100 unique metrics for 100 different nodes resulting into a
total of 10000 metrics.&lt;/p&gt;
&lt;p&gt;The routing table (line 46) tells us events are travelling through the
modules in following order: hammer -&amp;gt; encodegraphite -&amp;gt; tcpout. &amp;nbsp;The
tcpout module (line 38) submits the metrics over TCP to the destination
defined with the pool variable (line 42).&lt;/p&gt;
&lt;p&gt;The buffer module (line 30) is initialized but not included in our
routing table. &amp;nbsp;That means it's not processing any metrics for the
moment. &amp;nbsp;We will come back to that in one of the following scenarios.&lt;/p&gt;
&lt;p&gt;Start a metricfactory in the foreground using following command:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
$ metricfactory debug --config hammer.json
&lt;/pre&gt;
&lt;p&gt;You can stop metricfactory by pressing CTRL+C.&lt;/p&gt;
&lt;p&gt;With this particular setup metricfactory will create 1 TCP connection
per metric. &amp;nbsp;So it might take a while until all metrics are actually
submitted. &amp;nbsp;Depending on the available resources your mileage may vary.&lt;/p&gt;
&lt;p&gt;&lt;a class="reference external" href="pics/graphite1.png"&gt;&lt;img alt="graphite1" src="pics/graphite1.png" /&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;When reviewing the self generated Graphite metrics we can see we
actually have received 10000 metrics.&lt;/p&gt;
&lt;p&gt;When you have more than one carbon-relay server you can extend the
pool variable (line 42) accordingly.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="scenario-2-submit-buffered-unique-metrics-to-carbon-relay"&gt;
&lt;h2&gt;Scenario 2: Submit buffered unique metrics to carbon-relay.&lt;/h2&gt;
&lt;p&gt;You might want to limit the number of connections by grouping metrics
and submit them in bulk to carbon-relay. &amp;nbsp;We have already initialized
the buffer module (line 30). &amp;nbsp;The only thing left compared to our
previous scenario is to include the buffer module in our &lt;em&gt;routingtable&lt;/em&gt;
section (line 48-49).&lt;/p&gt;
&lt;pre class="literal-block"&gt;
{
  &amp;quot;metrics&amp;quot;: {
    &amp;quot;enable&amp;quot;: true,
    &amp;quot;group&amp;quot;: &amp;quot;wishbone.metrics&amp;quot;,
    &amp;quot;interval&amp;quot;: 60,
    &amp;quot;module&amp;quot;: &amp;quot;Log&amp;quot;,
    &amp;quot;variables&amp;quot;: {
    }
  },
  &amp;quot;bootstrap&amp;quot;: {
    &amp;quot;hammer&amp;quot;: {
      &amp;quot;group&amp;quot;: &amp;quot;metricfactory.test&amp;quot;,
      &amp;quot;module&amp;quot;: &amp;quot;Hammer&amp;quot;,
      &amp;quot;variables&amp;quot;: {
        &amp;quot;mode&amp;quot;:&amp;quot;sequential&amp;quot;,
        &amp;quot;total&amp;quot;:0,
        &amp;quot;sleep&amp;quot;:0,
        &amp;quot;host&amp;quot;:100,
        &amp;quot;metric&amp;quot;:100,
        &amp;quot;value&amp;quot;:10000000
      }
    },
    &amp;quot;encodegraphite&amp;quot;: {
      &amp;quot;group&amp;quot;: &amp;quot;metricfactory.encoder&amp;quot;,
      &amp;quot;module&amp;quot;: &amp;quot;Graphite&amp;quot;,
      &amp;quot;variables&amp;quot;: {
        &amp;quot;prefix&amp;quot;:&amp;quot;hammer&amp;quot;
      }
    },
    &amp;quot;buffer&amp;quot;: {
      &amp;quot;group&amp;quot;: &amp;quot;wishbone.module&amp;quot;,
      &amp;quot;module&amp;quot;: &amp;quot;TippingBucket&amp;quot;,
      &amp;quot;variables&amp;quot;: {
        &amp;quot;events&amp;quot;: 100,
        &amp;quot;age&amp;quot;: 10
      }
    },
    &amp;quot;tcpout&amp;quot;: {
      &amp;quot;group&amp;quot;: &amp;quot;wishbone.iomodule&amp;quot;,
      &amp;quot;module&amp;quot;: &amp;quot;TCPClient&amp;quot;,
      &amp;quot;variables&amp;quot;: {
        &amp;quot;pool&amp;quot;: [&amp;quot;graphite-001:2013&amp;quot;]
      }
    }
  },
  &amp;quot;routingtable&amp;quot;: {
    &amp;quot;hammer.inbox&amp;quot;: [ &amp;quot;encodegraphite.inbox&amp;quot; ],
    &amp;quot;encodegraphite.outbox&amp;quot;: [ &amp;quot;buffer.inbox&amp;quot; ],
    &amp;quot;buffer.outbox&amp;quot;: [ &amp;quot;tcpout.inbox&amp;quot; ]
  }
}
&lt;/pre&gt;
&lt;p&gt;The events variable (line 34) makes the buffer flush when 100 events are
available. &amp;nbsp;The age variable (line 35) make the buffer flush when the
last added metric added is X seconds old. &amp;nbsp;With this scenario we would
only require 10 TCP connections compared to 10000 to submit the same
number of metrics.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="scenario-3-generate-a-constant-stream-of-random-metrics"&gt;
&lt;h2&gt;Scenario 3: Generate a constant stream of random metrics.&lt;/h2&gt;
&lt;p&gt;To generate a continuous stream of random metrics we can set the &lt;em&gt;mode&lt;/em&gt;
variable (line 15) to random. &amp;nbsp;This gives a different meaning to the
host (line 18) and metric (line 19) variables. &amp;nbsp;They now become for each
metric the maximum value of a random integer to choose from starting
from 0. &amp;nbsp;Hostnames will have the format &lt;em&gt;host_1234&lt;/em&gt; and metrics
&lt;em&gt;metric_1234.&lt;/em&gt;&amp;nbsp; Depending upon your specific needs, you might want to
choose a higher value to avoid duplicate values being generated.&lt;/p&gt;
&lt;pre class="literal-block"&gt;
{
  &amp;quot;metrics&amp;quot;: {
    &amp;quot;enable&amp;quot;: true,
    &amp;quot;group&amp;quot;: &amp;quot;wishbone.metrics&amp;quot;,
    &amp;quot;interval&amp;quot;: 60,
    &amp;quot;module&amp;quot;: &amp;quot;Log&amp;quot;,
    &amp;quot;variables&amp;quot;: {
    }
  },
  &amp;quot;bootstrap&amp;quot;: {
    &amp;quot;hammer&amp;quot;: {
      &amp;quot;group&amp;quot;: &amp;quot;metricfactory.test&amp;quot;,
      &amp;quot;module&amp;quot;: &amp;quot;Hammer&amp;quot;,
      &amp;quot;variables&amp;quot;: {
        &amp;quot;mode&amp;quot;:&amp;quot;random&amp;quot;,
        &amp;quot;total&amp;quot;:0,
        &amp;quot;sleep&amp;quot;:0,
        &amp;quot;host&amp;quot;:1000,
        &amp;quot;metric&amp;quot;:1000,
        &amp;quot;value&amp;quot;:10000000
      }
    },
    &amp;quot;encodegraphite&amp;quot;: {
      &amp;quot;group&amp;quot;: &amp;quot;metricfactory.encoder&amp;quot;,
      &amp;quot;module&amp;quot;: &amp;quot;Graphite&amp;quot;,
      &amp;quot;variables&amp;quot;: {
        &amp;quot;prefix&amp;quot;:&amp;quot;hammer&amp;quot;
      }
    },
    &amp;quot;buffer&amp;quot;: {
      &amp;quot;group&amp;quot;: &amp;quot;wishbone.module&amp;quot;,
      &amp;quot;module&amp;quot;: &amp;quot;TippingBucket&amp;quot;,
      &amp;quot;variables&amp;quot;: {
        &amp;quot;events&amp;quot;: 100,
        &amp;quot;age&amp;quot;: 10
      }
    },
    &amp;quot;tcpout&amp;quot;: {
      &amp;quot;group&amp;quot;: &amp;quot;wishbone.iomodule&amp;quot;,
      &amp;quot;module&amp;quot;: &amp;quot;TCPClient&amp;quot;,
      &amp;quot;variables&amp;quot;: {
        &amp;quot;pool&amp;quot;: [&amp;quot;graphite-001:2013&amp;quot;]
      }
    }
  },
  &amp;quot;routingtable&amp;quot;: {
    &amp;quot;hammer.inbox&amp;quot;: [ &amp;quot;encodegraphite.inbox&amp;quot; ],
    &amp;quot;encodegraphite.outbox&amp;quot;: [ &amp;quot;buffer.inbox&amp;quot; ],
    &amp;quot;buffer.outbox&amp;quot;: [ &amp;quot;tcpout.inbox&amp;quot; ]
  }
}
&lt;/pre&gt;
&lt;p&gt;The sleep variable (line 17) determines how much time to wait between
generating each metric. That might be useful when you want to limit CPU
usage or control the interval between metrics. A value of 0 means
Metricfactory will drain your CPU trying to produce as much as possible.
Setting a value of 1 means one metric will be produced every second.
&amp;nbsp;When&amp;nbsp;you notice Metricfactory gradually consumes all memory available
that means data is produced at a higher rate than you can submit to
Graphite. In that case you might want to raise the events variable (line
34) which allows you to submit larger chunks of data per connection.&lt;/p&gt;
&lt;p&gt;&lt;img alt="graphite3" src="pics/graphite3.png" /&gt;&lt;/p&gt;
&lt;p&gt;&lt;a class="reference external" href="http://smetj.net/2013/04/28/testing-graphite-with-metricfactory/graphite2/"&gt;The difference in Graphite throughput by changing the buffer
events variable (line 34) from 100 to 1000.&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Depending on your settings Metricfactory can generate a significant
amount of metrics. &amp;nbsp;You could even raise that by starting multiple
parallel processes:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
$ metricfactory debug --config hammer.json --instances 4
&lt;/pre&gt;
&lt;p&gt;This will start 4 parallel processes each executing exactly the same.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="conclusion"&gt;
&lt;h2&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;Generating a predictable number of metrics can be practical to verify whether
your Graphite setup behaves as expected under different scenarios. &amp;nbsp;It becomes
more&amp;nbsp;meaningful&amp;nbsp;if you have a more complex environment with a number of
relays, sharding and duplication policies. &amp;nbsp;By generating large batches of
continuous&amp;nbsp;data with different sizing it's possible to get an idea about the
throughput of your Graphite setup.&lt;/p&gt;
&lt;/div&gt;
</summary><category term="monitoringlove"></category><category term="graphite"></category><category term="metricfactory"></category><category term="python"></category></entry><entry><title>Consume, process and produce data with Wishbone and RabbitMQ</title><link href="http://smetj.net/consume-process-and-produce-data-with-wishbone-and-rabbitmq.html" rel="alternate"></link><updated>2013-01-29T22:07:00+01:00</updated><author><name>smetj</name></author><id>tag:smetj.net,2013-01-29:consume-process-and-produce-data-with-wishbone-and-rabbitmq.html</id><summary type="html">&lt;p&gt;When I first came in touch with the &lt;a class="reference external" href="http://en.wikipedia.org/wiki/Advanced_Message_Queuing_Protocol"&gt;messaging&lt;/a&gt;&amp;nbsp;concept&amp;nbsp;it was some
kind of a revelation. &amp;nbsp;Ever since many solutions I work on involve
message brokers one way or the other. &amp;nbsp;Because of that, a design pattern
occurred hence the need for a Python framework allowing me to easily
write solutions to interact with messaging based setups. &amp;nbsp;&lt;a class="reference external" href="https://github.com/smetj/wishbone"&gt;Wishbone&lt;/a&gt;&amp;nbsp;is
a Python framework which simplifies writing coroutine event pipelines.
&amp;nbsp;Wishbone is a framework in which you can load and connect multiple
modules in order to come to a tailored solution.
Although Wishbone's scope is larger than that, I would like to
demonstrate how easy it is to write a daemon which consumes and
processes messages from &lt;em&gt;`RabbitMQ`_&lt;/em&gt;.&lt;/p&gt;
&lt;div class="section" id="preparation"&gt;
&lt;h2&gt;Preparation&lt;/h2&gt;
&lt;p&gt;If you want to be able to execute the examples throughout this article
you should have a RabbitMQ (with the&amp;nbsp;&lt;a class="reference external" href="http://www.rabbitmq.com/management.html"&gt;management plugin&lt;/a&gt;)&amp;nbsp;instance&amp;nbsp;up
and running and install the Wishbone library. &amp;nbsp;There is some great
RabbitMQ documentation out there explaining you how to install a basic
stand-alone instance.&lt;/p&gt;
&lt;div class="section" id="installing-wishbone"&gt;
&lt;h3&gt;Installing Wishbone&lt;/h3&gt;
&lt;p&gt;Installing the Wishbone library can be done through&amp;nbsp;&lt;a class="reference external" href="http://pypi.python.org/pypi/wishbone/0.2.2"&gt;Cheeseshop&lt;/a&gt;&amp;nbsp;or
from&amp;nbsp;&lt;a class="reference external" href="https://github.com/smetj/wishbone"&gt;GitHub&lt;/a&gt;:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
[vagrant&amp;#64;wishbone ~]$ sudo easy_install wishbone
&lt;/pre&gt;
&lt;p&gt;&lt;em&gt;On centos I required:&amp;nbsp;gcc-c++ snappy-devel python-dev Cython
libev-devel&lt;/em&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="rabbitmq"&gt;
&lt;h3&gt;RabbitMQ&lt;/h3&gt;
&lt;p&gt;Within RabbitMQ let's create 2 queues we're going to use in this
article&lt;/p&gt;
&lt;p&gt;Visit the web based RabbitMQ management application listening on port
55672 and create 3 queues:&lt;/p&gt;
&lt;blockquote&gt;
&lt;em&gt;wishbone_in, wishbone_even, wishbone_uneven&lt;/em&gt;&lt;/blockquote&gt;
&lt;p&gt;RabbitMQ Management Interface&lt;/p&gt;
&lt;blockquote&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;You can&amp;nbsp;achieve the same by using the rabbitmqadmin tool.&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="creating-a-wishbone-setup"&gt;
&lt;h2&gt;Creating a Wishbone Setup&lt;/h2&gt;
&lt;p&gt;Now we have our test environment up and running lets create our first
daemon.&lt;/p&gt;
&lt;div class="section" id="challenge"&gt;
&lt;h3&gt;Challenge&lt;/h3&gt;
&lt;p&gt;Create a daemon which consumes messages from the wishbone_in queue.
&amp;nbsp;Each submitted message contains an integer. &amp;nbsp;If this integer is even we
submit the message to the &lt;em&gt;wishbone_uneven&lt;/em&gt; queue while the messages
with even values should end up in the &lt;em&gt;wishbone_even&lt;/em&gt; queue.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="make-a-server"&gt;
&lt;h3&gt;Make a server&lt;/h3&gt;
&lt;p&gt;Wishbone is made to easily write daemons. &amp;nbsp;It comes with the required
functionality to minimize all the work which goes along with that:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
#!/usr/bin/env python
from wishbone.server import BootStrap
if __name__ == '__main__':
    BootStrap(name=&amp;quot;BrokerTest&amp;quot;,
        description=&amp;quot;This setup is just an example.&amp;quot;,
        version=&amp;quot;0.1&amp;quot;,
        author=&amp;quot;Your name&amp;quot;
    )
&lt;/pre&gt;
&lt;p&gt;Save the content to a file called &amp;quot;brokertest&amp;quot; and make it executable.
When executing you will get:&lt;/p&gt;
&lt;p&gt;&lt;a class="reference external" href="pics/cli11.png"&gt;&lt;img alt="cli1" src="pics/cli11-300x188.png" /&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;And that's it! You have a WishBone server available. &amp;nbsp;Granted it doesn't
do anything at all at this stage but that's what we'll cover in the next
paragraph.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="modules"&gt;
&lt;h3&gt;Modules&lt;/h3&gt;
&lt;p&gt;Wishbone has the concept of &lt;a class="reference external" href="http://smetj.github.com/wishbone/docs/build/html/introduction.html#wishbone-modules"&gt;modules&lt;/a&gt;. &amp;nbsp;A module is a piece of code
which is plugged into the Wishbone framework which takes data in and
pushes data out. &amp;nbsp;Our WishBone server needs to know which modules to
load, how to initialize them and how to tie them together into a
workflow. &amp;nbsp;This is done using a &lt;a class="reference external" href="http://smetj.github.com/wishbone/docs/build/html/bootstrapfiles.html"&gt;bootstrap&lt;/a&gt; file which is loaded using
the --config option. &amp;nbsp;A bootstrap file is mandatory, otherwise your
Wishbone application is just an empty shell.&lt;/p&gt;
&lt;div class="section" id="use-an-existing-module-broker"&gt;
&lt;h4&gt;Use an existing module: Broker&lt;/h4&gt;
&lt;p&gt;Wishbone comes with a bunch of already available modules. One of them
is the&amp;nbsp;&lt;a class="reference external" href="http://smetj.github.com/wishbone/docs/build/html/iomodules.html#wishbone.iomodules.broker.Broker"&gt;Broker&lt;/a&gt;&amp;nbsp;module which allows you to get RabbitMQ messages in
and out of Wishbone.&lt;/p&gt;
&lt;p&gt;We are going to initialize the broker module with following
parameters:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
... snip ...
&amp;quot;broker&amp;quot;:{
         &amp;quot;module&amp;quot;:&amp;quot;wishbone.iomodules.broker&amp;quot;,
         &amp;quot;class&amp;quot;:&amp;quot;Broker&amp;quot;,
         &amp;quot;variables&amp;quot;:{
            &amp;quot;host&amp;quot;:&amp;quot;sandbox&amp;quot;,
            &amp;quot;vhost&amp;quot;:&amp;quot;/&amp;quot;,
            &amp;quot;username&amp;quot;:&amp;quot;guest&amp;quot;,
            &amp;quot;password&amp;quot;:&amp;quot;guest&amp;quot;,
            &amp;quot;consume_queue&amp;quot;:&amp;quot;wishbone_in&amp;quot;,
            &amp;quot;prefetch_count&amp;quot;:200,
            &amp;quot;no_ack&amp;quot;:false,
            &amp;quot;delivery_mode&amp;quot;:2
         }
}
... snip ...
&lt;/pre&gt;
&lt;p&gt;Most of the parameters speak for themselves. &amp;nbsp;Have a look at the module
documentation page for details.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="create-a-new-module-evenuneven"&gt;
&lt;h4&gt;Create a new module: EvenUneven&lt;/h4&gt;
&lt;p&gt;A module to determine whether the number is even/uneven is of course
not available out of the box. &amp;nbsp;We're going to create this one ourselves.&lt;/p&gt;
&lt;p&gt;WishBone includes a &amp;nbsp;&lt;a class="reference external" href="https://github.com/smetj/wishbone/blob/master/wishbone/modules/skeleton.py"&gt;skeleton module&lt;/a&gt; which can be used as a
standard to build your new module on.&lt;/p&gt;
&lt;p&gt;The WishBone framework really requires a Python module to load. &amp;nbsp;That
means you should create a directory called &amp;quot;&lt;em&gt;evenuneven&lt;/em&gt;&amp;quot; and paste
the below code into a file called &amp;nbsp;&lt;em&gt;evenuneven/__init__.py&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Wishbone modules are actually regular Python modules. &amp;nbsp;You should really
try to follow the proper guidelines on how to build, package and install
Python modules.&lt;/p&gt;
&lt;pre class="literal-block"&gt;
#!/usr/bin/env python

from wishbone.toolkit import PrimitiveActor

class EvenUneven(PrimitiveActor):
    '''**An example Wishbone module which verifies if the data submitted
    is even or uneven.**''

    Parameters:

        - name (str):    The instance name when initiated.

    Queues:

        - inbox:    Incoming events.
        - outbox:   Outgoing events.
    '''

    def __init__(self, name):
        PrimitiveActor.__init__(self, name)

    def consume(self,doc):
        if int(doc[&amp;quot;data&amp;quot;])%2 == 0:
            self.logging.info('I received an even message.')

            doc[&amp;quot;header&amp;quot;][&amp;quot;broker_exchange&amp;quot;]=''
            doc[&amp;quot;header&amp;quot;][&amp;quot;broker_key&amp;quot;]='wishbone_even'
        else:
            self.logging.info('I received an uneven message.')

            doc[&amp;quot;header&amp;quot;][&amp;quot;broker_exchange&amp;quot;]=''
            doc[&amp;quot;header&amp;quot;][&amp;quot;broker_key&amp;quot;]='wishbone_uneven'

        self.putData(doc)

    def shutdown(self):
        self.logging.info('Shutdown')
&lt;/pre&gt;
&lt;p&gt;Once initiated, this class will run as a (green)thread within the
Wishbone framework. The initialized instance of the class will
automatically &amp;quot;inherit&amp;quot; an &lt;em&gt;inbox&lt;/em&gt; and &lt;em&gt;outbox&lt;/em&gt; queue. All messages
arriving to the &lt;em&gt;inbox&lt;/em&gt; queue will automatically be &amp;quot;consumed&amp;quot; by the
&lt;em&gt;consume()&lt;/em&gt; function. The framework will do that for you, so you don't
need to worry about that. &amp;nbsp;Once done processing the data it can be place
into the class's outbox queue, which is done using the &lt;em&gt;putData()&lt;/em&gt;
function (line 34).&lt;/p&gt;
&lt;p&gt;Each document flowing through the framework has following format:&lt;/p&gt;
&lt;blockquote&gt;
{&amp;quot;header&amp;quot;:{}, &amp;quot;data&amp;quot;:object }&lt;/blockquote&gt;
&lt;p&gt;We're extending the &amp;quot;header&amp;quot; part of the document with 2 variables:
&amp;quot;&lt;em&gt;broker_exchange&lt;/em&gt;&amp;quot; and &amp;quot;&lt;em&gt;broker_key&lt;/em&gt;&amp;quot;. When this message will
arrive back into the broker module it will know to which exchange and
queue to submit the document to.&lt;/p&gt;
&lt;p&gt;This simple module does not require any variables when initialized, so
the bootstrap file section to initialize this module would look like:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
... snip ...
&amp;quot;evenuneven&amp;quot;:{
         &amp;quot;module&amp;quot;:&amp;quot;evenuneven&amp;quot;,
         &amp;quot;class&amp;quot;:&amp;quot;EvenUneven&amp;quot;,
         &amp;quot;variables&amp;quot;:{
         }
}
... snip ...
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="bootstrap-file"&gt;
&lt;h3&gt;Bootstrap file&lt;/h3&gt;
&lt;p&gt;The bootstrap file (which is defined through the &amp;nbsp;--config option) tells
the WishBone server which modules to load and how the data flows through
the modules.&lt;/p&gt;
&lt;p&gt;The complete bootstrap for our example setup would look like this:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
{
   &amp;quot;system&amp;quot;:{
      &amp;quot;metrics&amp;quot;:true,
      &amp;quot;metrics_interval&amp;quot;:10,
      &amp;quot;metrics_dst&amp;quot;:&amp;quot;logging&amp;quot;
   },
   &amp;quot;bootstrap&amp;quot;:{
      &amp;quot;broker&amp;quot;:{
         &amp;quot;module&amp;quot;:&amp;quot;wishbone.iomodules.broker&amp;quot;,
         &amp;quot;class&amp;quot;:&amp;quot;Broker&amp;quot;,
         &amp;quot;variables&amp;quot;:{
            &amp;quot;host&amp;quot;:&amp;quot;sandbox&amp;quot;,
            &amp;quot;vhost&amp;quot;:&amp;quot;/&amp;quot;,
            &amp;quot;username&amp;quot;:&amp;quot;guest&amp;quot;,
            &amp;quot;password&amp;quot;:&amp;quot;guest&amp;quot;,
            &amp;quot;consume_queue&amp;quot;:&amp;quot;wishbone_in&amp;quot;,
            &amp;quot;prefetch_count&amp;quot;:200,
            &amp;quot;no_ack&amp;quot;:true,
            &amp;quot;delivery_mode&amp;quot;:2
         }
      },
      &amp;quot;evenuneven&amp;quot;:{
         &amp;quot;module&amp;quot;:&amp;quot;evenuneven&amp;quot;,
         &amp;quot;class&amp;quot;:&amp;quot;EvenUneven&amp;quot;,
         &amp;quot;variables&amp;quot;:{
         }
      }
   },
   &amp;quot;routingtable&amp;quot;:{
      &amp;quot;broker.inbox&amp;quot;:[
         &amp;quot;evenuneven.inbox&amp;quot;
      ],
      &amp;quot;evenuneven.outbox&amp;quot;:[
         &amp;quot;broker.outbox&amp;quot;
      ]
   }
}
&lt;/pre&gt;
&lt;p&gt;The &lt;em&gt;system&lt;/em&gt;&amp;nbsp;section of the bootstrap file allows you to control
Wishbone framework specific items. &amp;nbsp;Currently only options related to
metrics are available.&lt;/p&gt;
&lt;p&gt;The&amp;nbsp;&lt;em&gt;bootstrap&lt;/em&gt; section allows you to initialize the modules and
assign them to an instance name, which is in this case &amp;quot;&lt;em&gt;broker&lt;/em&gt;&amp;quot; and
&amp;quot;&lt;em&gt;evenuneven&lt;/em&gt;&amp;quot;.&lt;/p&gt;
&lt;p&gt;The&amp;nbsp;&lt;em&gt;routingtable&lt;/em&gt; section allows you to connect the instance queues
to each other &amp;nbsp;in order to determine the application's dataflow.
&amp;nbsp;Normally one connects the &lt;em&gt;outbox&lt;/em&gt; queue to the &lt;em&gt;inbox&lt;/em&gt; queue. &amp;nbsp;But in
case of an IOmodule (which the broker module is) the data coming from
the outside world arrives&amp;nbsp;&lt;em&gt;inbox&lt;/em&gt; queue and the data going to the
outside world should go to the&amp;nbsp;&lt;em&gt;outbox&lt;/em&gt; queue.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="start-your-server-and-test"&gt;
&lt;h3&gt;Start your server and test.&lt;/h3&gt;
&lt;p&gt;To start your server and prevent it to fork into the background you
should do something like:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
[vagrant&amp;#64;wishbone files]$ ./brokertest debug --config brokertest.json --loglevel debug
&lt;/pre&gt;
&lt;p&gt;You should get a similar output to following screenshot:&lt;/p&gt;
&lt;p&gt;&lt;a class="reference external" href="pics/cli2.png"&gt;&lt;img alt="cli2" src="pics/cli2-300x50.png" /&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Now submit a message containing the number &amp;quot;&lt;em&gt;100&lt;/em&gt;&amp;quot; through the
RabbitMQ broker management interface into the &lt;em&gt;wishbone_in&lt;/em&gt; queue.&lt;/p&gt;
&lt;p&gt;&lt;a class="reference external" href="pics/rabbit2.png"&gt;&lt;img alt="rabbit2" src="pics/rabbit2-231x300.png" /&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;If all went well your Wishbone application should create a log entry
about the data you just submitted:&lt;/p&gt;
&lt;p&gt;&lt;a class="reference external" href="pics/cli3.png"&gt;&lt;img alt="cli3" src="pics/cli3-300x56.png" /&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Have a look to the &lt;em&gt;wishbone_even&lt;/em&gt; queue your message should be arrived
there.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="conclusion"&gt;
&lt;h2&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;Although the the example as such isn't that spectacular and it only
scratches the surface of the possibilities it hopefully shows you how
easy it is to create a &amp;nbsp;Python based server which interacts with
RabbitMQ. &amp;nbsp;The Wishbone library also includes other IO modules. &amp;nbsp;Have a
look at my &lt;a class="reference external" href="https://github.com/smetj/experiments/tree/master/python/wishbone"&gt;experiments repository&lt;/a&gt; for more examples of Wishbone
setups.&lt;/p&gt;
&lt;/div&gt;
</summary><category term="amqp"></category><category term="python"></category><category term="rabbitmq"></category><category term="wishbone"></category></entry><entry><title>Using MetricFactory to get Hadoop metrics into Graphite.</title><link href="http://smetj.net/using-metricfactory-to-get-hadoop-metrics-into-graphite.html" rel="alternate"></link><updated>2013-01-10T00:40:00+01:00</updated><author><name>smetj</name></author><id>tag:smetj.net,2013-01-10:using-metricfactory-to-get-hadoop-metrics-into-graphite.html</id><summary type="html">&lt;p&gt;Without metrics we're flying blind and that's very much the case with
&amp;nbsp;&lt;a class="reference external" href="http://hadoop.apache.org/"&gt;Hadoop&lt;/a&gt;. &amp;nbsp;Hadoop is a well known framework to build reliable,
scalable&amp;nbsp;and distributed computing clusters. &amp;nbsp;The Hadoop framework &amp;nbsp;is a
complex environment which &amp;quot;out of the box&amp;quot; hardly offers any metrics
oversight on how the different components are performing.&lt;/p&gt;
&lt;p&gt;&lt;a class="reference external" href="http://graphite.wikidot.com/"&gt;Graphite&lt;/a&gt;&amp;nbsp;is king of the hill when it comes to graphing metrics with
open source. &amp;nbsp;Hadoop doesn't support Graphite's data format and way to
submit metrics, however it does natively support
the&amp;nbsp;&lt;a class="reference external" href="http://ganglia.sourceforge.net/"&gt;Ganglia&lt;/a&gt;&amp;nbsp;graphing framework. &amp;nbsp;That is something we are going to
use to our advantage.&lt;/p&gt;
&lt;p&gt;&lt;a class="reference external" href="https://github.com/smetj/metricfactory"&gt;MetricFactory&lt;/a&gt;&amp;nbsp;is a modular tool which allows you to build servers
which can do &amp;quot;stuff&amp;quot; with metrics. &amp;nbsp;In this case &amp;quot;stuff&amp;quot; means accepting
Ganglia metrics, convert and submit them to the Graphite framework.&lt;/p&gt;
&lt;p&gt;The information this blog post is just another way of doing things which
might suit your needs better than any other available options.&lt;/p&gt;
&lt;div class="section" id="hadoop-metrics"&gt;
&lt;h2&gt;Hadoop metrics&lt;/h2&gt;
&lt;p&gt;As we already mentioned Hadoop can generate Ganglia formatted metrics.
&amp;nbsp;Hadoop metrics are controlled by
/etc/hadoop/conf/hadoop-metrics.properties&lt;/p&gt;
&lt;p&gt;You should have at least following entries:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
dfs.class=org.apache.hadoop.metrics.ganglia.GangliaContext31
dfs.period=10
dfs.servers=metricfactory-001
&lt;/pre&gt;
&lt;pre class="literal-block"&gt;
mapred.class=org.apache.hadoop.metrics.ganglia.GangliaContext31
mapred.period=10
mapred.servers=metricfactory-001
&lt;/pre&gt;
&lt;pre class="literal-block"&gt;
jvm.class=org.apache.hadoop.metrics.ganglia.GangliaContext31
jvm.period=10
jvm.servers=metricfactory-001
&lt;/pre&gt;
&lt;pre class="literal-block"&gt;
rpc.class=org.apache.hadoop.metrics.ganglia.GangliaContext31
rpc.period=10
rpc.servers=metricfactory-001
&lt;/pre&gt;
&lt;p&gt;The rpc.period defines the interval to submit metrics. &amp;nbsp;In this case 10
seconds.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="graphite"&gt;
&lt;h2&gt;Graphite&lt;/h2&gt;
&lt;p&gt;The Graphite instance does nothing particular. &amp;nbsp;You can consult the
graphs by visiting following URL:
&lt;a class="reference external" href="http://"&gt;http://&lt;/a&gt;&lt;a class="reference external" href="http://graphite-001/dashboard/"&gt;http://graphite-001/dashboard/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a class="reference external" href="pics/Screenshot-from-2013-01-07-223750.png"&gt;&lt;img alt="Screenshot from 2013-01-07 22:37:50" src="pics/Screenshot-from-2013-01-07-223750-300x150.png" /&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="metricfactory"&gt;
&lt;h2&gt;MetricFactory&lt;/h2&gt;
&lt;p&gt;MetricFactory's setup is controlled through so called &lt;a class="reference external" href="https://github.com/smetj/experiments/tree/master/metricfactory"&gt;bootstrap
files&lt;/a&gt;. &amp;nbsp;These files contain&amp;nbsp;the information on which modules need to
be loaded, how they are initiated and how &amp;nbsp;they are connected to each
other.&lt;/p&gt;
&lt;p&gt;For this scenario we need to have at least:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;a class="reference external" href="https://github.com/smetj/wishboneModules"&gt;UDP input&lt;/a&gt; (The Ganglia metrics come in over UDP).&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="https://github.com/smetj/metricfactory/blob/master/metricfactory/decoder/ganglia.py"&gt;Ganglia decoder&lt;/a&gt;&amp;nbsp;(Deserialize the XDR format into a generic
format.)&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="http://wishbone.readthedocs.org/en/latest/modules.html?highlight=graphite#wishbone.module.Graphite"&gt;Graphite encoder&lt;/a&gt; (Convert the generic format into a Graphite
format.)&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="https://github.com/smetj/wishboneModules"&gt;A TCP client&lt;/a&gt; (Write the metrics into Graphite)&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="section" id="a-small-test"&gt;
&lt;h3&gt;A small test&lt;/h3&gt;
&lt;p&gt;First let's make a small test using &lt;a class="reference external" href="https://github.com/smetj/experiments/blob/master/metricfactory/hadoop2graphite/hadoop2graphite.yaml"&gt;this&lt;/a&gt; bootstrapfile. &amp;nbsp;Instead of
writing the converted data to Graphite, we're going to print it to
STDOUT. &amp;nbsp;Not very useful, although this way we can verify clearly
whether we have data coming in and whether the output format is as we
expect.&lt;/p&gt;
&lt;p&gt;We can start &amp;nbsp;MetricFactory with the debug option so it does not detach
into the background. &amp;nbsp;CTRL-C stops the process again:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
[vagrant&amp;#64;metricfactory-001 ~]$ metricfactory debug --config /home/vagrant/experiments/metricfactory/ganglia2graphite/ganglia2graphite2stdout.json
2013-01-07 22:38:06,150 INFO root: Starting MetricFactory in foreground.
2013-01-07 22:38:06,156 INFO root: Instance #0 started.
2013-01-07 22:38:06,158 INFO root: Started with pids: 3702, 3703
2013-01-07 22:38:06,165 INFO Intance #0:buffer: Initiated.
2013-01-07 22:38:06,168 INFO Intance #0:udpserver: started and listening on port 8649
2013-01-07 22:38:06,170 INFO Intance #0:ganglia: Initiated.
2013-01-07 22:38:06,171 INFO Intance #0:graphite: Initiated.
2013-01-07 22:38:06,172 INFO Intance #0:stdout: Initiated.
2013-01-07 22:38:06,174 INFO Intance #0:buffer: Started.
2013-01-07 22:38:06,174 INFO Intance #0:stdout: Started.
2013-01-07 22:38:06,175 INFO Intance #0:ganglia: Started.
2013-01-07 22:38:06,175 INFO Intance #0:graphite: Started.
0 - systems.hadoop-001.jvm.JobTracker.metrics.gcCount 159 1357598286.52
1 - systems.hadoop-001.jvm.JobTracker.metrics.gcTimeMillis 481 1357598286.52
2 - systems.hadoop-001.jvm.JobTracker.metrics.logError 0 1357598286.52
3 - systems.hadoop-001.jvm.JobTracker.metrics.logFatal 0 1357598286.52
4 - systems.hadoop-001.jvm.JobTracker.metrics.logInfo 57 1357598286.52
5 - systems.hadoop-001.jvm.JobTracker.metrics.logWarn 1 1357598286.52
6 - systems.hadoop-001.jvm.JobTracker.metrics.maxMemoryM 3866.6875 1357598286.52
7 - systems.hadoop-001.jvm.JobTracker.metrics.memHeapCommittedM 15.125 1357598286.52
8 - systems.hadoop-001.jvm.JobTracker.metrics.memHeapUsedM 7.0045853 1357598286.52
9 - systems.hadoop-001.jvm.JobTracker.metrics.memNonHeapCommittedM 23.1875 1357598286.52
10 - systems.hadoop-001.jvm.JobTracker.metrics.memNonHeapUsedM 19.089851 1357598286.52
11 - systems.hadoop-001.jvm.JobTracker.metrics.threadsBlocked 0 1357598286.52
12 - systems.hadoop-001.jvm.JobTracker.metrics.threadsNew 0 1357598286.52
... snip ...
&lt;/pre&gt;
&lt;/div&gt;
&lt;div class="section" id="a-standalone-instance"&gt;
&lt;h3&gt;A standalone instance&lt;/h3&gt;
&lt;p&gt;We can now start to write the metrics into Graphite. &amp;nbsp;For this we
require&amp;nbsp;&lt;a class="reference external" href="https://github.com/smetj/experiments/blob/master/metricfactory/hadoop2graphite/hadoop2graphite.yaml"&gt;a bootstrap file&lt;/a&gt; which &amp;nbsp;actually writes the data into
Graphite:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
[vagrant&amp;#64;metricfactory-001 ~]$ metricfactory debug --config /home/vagrant/experiments/metricfactory/ganglia2graphite/ganglia2graphite.json
&lt;/pre&gt;
&lt;/div&gt;
&lt;div class="section" id="multiple-instances"&gt;
&lt;h3&gt;Multiple instances&lt;/h3&gt;
&lt;p&gt;MetricFactory is build using the Wishbone library, which on its turn
uses Gevent with green threads on top of a libevent loop. &amp;nbsp;Something to
keep in mind when working with greenthreads on a libevent loop is that
they are great to deal with IO bound processing but not with CPU bound
processing. &amp;nbsp;Because of that (cutting corners here) our whole setup runs
inside 1 process which doesn't take advantage of a multiple CPU
architecture. &amp;nbsp;This can become problematic because every time we're
doing a CPU intensive task, the libevent loop stops, something we want
to avoid as much as possible.&lt;/p&gt;
&lt;p&gt;A WishBone based setup can be started with the --instances parameter,
which basically starts a number of identical processes thus taking
advantage of a multiple CPU architecture. In our case however we can not
take advantage of this since we require an UDP listener in our setup
hence we can't have multiple instances bind to that port at the same
time. &amp;nbsp;So let's get creative and&amp;nbsp;split the setup into 2 parts:&lt;/p&gt;
&lt;div class="section" id="a-decoder-with-multiple-instances"&gt;
&lt;h4&gt;A decoder with multiple instances&lt;/h4&gt;
&lt;p&gt;This setup creates 5 parallel instances. &amp;nbsp;Each instance accepts input
from its own Unix domain socket.&lt;/p&gt;
&lt;pre class="literal-block"&gt;
[vagrant&amp;#64;metricfactory-001 ~]$&amp;nbsp;metricfactory debug --config /home/vagrant/experiments/metricfactory/ganglia2graphite/uds-ganglia-graphite.json --instances 5 --pid /tmp/uds-ganglia-graphite.pid
&lt;/pre&gt;
&lt;/div&gt;
&lt;div class="section" id="a-receiver"&gt;
&lt;h4&gt;A receiver&lt;/h4&gt;
&lt;p&gt;Accepts all the data on UDP and distributes that evenly over multiple
decoders each listening on a domain socket.&lt;/p&gt;
&lt;pre class="literal-block"&gt;
[vagrant&amp;#64;metricfactory-001 ~]$ metricfactory debug --config /home/vagrant/experiments/metricfactory/ganglia2graphite/loadbalance-ganglia.json --pid /tmp/loadbalance-ganglia.pid
&lt;/pre&gt;
&lt;p&gt;&lt;em&gt;`The UDSclient module`_ can be initiated with &amp;quot;pool&amp;quot; set to &amp;quot;True&amp;quot;.When
enabled the defined path will be considered a directory containing one
or more Unix domain sockets. The client &amp;quot;round robins&amp;quot; over all domain
sockets found in that directory. Worth to mention is the buffer module,
which buffers the Graphite data and when full submits the batch.&lt;/em&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="conclusion"&gt;
&lt;h2&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;Using this setup we can accept Ganglia metrics over UDP from Hadoop,
convert using multiple parallel processes the metrics to Graphite format
in and submit the converted metrics in batches to Graphite. &amp;nbsp;I'm
planning to add more functionality to MetricFactory. &amp;nbsp;Currently it can
tackle mod_gearman and Ganglia data. &amp;nbsp;Using the examples in this
article you should be able to setup your own MetricFactory based setups
relatively easy. &amp;nbsp;If you require support you can submit a message to the
&lt;a class="reference external" href="https://groups.google.com/forum/?fromgroups#!forum/metricfactory"&gt;MetricFactory mailing list&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
</summary></entry><entry><title>New Year Python Meme 2012</title><link href="http://smetj.net/new-year-python-meme-2012.html" rel="alternate"></link><updated>2012-12-31T14:27:00+01:00</updated><author><name>smetj</name></author><id>tag:smetj.net,2012-12-31:new-year-python-meme-2012.html</id><summary type="html">&lt;p&gt;Following &lt;a class="reference external" href="http://blog.ziade.org/2012/12/23/new-years-python-meme-2012/"&gt;Tarek Ziadé's idea for a 2012 New Year Python Meme&lt;/a&gt; here's
mine&lt;/p&gt;
&lt;p&gt;&lt;/p&gt;
&lt;div class="section" id="what-is-the-coolest-python-application-framework-or-library-you-have-discovered-in-2012"&gt;
&lt;h2&gt;What is the coolest Python application, framework or library you have discovered in 2012?&lt;/h2&gt;
&lt;p&gt;That must be &lt;a class="reference external" href="http://www.gevent.org/"&gt;Gevent&lt;/a&gt;. &amp;nbsp;It's possible I have been&amp;nbsp;dabbling&amp;nbsp;around with
it before 2012, but this year I really got into Gevent. &amp;nbsp;I really like
greenthreads and how Gevent deals with them. &amp;nbsp;When I discovered that, I
just had the urge to rewrite everything again with Gevent and
greenthreads. &amp;nbsp;Gevent really gave a boost to my Python productivity.
&amp;nbsp;Thank you &lt;a class="reference external" href="http://denisbilenko.com/"&gt;Denis Bilenko&lt;/a&gt;!&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="what-new-programming-technique-did-you-learn-in-2012"&gt;
&lt;h2&gt;What new programming technique did you learn in 2012?&lt;/h2&gt;
&lt;p&gt;At a certain point in time we all want to have some sort of
&amp;quot;concurrency&amp;quot; between the different moving parts of the application
we're writing. &amp;nbsp;Processes, threads, async network &amp;nbsp;IO all come with
their own complexities... &amp;nbsp;For me it always boiled down to the fact I
loose oversight of the application pretty quickly once it starts to
expand. &amp;nbsp;Especially when an application is written with many callbacks.
&amp;nbsp;I don't like callbacks. &amp;nbsp;It puts a knot in my brain (and productivity)
whenever I'm working with them. &amp;nbsp;&lt;strong&gt;`I personally prefer clarity over
efficiency`_&lt;/strong&gt;&amp;nbsp;(within reason of course). &amp;nbsp;Keeping this in mind, when
going through the RabbitMQ tutorials and documentation ecosystem I came
across the concepts of &lt;a class="reference external" href="http://en.wikipedia.org/wiki/Message_passing"&gt;message passing&lt;/a&gt; and the &lt;a class="reference external" href="http://en.wikipedia.org/wiki/Actor_model#Fundamental_concepts"&gt;actor model&lt;/a&gt;, this
opened for me a new way of thinking and approach to create solutions to
the problems I'm confronted with. &amp;nbsp;It allows me to visualize and
identify (both mentally as in a diagram) the different components of a
program and the interaction between them and above all avoid the
callback jungle.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="what-is-the-name-of-the-open-source-project-you-contributed-the-most-in-2012-what-did-you-do"&gt;
&lt;h2&gt;What is the name of the open source project you contributed the most in 2012? What did you do?&lt;/h2&gt;
&lt;p&gt;I must admit that I have been pretty much occupied with my own projects
so I haven't really contributed to any projects other than &lt;a class="reference external" href="https://github.com/smetj"&gt;my own&lt;/a&gt;.
&amp;nbsp;Most of my time went into creating the &lt;a class="reference external" href="https://github.com/smetj/wishbone"&gt;WishBone&lt;/a&gt;&amp;nbsp;library. &amp;nbsp;A library
which allows one to create coroutine based event pipeline solutions.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="what-was-the-python-blog-or-website-you-read-the-most-in-2012"&gt;
&lt;h2&gt;What was the Python blog or website you read the most in 2012?&lt;/h2&gt;
&lt;p&gt;Most Python information came through via Twitter. &amp;nbsp;I have recently
discovered &lt;a class="reference external" href="http://www.pythonweekly.com/"&gt;Python Weekly&lt;/a&gt;&amp;nbsp;and &lt;a class="reference external" href="http://pycoders.com/"&gt;Pycoder's weekly&lt;/a&gt;&amp;nbsp;which meanwhile have
proven to be a great source of Python info.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="what-are-the-three-top-things-you-want-to-learn-in-2013"&gt;
&lt;h2&gt;What are the three top things you want to learn in 2013?&lt;/h2&gt;
&lt;p&gt;More than 3 things I would say, but I'll start with this list:&lt;/p&gt;
&lt;ol class="arabic simple"&gt;
&lt;li&gt;Explore and learn the new stuff Python 3.3 brings.&lt;/li&gt;
&lt;li&gt;ZeroMQ and its Python bindings.&lt;/li&gt;
&lt;li&gt;More on metric analysis...&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;div class="section" id="what-are-the-top-software-app-or-lib-you-wish-someone-would-write-in-2013"&gt;
&lt;h2&gt;What are the top software, app or lib you wish someone would write in 2013?&lt;/h2&gt;
&lt;p&gt;A killer bookmark manager in my browser to manage my delicious
bookmarks.&lt;/p&gt;
&lt;/div&gt;
</summary></entry><entry><title>After a long hiatus</title><link href="http://smetj.net/after-a-long-hiatus.html" rel="alternate"></link><updated>2012-09-30T23:46:00+02:00</updated><author><name>smetj</name></author><id>tag:smetj.net,2012-09-30:after-a-long-hiatus.html</id><summary type="html">&lt;p&gt;Finally after finishing a whole bunch of private &amp;quot;projects&amp;quot;, I'm able to
spend some more time again to the &lt;a class="reference external" href="https://github.com/smetj"&gt;various open source projects&lt;/a&gt; I've
been working on until now. &amp;nbsp;I have gathered a whole bunch of new ideas,
processed good and bad feedback, experienced that some ideas just don't
work out while others are quite encouraging.&lt;/p&gt;
&lt;p&gt;I haven't been totally unproductive though. &amp;nbsp;I have been able to spend
time writing the Python&amp;nbsp;&lt;a class="reference external" href="https://github.com/smetj/wishbone"&gt;Wishbone&lt;/a&gt;&amp;nbsp;library. &amp;nbsp;The Wishbone library is
a lightweight way of writing multiple gevent based parallel processes
which connect multiple modules through an internal message passing
interface into a clean workflow.&lt;/p&gt;
&lt;p&gt;I have also created &lt;a class="reference external" href="https://github.com/smetj/monfs"&gt;MonFS&lt;/a&gt;&amp;nbsp;which is a Fuse filesystem plugin allowing
you to store your Nagios (or compatible) configuration into a MongoDB
and mount that database as a read-only filesystem containing Nagios
configuration files.&lt;/p&gt;
&lt;p&gt;The projects which currently gets most attention is &lt;a class="reference external" href="https://github.com/smetj/molog/tree/wishbone_based"&gt;MoLog&lt;/a&gt;. &amp;nbsp;The
latest development which is a complete rewrite, is currently sitting in
the &lt;em&gt;molog_based&lt;/em&gt; branch. &amp;nbsp;I've split MoLog into 3 &amp;nbsp;parts: &amp;nbsp;The main
engine, a RESTful API and a CLI. &amp;nbsp;The main engine has been
rewritten&amp;nbsp;using the Wishbone and it seems to work reasonably fast even
without doing any optimization and without doing any profiling to
identify existing hot spots.&lt;/p&gt;
&lt;p&gt;It's time to roll up the sleeves and start to do some&amp;nbsp;useful&amp;nbsp;tinkering
and coding again.&lt;/p&gt;
</summary><category term="molog"></category><category term="monitoring"></category></entry><entry><title>Working with Moncli part2: Creating a simple request</title><link href="http://smetj.net/working-with-moncli-part2-creating-a-simple-request.html" rel="alternate"></link><updated>2012-03-11T22:12:00+01:00</updated><author><name>smetj</name></author><id>tag:smetj.net,2012-03-11:working-with-moncli-part2-creating-a-simple-request.html</id><summary type="html">&lt;p&gt;In our &lt;a class="reference external" href="http://smetj.net/2012/03/06/working-with-moncli-part1-creating-a-plugin/"&gt;previous post&lt;/a&gt;&amp;nbsp;we have covered how to &amp;nbsp;create an example plugin
which allows you to generate the size of directories as a metric. &amp;nbsp;A
plugin on itself doesn't do that much at all. &amp;nbsp;When a plugin is executed
it returns the values of that very moment. &amp;nbsp;Executing a plugin is done
by Moncli itself and we want to have control over that as much as
possible.&lt;/p&gt;
&lt;div class="section" id="moncli-request"&gt;
&lt;h2&gt;moncli_request&lt;/h2&gt;
&lt;p&gt;&lt;a class="reference external" href="http://wiki.smetj.net/wiki/Moncli_documentation#Request"&gt;A request is a JSON document&lt;/a&gt; which is submitted to the messagebroker
on which the Moncli clients are listening for incoming requests.
&amp;nbsp;Creating and submitting a request could be done&amp;nbsp;by hand, but that's not
pratical at all. &amp;nbsp;&lt;a class="reference external" href="https://github.com/smetj/moncli_request"&gt;Moncli_request&lt;/a&gt;&amp;nbsp;is a simple request generator tool
which generates and submits a valid JSON document to Moncli to work
with. &amp;nbsp;Let's generate a request for our dir_size plugin we created in
the previous article. &amp;nbsp;Moncli_request takes a base JSON document and
completes &amp;nbsp;it with the parameters you feed to it. &amp;nbsp;So let run through
the required steps:&lt;/p&gt;
&lt;ol class="arabic"&gt;
&lt;li&gt;&lt;p class="first"&gt;Install moncli_request from git:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
$ git clone https://smetj&amp;#64;github.com/smetj/moncli_request.git /opt/moncli_request
&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;Copy the skeleton base document over to a new default check called
DirSize:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
$ cp /opt/moncli_request/repository/skeleton /opt/moncli_request/repository/.default/DirSize
&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;Complete our newly created DirSize base document with the plugin name
and hash:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
{
 &amp;quot;plugin&amp;quot;:{
 &amp;quot;name&amp;quot;:&amp;quot;dir_size&amp;quot;,
 &amp;quot;hash&amp;quot;:&amp;quot;a1161fc0d2dfcd6b4e9f52651e88a1d0&amp;quot;,
 &amp;quot;timeout&amp;quot;:60
 },
 &amp;quot;report&amp;quot;:{
 &amp;quot;message&amp;quot;:&amp;quot;&amp;quot;
 },
 &amp;quot;request&amp;quot;:{
 &amp;quot;cycle&amp;quot;:60
 },
 &amp;quot;evaluators&amp;quot;:{
 },
 &amp;quot;tags&amp;quot;:[]
}
&lt;/pre&gt;
&lt;p&gt;The name is the name of the plugin we created in the previous post
and stored in Moncli's local repository. &amp;nbsp;This actually corresponds
to the directory name containing the plugin. &amp;nbsp;The hash is the md5sum
of the plugin. &amp;nbsp;Parameters is a list of parameters we want to feed to
the script.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;Now execute moncli_request without the --broker parameter. &amp;nbsp;This
will print the request which you can submit to Moncli through the
message broker on STDOUT:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
$ /opt/moncli_request/moncli_request --host indigo --subject 'DirSize' --parameters [\&amp;quot;\'/tmp/test/*\'\&amp;quot;]
{&amp;quot;request&amp;quot;:{&amp;quot;source&amp;quot;:&amp;quot;indigo&amp;quot;,&amp;quot;month&amp;quot;:3,&amp;quot;week_of_year&amp;quot;:10,&amp;quot;time&amp;quot;:&amp;quot;2012-03-11T19:58:54+01:00&amp;quot;,&amp;quot;day_of_year&amp;quot;:71,&amp;quot;uuid&amp;quot;:&amp;quot;DDB2AFC8-6BA3-11E1-B62D-8DA2DAFBAEBF&amp;quot;,&amp;quot;day&amp;quot;:11,&amp;quot;day_of_week&amp;quot;:7,&amp;quot;cycle&amp;quot;:60,&amp;quot;year&amp;quot;:2012},&amp;quot;plugin&amp;quot;:{&amp;quot;parameters&amp;quot;:[&amp;quot;'/tmp/test/*'&amp;quot;],&amp;quot;hash&amp;quot;:&amp;quot;a1161fc0d2dfcd6b4e9f52651e88a1d0&amp;quot;,&amp;quot;timeout&amp;quot;:60,&amp;quot;name&amp;quot;:&amp;quot;dir_size&amp;quot;},&amp;quot;report&amp;quot;:{&amp;quot;message&amp;quot;:&amp;quot;&amp;quot;},&amp;quot;destination&amp;quot;:{&amp;quot;subject&amp;quot;:&amp;quot;DirSize&amp;quot;,&amp;quot;name&amp;quot;:&amp;quot;indigo&amp;quot;},&amp;quot;evaluators&amp;quot;:{},&amp;quot;tags&amp;quot;:[]}
&lt;/pre&gt;
&lt;div&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;After verifying the content we can 'inject' the request into the
message broker on which Moncli is listening:&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;pre class="literal-block"&gt;
$ /opt/moncli_request/moncli_request --broker sandbox --host sandbox --subject 'DirSize' --parameters [\&amp;quot;\'/tmp/test/*\'\&amp;quot;]
A new Report Request (7373E8A2-6B6C-11E1-A438-D193DAFBAEBF) has been submitted.
&lt;/pre&gt;
&lt;p&gt;Keep in mind that the --broker parameter is the address/hostname of your
broker and the --host is the hostname of the host on which Moncli is
started. &amp;nbsp;Each started Moncli instance creates a queue in the broker
with its hostname as the queue name.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="report"&gt;
&lt;h2&gt;Report&lt;/h2&gt;
&lt;p&gt;When we consume the result from the broker (&lt;a class="reference external" href="http://smetj.net/2012/02/11/consuming-moncli-data-from-rabbitmq-using-krolyk/"&gt;see this post&lt;/a&gt;) we get
following result:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
{
   &amp;quot;evaluators&amp;quot;:{

   },
   &amp;quot;tags&amp;quot;:[

   ],
   &amp;quot;destination&amp;quot;:{
      &amp;quot;name&amp;quot;:&amp;quot;indigo&amp;quot;,
      &amp;quot;subject&amp;quot;:&amp;quot;DirSize&amp;quot;
   },
   &amp;quot;request&amp;quot;:{
      &amp;quot;uuid&amp;quot;:&amp;quot;3FF36DE4-6BA4-11E1-8B44-B4A2DAFBAEBF&amp;quot;,
      &amp;quot;year&amp;quot;:2012,
      &amp;quot;day_of_year&amp;quot;:71,
      &amp;quot;day_of_week&amp;quot;:7,
      &amp;quot;month&amp;quot;:3,
      &amp;quot;source&amp;quot;:&amp;quot;indigo&amp;quot;,
      &amp;quot;week_of_year&amp;quot;:10,
      &amp;quot;time&amp;quot;:&amp;quot;2012-03-11T20:01:38+01:00&amp;quot;,
      &amp;quot;day&amp;quot;:11,
      &amp;quot;cycle&amp;quot;:60
   },
   &amp;quot;report&amp;quot;:{
      &amp;quot;month&amp;quot;:3,
      &amp;quot;year&amp;quot;:2012,
      &amp;quot;timezone&amp;quot;:&amp;quot;+0100&amp;quot;,
      &amp;quot;message&amp;quot;:&amp;quot;&amp;quot;,
      &amp;quot;day&amp;quot;:11,
      &amp;quot;uuid&amp;quot;:&amp;quot;35672bb1-2cb8-46ea-8e23-bf5b98cbeaf4&amp;quot;,
      &amp;quot;day_of_year&amp;quot;:71,
      &amp;quot;day_of_week&amp;quot;:0,
      &amp;quot;source&amp;quot;:&amp;quot;indigo&amp;quot;,
      &amp;quot;week_of_year&amp;quot;:10,
      &amp;quot;time&amp;quot;:&amp;quot;2012-03-11T19:02:06+0100&amp;quot;
   },
   &amp;quot;plugin&amp;quot;:{
      &amp;quot;metrics&amp;quot;:{
         &amp;quot;pre_epoch&amp;quot;:1331488926.0,
         &amp;quot;/tmp/test/2&amp;quot;:&amp;quot;24576&amp;quot;,
         &amp;quot;/tmp/test/1&amp;quot;:&amp;quot;24576&amp;quot;,
         &amp;quot;pre_/tmp/test/1&amp;quot;:&amp;quot;24576&amp;quot;,
         &amp;quot;pre_/tmp/test/3&amp;quot;:&amp;quot;24576&amp;quot;,
         &amp;quot;pre_/tmp/test/2&amp;quot;:&amp;quot;24576&amp;quot;,
         &amp;quot;/tmp/test/3&amp;quot;:&amp;quot;24576&amp;quot;,
         &amp;quot;epoch&amp;quot;:1331488926.0
      },
      &amp;quot;raw&amp;quot;:[
         &amp;quot;/tmp/test/1:24576\n&amp;quot;,
         &amp;quot;/tmp/test/2:24576\n&amp;quot;,
         &amp;quot;/tmp/test/3:24576\n&amp;quot;
      ],
      &amp;quot;name&amp;quot;:&amp;quot;dir_size&amp;quot;,
      &amp;quot;verbose&amp;quot;:[

      ]
   }
}
&lt;/pre&gt;
&lt;/div&gt;
&lt;div class="section" id="conclusion"&gt;
&lt;h2&gt;Conclusion:&lt;/h2&gt;
&lt;p&gt;We have seen how to create a plugin and how to generate a request for
it. &amp;nbsp;We let Moncli execute the plugin by generating and submitting a
request with moncli_request and we have verified the incoming results.
&amp;nbsp;In this request we haven't done any evaluations which is something we
will cover in the next article in this series.&lt;/p&gt;
&lt;/div&gt;
</summary><category term="moncli"></category><category term="monitoringlove"></category></entry><entry><title>Moncli 0.2.5</title><link href="http://smetj.net/moncli-0-2-5.html" rel="alternate"></link><updated>2012-03-11T22:07:00+01:00</updated><author><name>smetj</name></author><id>tag:smetj.net,2012-03-11:moncli-0-2-5.html</id><summary type="html">&lt;p&gt;A new version of Moncli is released:&lt;/p&gt;
&lt;p&gt;&lt;a class="reference external" href="http://bit.ly/zE7XeN"&gt;Version 0.2.5&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;This release fixes 1 important bug and introduces a new feature:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Fixed bug which resulted in a growing number of never closing Moncli
processes.&lt;/li&gt;
&lt;li&gt;Writing to a logfile is replaced by writing to syslog only.&lt;/li&gt;
&lt;/ul&gt;
&lt;div&gt;&lt;p&gt;It is advised to upgrade to this version.&lt;/p&gt;
&lt;/div&gt;&lt;p&gt;For support please post a message to the&amp;nbsp;&lt;a class="reference external" href="https://groups.google.com/forum/?fromgroups#!forum/moncli"&gt;mailing list&lt;/a&gt;&amp;nbsp;or submit
a&amp;nbsp;&lt;a class="reference external" href="https://github.com/smetj/moncli/issues"&gt;bug report&lt;/a&gt;.&lt;/p&gt;
</summary><category term="moncli"></category></entry><entry><title>Working with Moncli part1: Creating a plugin</title><link href="http://smetj.net/working-with-moncli-part1-creating-a-plugin.html" rel="alternate"></link><updated>2012-03-06T23:25:00+01:00</updated><author><name>smetj</name></author><id>tag:smetj.net,2012-03-06:working-with-moncli-part1-creating-a-plugin.html</id><summary type="html">&lt;div class="section" id="producing-data"&gt;
&lt;h2&gt;Producing data&lt;/h2&gt;
&lt;p&gt;In the previous 2 posts we had an &lt;a class="reference external" href="http://smetj.net/2012/02/09/moncli-an-introduction/"&gt;introduction about Moncli&lt;/a&gt; and we
have seen how to&amp;nbsp;&lt;a class="reference external" href="http://smetj.net/2012/02/11/consuming-moncli-data-from-rabbitmq-using-krolyk/"&gt;consume Moncli data (reports) from the Message
broker with Krolyk&lt;/a&gt;&amp;nbsp;and process them. &amp;nbsp;Now its time to let Moncli
generate some data we can work with. &amp;nbsp;In the next couple of articles we
will go through the process of building a new plugin and use it to
generate metrics and perform different kind of evaluations.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="creating-a-simple-plugin"&gt;
&lt;h2&gt;Creating a simple plugin&lt;/h2&gt;
&lt;p&gt;One of the goals for Moncli was to create a framework which allows
people to easily create their own plugins. &amp;nbsp;Although Moncli already
comes with a &lt;a class="reference external" href="https://github.com/smetj/moncli/tree/master/lib/repository"&gt;set of plugins&lt;/a&gt; which provide basic system metrics they
will not cover all your needs, so we'll create one as an example.&lt;/p&gt;
&lt;p&gt;Let's say we want to measure and evaluate the disk space one or more
directories consume. &amp;nbsp;For this I create a small Bash/Perl oneliner which
looks like this:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
#!/bin/bash
du -s -b $1\|perl -n -e '/(\\d\*)\\s\*(.\*)/ &amp;amp;&amp;amp; print &amp;quot;$2:$1\\n&amp;quot;'
&lt;/pre&gt;
&lt;p&gt;This script accepts 1 parameter which is the directory of which we want
to process the content.&lt;/p&gt;
&lt;pre class="literal-block"&gt;
jelle&amp;#64;indigo:~$ ./dir_size.sh '/tmp/test/*'
/tmp/test/one:155656192
/tmp/test/three:4096
/tmp/test/two:583471104
jelle&amp;#64;indigo:~$
&lt;/pre&gt;
&lt;p&gt;Now we have to make sure Moncli can execute this new plugin. &amp;nbsp;The name
of the plugin is dir_size, so first we will make a new directory in the
&lt;a class="reference external" href="http://wiki.smetj.net/wiki/Moncli_documentation#local_repo"&gt;Moncli's repository directory&lt;/a&gt; which contains all plugins. &amp;nbsp;The name
of the directory is the name of our script:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
jelle&amp;#64;indigo:~$ mkdir /opt/moncli/lib/repository/dir_size
&lt;/pre&gt;
&lt;p&gt;Then we rename our script to the value of its md5sum and move it to the
directory we just created:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
jelle&amp;#64;indigo:~$ md5sum dir_size.sh
a1161fc0d2dfcd6b4e9f52651e88a1d0 dir_size.sh
jelle&amp;#64;indigo:~$ mv dir_size.sh /opt/moncli/lib/repository/dir_size/a1161fc0d2dfcd6b4e9f52651e88a1d0
jelle&amp;#64;indigo:~$
&lt;/pre&gt;
&lt;/div&gt;
&lt;div class="section" id="security"&gt;
&lt;h2&gt;Security&lt;/h2&gt;
&lt;p&gt;The reason why we store the script as its md5sum is for both security as
practical reasons. &amp;nbsp;Moncli knows which script to execute because it has
the name of the directory. &amp;nbsp;The request submitted to Moncli contains
besides the name of the plugin also the md5sum of the version to
execute. &amp;nbsp;If somebody changes the content of the script, then Moncli
will not execute it, because before executing the script Moncli looks
whether the filename of the script matches its hash. &amp;nbsp;Somebody could add
a new version of the script inside the directory with the correct hash,
but then you must define that hash in your request. &amp;nbsp;In other words, you
can have multiple versions of the plugin inside the directory.&lt;/p&gt;
&lt;p&gt;Our script is now ready to be used.&lt;/p&gt;
&lt;p&gt;In part2 we will cover how to generate a request so we can test and use
our newly created plugin.&lt;/p&gt;
&lt;/div&gt;
</summary><category term="moncli"></category></entry><entry><title>Moncli 0.2.4</title><link href="http://smetj.net/moncli-0-2-4.html" rel="alternate"></link><updated>2012-03-05T18:28:00+01:00</updated><author><name>smetj</name></author><id>tag:smetj.net,2012-03-05:moncli-0-2-4.html</id><summary type="html">&lt;p&gt;A new version of Moncli is released:&lt;/p&gt;
&lt;p&gt;This release immediately follows&amp;nbsp;the 0.2.3 release to fix 2 issues which
got unnoticed during &amp;nbsp;that release:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;a class="reference external" href="https://github.com/smetj/moncli/issues/2"&gt;Moncli doesn't submit valid json data to the broker.&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="https://github.com/smetj/moncli/issues/3"&gt;traceback module not loaded&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Both issues have been tackled.&lt;/p&gt;
&lt;p&gt;For support please post a message to the &lt;a class="reference external" href="https://groups.google.com/forum/?fromgroups#!forum/moncli"&gt;mailing list&lt;/a&gt;&amp;nbsp;or submit a
&lt;a class="reference external" href="https://github.com/smetj/moncli/issues"&gt;bug report&lt;/a&gt;.&lt;/p&gt;
</summary><category term="moncli"></category></entry><entry><title>Consuming Moncli data from RabbitMQ using Krolyk</title><link href="http://smetj.net/consuming-moncli-data-from-rabbitmq-using-krolyk.html" rel="alternate"></link><updated>2012-02-11T18:08:00+01:00</updated><author><name>smetj</name></author><id>tag:smetj.net,2012-02-11:consuming-moncli-data-from-rabbitmq-using-krolyk.html</id><summary type="html">&lt;div class="section" id="what-s-in-a-name"&gt;
&lt;h2&gt;What's in a name?&lt;/h2&gt;
&lt;p&gt;Before we go into more detail on how to execute plugins,
manipulate and evaluate data with Moncli we first have to take a look
how we are going to consume the data produced by Moncli from RabbitMQ.
&amp;nbsp;I found myself quite often in the situation where I had to write again
and again a daemon or process which consumes data from RabbitMQ and do
something with it. &amp;nbsp;I already started to write &lt;a class="reference external" href="https://github.com/smetj/krolyk"&gt;Krolyk&lt;/a&gt;&amp;nbsp;which initial
goal was to consume Nagios passive check results from RabbitMQ and write
them into the Nagios command pipe. &amp;nbsp;I found that too specific, so I
changed Krolyk into a more &lt;a class="reference external" href="https://github.com/smetj/krolyk/tree/master/lib/plugins"&gt;modular or plugin system&lt;/a&gt;, which allows you
to write a &lt;a class="reference external" href="https://github.com/smetj/krolyk/blob/master/lib/plugins/skeleton.py"&gt;simple Python class&lt;/a&gt; which consumes data from RabbitMQ.
&amp;nbsp;The nice thing about it is when you write a plugin for Krolyk, it will
start one or more &amp;nbsp;parallel consumers without you having to worry about
how to organize all that. &amp;nbsp;This makes writing consumers for RabbitMQ
easy and accessible to more people. &amp;nbsp;Krolyk's use is however &lt;strong&gt;not&lt;/strong&gt;limited to the monitoring and metrics collection scope. &amp;nbsp;It's intended
to be generic, allowing one to easily write parallel RabbitMQ consumers.&lt;/p&gt;
&lt;p&gt;Consuming Moncli data from RabbitMQ&lt;/p&gt;
&lt;p&gt;So let's setup Krolyk to consume and simply display data produced by
Moncli.&lt;/p&gt;
&lt;p&gt;To realize this we can use the &lt;a class="reference external" href="https://github.com/smetj/krolyk/blob/master/lib/plugins/skeleton.py"&gt;skeleton.py&lt;/a&gt; plugin. &amp;nbsp;The &lt;em&gt;skeleton&lt;/em&gt;
plugin can be used as a base for your new and more complex plugins.
&amp;nbsp;What skeleton does out of the box is just print the content it consumes
from the broker to stdout and acknowledge it back to the broker so it's
removed from the queue. &amp;nbsp;Just have a look at the &lt;em&gt;consume&lt;/em&gt; function.
&amp;nbsp;This should pretty much give you an idea of what you can do with it.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="configuration"&gt;
&lt;h2&gt;Configuration&lt;/h2&gt;
&lt;p&gt;Krolyk has a config file in which you can define parameters to connect
to RabbitMQ and parameters which are available to the plugin you write.
&amp;nbsp;If we take a look at krolyk.cfg we can see under the [&amp;quot;plugins&amp;quot;]
section a configuration section for each individual plugin. &amp;nbsp;You have to
make sure that the name of the plugin section is exactly the same
(including case) as the name of your class.&lt;/p&gt;
&lt;pre class="literal-block"&gt;
[ccnbw_ini width=&amp;quot;500&amp;quot; lines=&amp;quot;-1&amp;quot; ]
[ &amp;quot;plugins&amp;quot; ]
    [[ &amp;quot;Skeleton&amp;quot; ]]
        &amp;quot;_enabled&amp;quot;       = False
        &amp;quot;_workers&amp;quot;       = 5
        &amp;quot;_broker&amp;quot;        = &amp;quot;sandbox&amp;quot;
        &amp;quot;_queue&amp;quot;         = &amp;quot;moncli_reports&amp;quot;
        &amp;quot;_user&amp;quot;          = &amp;quot;guest&amp;quot;
        &amp;quot;_password&amp;quot;      = &amp;quot;guest&amp;quot;
        &amp;quot;blah1&amp;quot;          = &amp;quot;whatever&amp;quot;
        &amp;quot;fu&amp;quot;             = &amp;quot;bar&amp;quot;
[/ccnbw_ini]
&lt;/pre&gt;
&lt;p&gt;Each plugin/class should have at minimal the parameters defined required
to &amp;nbsp;connect to the RabbitMQ broker. &amp;nbsp;These parameters all start with an
underscore. &amp;nbsp;All other variables you define will be available to your
class as a dictionary called &amp;quot;self.configuration&amp;quot;&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="a-practical-example"&gt;
&lt;h2&gt;A practical example&lt;/h2&gt;
&lt;p&gt;So let's start an instance of Krolyk which consumes data produced by
Moncli and prints it to stdout. &amp;nbsp;Keep in mind Krolyk that if the queue
doesn't exist, Krolyk will create a durable one for you.&lt;/p&gt;
&lt;ol class="arabic"&gt;
&lt;li&gt;&lt;p class="first"&gt;Start Krolyk in the foreground with a config file which works for
your environment:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
jelle&amp;#64;indigo:~$ /opt/krolyk/bin/krolyk debug --config /opt/krolyk/etc/krolyk.cfg
&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;Submit a test string to the AMQP default exchange:&lt;a class="reference external" href="http://smetj.net/2012/02/11/consuming-moncli-data-from-rabbitmq-using-krolyk/krolyk_rabbit1/"&gt;&lt;img alt="image1" src="http://smetj.net/wp-content/uploads/2012/02/krolyk_rabbit1-150x150.jpg" /&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;And see it appear on the command line:&lt;a class="reference external" href="http://smetj.net/2012/02/11/consuming-moncli-data-from-rabbitmq-using-krolyk/krolyk_rabbit2/"&gt;&lt;img alt="image2" src="http://smetj.net/wp-content/uploads/2012/02/krolyk_rabbit2-300x91.jpg" /&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;This example isn't really doing anything exciting but, I at least it
gives you an idea on what functionality Krolyk offers. &amp;nbsp;Using the
information from this post you should be able to display the data
generated by Moncli, so you have an idea what comes out of it.&lt;/p&gt;
&lt;p&gt;In the next post we will be creating Requests and Reports with Moncli.&lt;/p&gt;
&lt;/div&gt;
</summary><category term="krolyk"></category><category term="moncli"></category><category term="monitoringlove"></category><category term="rabbitmq"></category></entry><entry><title>Moncli - An introduction</title><link href="http://smetj.net/moncli-an-introduction.html" rel="alternate"></link><updated>2012-02-09T00:20:00+01:00</updated><author><name>smetj</name></author><id>tag:smetj.net,2012-02-09:moncli-an-introduction.html</id><summary type="html">&lt;p&gt;&lt;a class="reference external" href="http://smetj.net/2012/02/09/moncli-an-introduction/moncli_architecture_1-2/"&gt;&lt;img alt="image0" src="http://smetj.net/wp-content/uploads/2012/02/Moncli_architecture_11-300x231.jpg" /&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;One of the classic tasks one has to deal with when working with a
monitoring framework is have the ability to retrieve metrics from an OS
or server which aren't available just like that over the network. There
are plenty of different techniques and a multitude of clients available
which offer this functionality. &amp;nbsp;Covering them falls out of the scope of
this post.&lt;/p&gt;
&lt;div class="section" id="so-why-another-monitoring-client"&gt;
&lt;h2&gt;So why another Monitoring Client?&lt;/h2&gt;
&lt;p&gt;When running into scalability problems with my Nagios setup, I realized
that the reason for this is the fact that Nagios always has to take the
initiative to poll a client. &amp;nbsp;This is in Nagios terminology called an
active check. &amp;nbsp;It's of course normal that a client receives instructions
on what it needs to do like which plugin to execute or which thresholds
to evaluate. &amp;nbsp;However, if you think about it, why do we have to repeat
the same question over and over again while in essence nothing has ever
changed between the current and the previous request? Isn't it normal we
ask a question once and say report back at this interval and carry on
until further notice?&lt;/p&gt;
&lt;p&gt;So why not offloading all (or most of) the scheduling effort a central
monitoring system has to perform to the monitoring clients running on
your hosts?&lt;/p&gt;
&lt;p&gt;If you would take it further, you could turn each of my monitoring
clients into an &amp;quot;independent miniature monitoring engine&amp;quot;. &amp;nbsp;This way you
could shift the load from a central system to the collective of clients
in the network. &amp;nbsp;This basically results in horizontal scalability and a
decentralized setup.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="requirements"&gt;
&lt;h2&gt;Requirements&lt;/h2&gt;
&lt;div class="section" id="open-and-rich-data-format"&gt;
&lt;h3&gt;Open and rich data format&lt;/h3&gt;
&lt;p&gt;All in- and outgoing communication should be done in an clear and open
data format, which offers the flexibility to transform it into any
other&amp;nbsp;desirable format which allows you to integrate the client with an
existing&amp;nbsp;platform but which in its turn also allows you to move away
from it. &amp;nbsp;All &lt;a class="reference external" href="http://wiki.smetj.net/wiki/Moncli_documentation#Request"&gt;incoming&lt;/a&gt;&amp;nbsp;to and &lt;a class="reference external" href="http://wiki.smetj.net/wiki/Moncli_documentation#Reports"&gt;outgoing&lt;/a&gt;&amp;nbsp;data from Moncli is in JSON
format. This makes sure that Moncli data is manipulated easily.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="scheduling"&gt;
&lt;h3&gt;Scheduling&lt;/h3&gt;
&lt;p&gt;As said, the client needs to be able to schedule a request at an
&lt;a class="reference external" href="http://wiki.smetj.net/wiki/Moncli_documentation#cycle"&gt;interval of choice&lt;/a&gt;. When the client restarts, it should remember its
scheduled requests and carry on from the moment it's alive again. Moncli
has a build in scheduler which &lt;a class="reference external" href="http://wiki.smetj.net/wiki/Moncli_documentation#cache"&gt;writes its schedule to disk&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="flexible-messaging"&gt;
&lt;h3&gt;Flexible messaging.&lt;/h3&gt;
&lt;p&gt;Since Moncli has its own scheduler, it has to submit the check results
somehow in a trustworthy way without actually having to care much about
who consumes the data when and where. Moncli submits check results into
the &lt;a class="reference external" href="http://www.rabbitmq.com/"&gt;RabbitMQ&lt;/a&gt; message broker, which offers a great deal of
flexibility.&lt;/p&gt;
&lt;p&gt;Moncli &lt;a class="reference external" href="http://wiki.smetj.net/wiki/Moncli_documentation#Communication"&gt;listens&lt;/a&gt; on the message broker infrastructure for incoming
requests. Each Moncli client registers a queue using its FQDN as a name
on the message broker infrastructure from where it receives the requests
it should execute.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="simple-manageable-but-safe-plugin-design"&gt;
&lt;h3&gt;Simple, manageable but safe plugin design&lt;/h3&gt;
&lt;p&gt;Metrics have to come from somewhere. When Moncli executes a request, it
actually executes a locally stored plugin. &lt;a class="reference external" href="http://wiki.smetj.net/wiki/Moncli_documentation#Plugins"&gt;All this plugin needs to do
is create a list of key/value pairs&lt;/a&gt;. This significantly lowers the
difficulty and time required to create new plugins which also allows
less experienced people to write plugins. Moncli will only execute
&lt;a class="reference external" href="http://wiki.smetj.net/wiki/Moncli_documentation#local_repo"&gt;locally stored plugins&lt;/a&gt; which have a hash which matches the one in the
request. When a plugin with such a hash isn't found locally, it will try
to download an update or new version from &lt;a class="reference external" href="http://wiki.smetj.net/wiki/Moncli_documentation#remote_repo"&gt;a central location&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="evaluation-of-metrics"&gt;
&lt;h3&gt;Evaluation of metrics&lt;/h3&gt;
&lt;p&gt;Nagios plugins require you to build in the evaluation of thresholds in
them by feeding the plugin the warning and critical values. &amp;nbsp;Moncli also
performs the evaluation of metrics on the client side but takes another
approach. &amp;nbsp;Instead of doing threshold evaluation in the plugin, Moncli
does the evaluation itself, based upon the &lt;a class="reference external" href="http://wiki.smetj.net/wiki/Moncli_documentation#thresholds"&gt;thresholds&lt;/a&gt; one provides in
combination with a an evaluator.&lt;/p&gt;
&lt;p&gt;There are currently 2 &lt;a class="reference external" href="http://wiki.smetj.net/wiki/Moncli_documentation#Evaluator_definitions"&gt;types of evaluators&lt;/a&gt; (more planned):&lt;/p&gt;
&lt;p&gt;Formulas: calculations using the keys/values returned by the plugin.
Regexes: Simple regex matching on the output of a plugin (not key
value pairs)&lt;/p&gt;
&lt;p&gt;It's optional to define evaluators in a request. &amp;nbsp;In this case, Moncli
just becomes a metrics collector.&lt;/p&gt;
&lt;p&gt;A good starting point to figure out what the possibilities of Moncli are
is done by looking through &amp;nbsp;the in- and outgoing data format of Moncli
called &lt;a class="reference external" href="http://wiki.smetj.net/wiki/Moncli_documentation#Request"&gt;requests&lt;/a&gt; and &lt;a class="reference external" href="http://wiki.smetj.net/wiki/Moncli_documentation#Reports"&gt;reports&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;A second post will be about consuming and processing of Moncli data from
RabbitMQ.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
</summary><category term="moncli"></category><category term="monitoringlove"></category><category term="rabbitmq"></category></entry><entry><title>Monitoring and metric collection across teams.</title><link href="http://smetj.net/monitoring-and-metrics-collection-across-teams.html" rel="alternate"></link><updated>2012-01-29T17:02:00+01:00</updated><author><name>smetj</name></author><id>tag:smetj.net,2012-01-29:monitoring-and-metrics-collection-across-teams.html</id><summary type="html">&lt;p&gt;There' s currently a lot of activity going on the monitoring and
metrics collection landscape and I couldn't be more happy about that as
it's on of those things which also keep me busy in a professional way.
When looking at the growth of information, blogs and projects I can see
that I share many of the problems I'm confronted with, with many people
out there.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Day to day operations&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;One of driving forces in my search of solutions has always been about
making sure that whoever uses it does not have to be a rocket scientist
or somebody who is soaked into the subject and aware of all the perils
that come with monitoring and metrics collection in general. &amp;nbsp;I'm not
only talking about who is going to use the application, but also about
the people who are involved in it some way or the other and who have
because of that expectations from it. &amp;nbsp;I find it very important to have
tools in place which can also be maintained and worked on by &amp;quot;mortal
souls&amp;quot; and basically just get things done without too much hassle.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Single point of ...&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Once having a monitoring or metrics collection framework in place in a
company you can see all kinds of people getting&amp;nbsp;enthusiastic about it.
&amp;nbsp;People from different technical teams within your company start to see
the&amp;nbsp;possibilities&amp;nbsp;and the benefits. &amp;nbsp;Networking engineers, business
applications admins, OS engineers, software engineers,... &amp;nbsp;They all want
data into that framework and have it presented and evaluated, which is
great but as they're busy with their own daily operations, they hardly
have the time to deal with the practical side of things, so quite often,
they expect this will be done by the monitoring guy or team.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Free membership&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;One of my rules of thumbs is that as a monitoring solution provider you
will have to make sure that it's trivial for engineers to create their
own data and submit it into the monitoring environment and have it
evaluated. &amp;nbsp;This not only makes sure that you, the monitoring guy, is
not&amp;nbsp;burdened with the endless work of creating all sorts of plugins
which deliver the information they want but it also makes sure they are
more involved in the whole process, so their expectations are on par and
they will feel more involved and responsible for their part, which is
generally a good thing.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;You're not an island&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Bottom line by making sure your tool facilitates participation, does not
only spread the work giving you more time to work on something more
useful, it also makes sure that the people or teams with requirements
are more involved and responsible themselves for what they want, which
is something everybody benefits from in the long run.&lt;/p&gt;
</summary><category term="company"></category><category term="monitoring"></category><category term="tools"></category></entry></feed>