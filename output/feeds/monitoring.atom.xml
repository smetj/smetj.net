<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>http://smetj.net</title><link href="file:///home/smetj/projects/github/smetj.net/output/" rel="alternate"></link><link href="file:///home/smetj/projects/github/smetj.net/output/feeds/monitoring.atom.xml" rel="self"></link><id>file:///home/smetj/projects/github/smetj.net/output/</id><updated>2013-05-10T15:59:00+02:00</updated><entry><title>Submit Nagios metrics to Graphite with ModGearman and MetricFactory</title><link href="file:///home/smetj/projects/github/smetj.net/output/submit-nagios-metrics-to-graphite-with-modgearman-and-metricfactory.html" rel="alternate"></link><updated>2013-05-10T15:59:00+02:00</updated><author><name>smetj</name></author><id>tag:file:///home/smetj/projects/github/smetj.net/output,2013-05-10:submit-nagios-metrics-to-graphite-with-modgearman-and-metricfactory.html</id><summary type="html">&lt;p&gt;When it comes down to monitoring Nagios is still the weapon of choice
for many. &amp;nbsp;I would have abandoned it if there weren't projects like
&lt;a class="reference external" href="http://mathias-kettner.de/checkmk_livestatus.html"&gt;Livestatus&lt;/a&gt;,&amp;nbsp;&lt;a class="reference external" href="http://labs.consol.de/lang/en/nagios/mod-gearman/"&gt;Mod_Gearman&lt;/a&gt;&amp;nbsp;and&amp;nbsp;&lt;a class="reference external" href="http://www.thruk.org/"&gt;Thruk&lt;/a&gt;&amp;nbsp;which to my opinion should
never be missing from any Nagios setup. &amp;nbsp;Mod_Gearman, the framework
which makes Nagios scalable, has a feature which stores the performance
data produced by the Nagios plugins into a &lt;a class="reference external" href="http://gearman.org/"&gt;Gearman&lt;/a&gt;&amp;nbsp;queue. &amp;nbsp;Graphing
that performance data with &lt;a class="reference external" href="http://graphite.wikidot.com/"&gt;Graphite&lt;/a&gt; is a straightforward job with
&lt;a class="reference external" href="https://github.com/smetj/metricfactory"&gt;Metricfactory&lt;/a&gt;.&lt;/p&gt;
&lt;div class="section" id="performance-data"&gt;
&lt;h2&gt;Performance data&lt;/h2&gt;
&lt;p&gt;Mod_Gearman is a Nagios addon which spreads the Nagios plugin execution
over a farm of worker nodes. &amp;nbsp;This allows you to build a scalable Nagios
setup quite effectively. &amp;nbsp;The workers execute the Nagios plugins and
submit the produced results back into the Gearman master server. &amp;nbsp;A
Nagios broker module then consumes the submitted check results from the
Gearman master and submits the check results into Nagios for further
processing. &amp;nbsp;The broker module can optionally submit the &lt;a class="reference external" href="http://nagios.sourceforge.net/docs/3_0/perfdata.html"&gt;performance
data&lt;/a&gt;&amp;nbsp;back into a dedicated Gearman queue ready to be consumed by an
external process which in our case is going to be Metricfactory.
&amp;nbsp;Metricfactory will convert the performance data into the proper format
and submit that into Graphite.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="mod-gearman"&gt;
&lt;h2&gt;Mod_Gearman&lt;/h2&gt;
&lt;p&gt;The Mod_Gearman project has quite extensive &lt;a class="reference external" href="http://labs.consol.de/lang/en/nagios/mod-gearman/"&gt;documentation
available&lt;/a&gt;&amp;nbsp;but these are the relevant parameters:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
perfdata=yes
&lt;/pre&gt;
&lt;p&gt;Setting the value to&amp;nbsp;&lt;em&gt;yes&lt;/em&gt; makes the broker module write the
performance data to the&amp;nbsp;&lt;em&gt;perfdata&lt;/em&gt; queue.&lt;/p&gt;
&lt;pre class="literal-block"&gt;
perfdata_mode=1
&lt;/pre&gt;
&lt;p&gt;Setting the value to&amp;nbsp;&lt;em&gt;1&lt;/em&gt; makes sure that performance data doesn't pile
up endlessly in the queue when Metricfactory isn't consuming. &amp;nbsp;It's
basically a precaution which prevents the queue to fill up to a point
all available system memory is consumed. &amp;nbsp;Setting the value to&amp;nbsp;&lt;em&gt;2&lt;/em&gt;
will append all performance data to the queue without overwriting old
data. &amp;nbsp;When enabled you can execute the&amp;nbsp;&lt;em&gt;gearman_top&lt;/em&gt; command and you
should see the&amp;nbsp;&lt;em&gt;perfdata&lt;/em&gt; queue appear:&lt;/p&gt;
&lt;p&gt;&lt;a class="reference external" href="http://smetj.net/2013/05/10/submit-nagios-metrics-to-graphite-with-modgearman-and-metricfactory/gearman_top/"&gt;&lt;img alt="gearman_top" src="http://smetj.net/wp-content/uploads/2013/05/gearman_top.png" /&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;The Jobs Waiting column indicates how many performance data is currently
stored in the queue. &amp;nbsp;Ideally this should be 0 or as low as possible and
never grow otherwise that might indicate the performance data is not
consumed fast enough. Keep in mind that not all Nagios plugins produce
performance data. &amp;nbsp;If you want to be sure whether a plugin produces
performance data, have a look in Thruk (or other Nagios interface) and
verify in the service or host details whether &lt;em&gt;Performance Data&lt;/em&gt;
actually contains valid perfdata.&lt;/p&gt;
&lt;p&gt;&lt;a class="reference external" href="http://smetj.net/2013/05/10/submit-nagios-metrics-to-graphite-with-modgearman-and-metricfactory/perfdata/"&gt;&lt;img alt="perfdata" src="http://smetj.net/wp-content/uploads/2013/05/perfdata.png" /&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="metricfactory"&gt;
&lt;h2&gt;Metricfactory&lt;/h2&gt;
&lt;p&gt;You can download Metricfactory from &lt;a class="reference external" href="https://github.com/smetj/metricfactory"&gt;Github&lt;/a&gt; and get it up an running
quite easily by following the installation instructions. &amp;nbsp;In our case,
you will require some additional modules which you can install from Pypi
using the&amp;nbsp;&lt;em&gt;easy_install&lt;/em&gt;command:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
$ easy_install wb_gearmand
$ easy_install wb_tcpclient
$ easy_install wb_tippingbucket
$ easy_install wb_stdout
&lt;/pre&gt;
&lt;p&gt;When all went well you should be able to execute (&lt;a class="reference external" href="http://ascii.io/a/3101"&gt;ascii.io
screencast&lt;/a&gt;):&lt;/p&gt;
&lt;pre class="literal-block"&gt;
$ metricfactory list
&lt;/pre&gt;
&lt;/div&gt;
&lt;div class="section" id="configuration"&gt;
&lt;h2&gt;Configuration&lt;/h2&gt;
&lt;p&gt;Metricfactory uses bootstrap files which define the modules to load and
how events will flow through the chain. &amp;nbsp;You can download a base example
&lt;a class="reference external" href="https://github.com/smetj/experiments/blob/master/metricfactory/modgearman2graphite/modgearman2graphite.json"&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;pre class="literal-block"&gt;
{
  &amp;quot;metrics&amp;quot;: {
    &amp;quot;enable&amp;quot;: true,
    &amp;quot;group&amp;quot;: &amp;quot;wishbone.metrics&amp;quot;,
    &amp;quot;interval&amp;quot;: 10,
    &amp;quot;module&amp;quot;: &amp;quot;Log&amp;quot;,
    &amp;quot;variables&amp;quot;: {
    }
  },
  &amp;quot;bootstrap&amp;quot;: {
    &amp;quot;modgearman&amp;quot;: {
      &amp;quot;group&amp;quot;: &amp;quot;wishbone.iomodule&amp;quot;,
      &amp;quot;module&amp;quot;: &amp;quot;Gearmand&amp;quot;,
      &amp;quot;variables&amp;quot;: {
        &amp;quot;hostnames&amp;quot;: [ &amp;quot;your.gearmand.server.hostname&amp;quot; ],
        &amp;quot;secret&amp;quot;: &amp;quot;changemechangeme&amp;quot;,
        &amp;quot;workers&amp;quot;: 1
      }
    },
    &amp;quot;decodemodgearman&amp;quot;: {
      &amp;quot;group&amp;quot;: &amp;quot;metricfactory.decoder&amp;quot;,
      &amp;quot;module&amp;quot;: &amp;quot;ModGearman&amp;quot;,
      &amp;quot;variables&amp;quot;: {
      }
    },
    &amp;quot;encodegraphite&amp;quot;: {
      &amp;quot;group&amp;quot;: &amp;quot;metricfactory.encoder&amp;quot;,
      &amp;quot;module&amp;quot;: &amp;quot;Graphite&amp;quot;,
      &amp;quot;variables&amp;quot;: {
        &amp;quot;prefix&amp;quot;:&amp;quot;nagios&amp;quot;
      }
    },
    &amp;quot;buffer&amp;quot;: {
      &amp;quot;group&amp;quot;: &amp;quot;wishbone.module&amp;quot;,
      &amp;quot;module&amp;quot;: &amp;quot;TippingBucket&amp;quot;,
      &amp;quot;variables&amp;quot;: {
        &amp;quot;events&amp;quot;: 1000,
        &amp;quot;age&amp;quot;: 60
      }
    },
    &amp;quot;tcpout&amp;quot;: {
      &amp;quot;group&amp;quot;: &amp;quot;wishbone.iomodule&amp;quot;,
      &amp;quot;module&amp;quot;: &amp;quot;TCPClient&amp;quot;,
      &amp;quot;variables&amp;quot;: {
        &amp;quot;pool&amp;quot;: [&amp;quot;your.graphite.relay1:2013&amp;quot;,&amp;quot;your.graphite.relay2:2013&amp;quot;]
      }
    },
    &amp;quot;stdout&amp;quot;: {
      &amp;quot;group&amp;quot;: &amp;quot;wishbone.module&amp;quot;,
      &amp;quot;module&amp;quot;: &amp;quot;STDOUT&amp;quot;,
      &amp;quot;variables&amp;quot;: {
        &amp;quot;purge&amp;quot;:true
      }
    }
  },
  &amp;quot;routingtable&amp;quot;: {
    &amp;quot;modgearman.inbox&amp;quot;: [ &amp;quot;decodemodgearman.inbox&amp;quot; ],
    &amp;quot;decodemodgearman.outbox&amp;quot;: [ &amp;quot;encodegraphite.inbox&amp;quot; ],
    &amp;quot;encodegraphite.outbox&amp;quot;: [ &amp;quot;tcpout.inbox&amp;quot; ]
  }
}
&lt;/pre&gt;
&lt;p&gt;Depending on your environment you will have to adapt some of the
variables in the boostrap file. The &lt;em&gt;hostnames&lt;/em&gt; variable (line 15) is a
list of the Gearmand servers from which the&amp;nbsp;&lt;em&gt;perfdata&lt;/em&gt;&amp;nbsp; has to be
consumed. &amp;nbsp;Usually this is a list containing just 1 server. &amp;nbsp;In some
special cases you might add more servers here but that's in our case not
likely.&lt;/p&gt;
&lt;p&gt;The secret variable (line 16) should contain the pre-shared encryption
key allowing you to decrypt the information consumed from Gearmand.
&amp;nbsp;Worth to mention there is no authentication, but without the decryption
key you wont be able to read the data coming from the Gearmand server.&lt;/p&gt;
&lt;p&gt;The number of workers variable (line 17) determines how many workers
should consume perfdata from the&amp;nbsp;&lt;em&gt;perfdata&lt;/em&gt; queue. &amp;nbsp;If you notice
perdata isn't consumed fast enough, you could bump this number to a
higher value. &amp;nbsp;In this case keep an eye on the the CPU usage of
Metricfactory due to the decrypting. &amp;nbsp;If you notice Metricfactory can't
keep up because of high cpu usage then another strategy might be to
leave this numer on 1 and start Metricfactory with the &lt;em&gt;--instances x&lt;/em&gt;
parameter, where x is the number of parallel processes.&lt;/p&gt;
&lt;p&gt;In this configuration, the &lt;em&gt;buffer&lt;/em&gt; instance of the TippingBucket module
will flush when 1000 metrics (line 27) are in the buffer or when the
last metric added to the buffer is 60 seconds (line 38) old. &amp;nbsp;This
allows you to control the size of the data per outgoing connection to
Graphite. &amp;nbsp;It's more efficient to group and submit metrics instead of
making a connection to Graphite per metric.&lt;/p&gt;
&lt;p&gt;The &lt;em&gt;tcpout&lt;/em&gt; instance is initiated in this example with the addresses of
2 Graphite relay servers (line 45). &amp;nbsp;When defining more than 1 address
in the &lt;em&gt;pool&lt;/em&gt; list then the client will randomly select one of the
addresses until a successful connect is done. To test, you can start
Metricfactory in debug mode to keep it from forking in the background
and by enabling the &lt;em&gt;--loglevel debug&lt;/em&gt;&amp;nbsp;parameter:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
$ metricfactory debug --config modgearmand2graphite.json --loglevel debug
&lt;/pre&gt;
&lt;p&gt;&lt;a class="reference external" href="http://ascii.io/a/3102"&gt;ascii.io screencast&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="converting-nagios-format-to-graphite-format"&gt;
&lt;h2&gt;Converting Nagios format to graphite format&lt;/h2&gt;
&lt;p&gt;Graphite stores the metrics in a tree-like hierarchical manner using a
dotted naming scheme. Somehow we will have to convert the Nagios metrics
into this format. &amp;nbsp;Metricfactory converts the metrics coming from an
external source into a common Metricfactory format. &amp;nbsp;From this format
it's straightforward to convert them into another format. Unfortunately,
many years of Nagios plugin development has lead to all kinds of metric
name formats. &amp;nbsp;This&amp;nbsp;inconsistency is something we will have to deal
with. Consider following examples:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
rta=1.274ms;3000.000;5000.000;0; pl=0%;80;100;;
&lt;/pre&gt;
&lt;pre class="literal-block"&gt;
/=1351MB;3426;3627;0;4031 /dev=0MB;3046;3225;0;3584 /dev/shm=0MB;3054;3233;0;3593 /boot=26MB;205;217;0;242 /tmp=16MB;427;452;0;503 /var=1430MB;6853;7256;0;8063 /var/tmp=16MB;427;452;0;503
&lt;/pre&gt;
&lt;pre class="literal-block"&gt;
MemUsedPercent=7%;98;102;0;100 SwapUsedPercent=0%;80;90;0;100 MemUsed=486MB;;;0;7187 SwapUsed=0MB;;;0;204
&lt;/pre&gt;
&lt;p&gt;The names of metrics in the first example are rta and pl respectively.
&amp;nbsp;In the second example the metric names are the paths of mount points
containing slashes. &amp;nbsp;The 3rd example has metric names with mixed
uppercase and lowercase. &amp;nbsp;Although the decode.gearman module does some
basic metric name sanitation, it's perfectly possible to write a
Wishbone module and plug it into your MetricFactory chain to convert the
metric names into whatever your like but covering that topic is out of
scope of this article. To get an idea how our data looks like after each
module we're going to alter the &lt;em&gt;routing table&lt;/em&gt; in the bootstrap file
accordingly. &amp;nbsp;If you take look at our bootstrap file, you notice we have
an additional module initiated called &lt;em&gt;stdout&lt;/em&gt; (line&amp;nbsp;48) which is not
included in our &lt;em&gt;routing table&lt;/em&gt;. &amp;nbsp;The&amp;nbsp;&lt;em&gt;stdout&lt;/em&gt; module prints, as you
might guess, incoming events to STDOUT. &amp;nbsp;Let's go over each step to see
how our data looks like:&lt;/p&gt;
&lt;div class="section" id="data-coming-from-wishbone-iomodule-gearmand"&gt;
&lt;h3&gt;Data coming from wishbone.iomodule.Gearmand&lt;/h3&gt;
&lt;p&gt;To print the data coming from Mod_Gearman to STDOUT we change our
routing table to the following:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
&amp;quot;routingtable&amp;quot;: {
    &amp;quot;modgearman.inbox&amp;quot;: [ &amp;quot;stdout.inbox&amp;quot; ]
  }
&lt;/pre&gt;
&lt;p&gt;Start Metricfactory in the foreground (&lt;a class="reference external" href="http://ascii.io/a/3120"&gt;ascii.io
screencast&lt;/a&gt;):&lt;/p&gt;
&lt;pre class="literal-block"&gt;
$ metricfactory debug --config modgearmand2graphite.json --loglevel debug
&lt;/pre&gt;
&lt;p&gt;Example host performance data:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
DATATYPE::HOSTPERFDATA TIMET::1368178733   HOSTNAME::host_339  HOSTPERFDATA::rta=0.091ms;3000.000;5000.000;0; pl=0%;80;100;;   HOSTCHECKCOMMAND::check:host.alive!(null)   HOSTSTATE::0    HOSTSTATETYPE::1
&lt;/pre&gt;
&lt;p&gt;Example service performance data:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
DATATYPE::SERVICEPERFDATA  TIMET::1368178797   HOSTNAME::localhost SERVICEDESC::Gearman Queues SERVICEPERFDATA::'check_results_waiting'=0;10;100;0 'check_results_running'=0 'check_results_worker'=1;25;50;0 'host_waiting'=0;10;100;0 'host_running'=0 'host_worker'=10;25;50;0 'hostgroup_localhost_waiting'=0;10;100;0 'hostgroup_localhost_running'=1 'hostgroup_localhost_worker'=10;25;50;0 'perfdata_waiting'=0;10;100;0 'perfdata_running'=0 'perfdata_worker'=1;25;50;0 'service_waiting'=0;10;100;0 'service_running'=0 'service_worker'=10;25;50;0 'worker_nagios-001_waiting'=0;10;100;0 'worker_nagios-001_running'=0 'worker_nagios-001_worker'=1;25;50;0   SERVICECHECKCOMMAND::check:app.gearman.master   SERVICESTATE::0 SERVICESTATETYPE::1
&lt;/pre&gt;
&lt;/div&gt;
&lt;div class="section" id="data-coming-from-metricfactory-decoder-modgearman"&gt;
&lt;h3&gt;Data coming from metricfactory.decoder.ModGearman&lt;/h3&gt;
&lt;p&gt;So the data coming from Mod_Gearman needs to be converted into the
common Metricfactory internal format. &amp;nbsp;For this we use a module from the
metricfactory.decoder group, in this case ModGearman.&lt;/p&gt;
&lt;p&gt;Change the routing table to following configuration:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
&amp;quot;routingtable&amp;quot;: {
    &amp;quot;modgearman.inbox&amp;quot;: [ &amp;quot;decodemodgearman.inbox&amp;quot; ],
    &amp;quot;decodemodgearman.outbox&amp;quot;: [ &amp;quot;stdout.inbox&amp;quot; ]
}
&lt;/pre&gt;
&lt;p&gt;Start Metricfactory in the foreground (&lt;a class="reference external" href="http://ascii.io/a/3121"&gt;ascii.io
screencast&lt;/a&gt;):&lt;/p&gt;
&lt;pre class="literal-block"&gt;
$ metricfactory debug --config modgearmand2graphite.json --loglevel debug
&lt;/pre&gt;
&lt;p&gt;Example host perfdata:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
{'name': 'rta', 'tags': ['check:host_alive!(null)', 'hostcheck'], 'value': '0.155', 'source': 'host_409', 'time': '1368179085', 'units': 'ms', 'type': 'nagios'}
&lt;/pre&gt;
&lt;p&gt;Example service perfdata:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
{'name': 'perfdata_waiting', 'tags': ['check:app_gearman_master', 'gearman_queues'], 'value': '0', 'source': 'localhost', 'time': '1368179129', 'units': '', 'type': 'nagios'}
&lt;/pre&gt;
&lt;p&gt;The ModGearman decoder module filters out some characters from different
parts&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="data-coming-from-metricfactory-encoder-graphite"&gt;
&lt;h3&gt;Data coming from metricfactory.encoder.Graphite&lt;/h3&gt;
&lt;p&gt;Now we have to convert the metrics from the internal Metricfactory
format into a the Graphite format. &amp;nbsp;The&amp;nbsp;&lt;em&gt;encodegraphite&lt;/em&gt; module has a
parameter&amp;nbsp;&lt;em&gt;prefix&lt;/em&gt; (line 30) which allows you to define a prefix for
the name of each metric to store in Graphite. &amp;nbsp;With this configuration,
each metric will start with &amp;quot;&lt;em&gt;nagios.&lt;/em&gt;&amp;quot;.&lt;/p&gt;
&lt;p&gt;Change the routing table to following configuration:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
&amp;quot;routingtable&amp;quot;: {
    &amp;quot;modgearman.inbox&amp;quot;: [ &amp;quot;decodemodgearman.inbox&amp;quot; ],
    &amp;quot;decodemodgearman.outbox&amp;quot;: [ &amp;quot;encodegraphite.inbox&amp;quot; ],
    &amp;quot;encodegraphite.outbox&amp;quot;: [ &amp;quot;stdout.inbox&amp;quot; ]
  }
&lt;/pre&gt;
&lt;p&gt;Start Metricfactory in the foreground (&lt;a class="reference external" href="http://ascii.io/a/3122"&gt;ascii.io
screencast&lt;/a&gt;):&lt;/p&gt;
&lt;pre class="literal-block"&gt;
$ metricfactory debug --config modgearmand2graphite.json --loglevel debug
&lt;/pre&gt;
&lt;p&gt;Example:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
nagios.host_260.hostcheck.pl 0 1368179289
nagios.host_26.hostcheck.rta 0.133 1368179289
nagios.host_26.hostcheck.pl 0 1368179289
nagios.host_256.hostcheck.rta 0.123 1368179289
nagios.localhost.gearman_queues.service_running 0 1368179329
nagios.localhost.gearman_queues.service_worker 9 1368179329
nagios.localhost.gearman_queues.worker_nagios-001_waiting 0 1368179329
nagios.localhost.gearman_queues.worker_nagios-001_running 0 1368179329
nagios.localhost.gearman_queues.worker_nagios-001_worker 1 136817932
&lt;/pre&gt;
&lt;p&gt;As you can see the Graphite encoder module had to make some assumptions.
&amp;nbsp;In case the metric type is Nagios (the internal format contains this
information) then the hostchecks always have the word&amp;nbsp;&lt;em&gt;hostcheck&lt;/em&gt; in
the metric name as you can see in the above example. &amp;nbsp;When the data is a
Nagios servicecheck, then the service description is included in the
metric name.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="graphite"&gt;
&lt;h2&gt;Graphite&lt;/h2&gt;
&lt;p&gt;Typically Nagios schedules checks every 5 minutes. &amp;nbsp;This doesn't really
result in high resolution metrics and is often used as a point of
critique. &amp;nbsp;Keep this in mind when you define a Graphite retention
policy. &amp;nbsp;In the example configuration we use&amp;nbsp;&lt;em&gt;nagios&lt;/em&gt; as a prefix
(line 30), so you could use a Whisper retention policy similar to:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
[nagios]
priority = 100
pattern = ^nagios\.
retentions = 300:2016
&lt;/pre&gt;
&lt;p&gt;Make sure the Nagios execution interval corresponds properly to
the&amp;nbsp;&lt;em&gt;retentions&lt;/em&gt;&amp;nbsp;parameter to prevent gaps.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="conclusion"&gt;
&lt;h2&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;We have covered how to setup Metricfactory to consume metric data from
ModGearman and submit that to Graphite. &amp;nbsp;We covered in detail how data
changes when traveling through the different modules to get a better
understanding of the whole process.&lt;/p&gt;
&lt;/div&gt;
</summary><category term="monitoringlove"></category><category term="graphite"></category><category term="metricfactory"></category><category term="metrics"></category></entry><entry><title>Testing Graphite with MetricFactory</title><link href="file:///home/smetj/projects/github/smetj.net/output/testing-graphite-with-metricfactory.html" rel="alternate"></link><updated>2013-04-28T22:14:00+02:00</updated><author><name>smetj</name></author><id>tag:file:///home/smetj/projects/github/smetj.net/output,2013-04-28:testing-graphite-with-metricfactory.html</id><summary type="html">&lt;p&gt;Graphite is great. &amp;nbsp;Not only because it's a great piece of software but
also because of the community around it which brings forth all kinds of
metrics goodness. &amp;nbsp;Although it's pretty straightforward to get Graphite
up and running on one node, it gets a bit more complex to get it up and
running in a clustered/sharded/federated mode. &amp;nbsp;I found &lt;a class="reference external" href="http://bitprophet.org/blog/2013/03/07/graphite/"&gt;Jeff
Forcier's Clustering Graphite&lt;/a&gt; and &lt;a class="reference external" href="http://rcrowley.org/articles/federated-graphite.html"&gt;Richard Crowley's Federated
Graphite&lt;/a&gt;&amp;nbsp;to be very helpful. &amp;nbsp;Once you have your clustered Graphite
setup up and running you might want to test its behavior and get
acquainted with its different settings and modules before going to
production. &amp;nbsp;That's where &lt;a class="reference external" href="https://github.com/smetj/metricfactory"&gt;Metricfactory&lt;/a&gt;&amp;nbsp;might help you out.&lt;/p&gt;
&lt;p&gt;Metricfactory is a modular framework based on &lt;a class="reference external" href="https://github.com/smetj/wishbone"&gt;Wishbone&lt;/a&gt; aimed to
quickly assemble servers which process metrics in one way or the other.
&amp;nbsp;So why not use it to generate random metrics and write them to Graphite
in a controlled way? &amp;nbsp;With this article I would like to take you through
a couple of use cases.&lt;/p&gt;
&lt;div class="section" id="installation"&gt;
&lt;h2&gt;Installation&lt;/h2&gt;
&lt;p&gt;Installing metricfactory is a matter of checking out the project from
Git and running the installer. &amp;nbsp;All dependencies should be downloaded
automatically.&lt;/p&gt;
&lt;pre class="literal-block"&gt;
$ git clone https://github.com/smetj/metricfactory
$ cd metricfactory
$ sudo python setup.py install
&lt;/pre&gt;
&lt;p&gt;We will also require some extra &lt;a class="reference external" href="https://github.com/smetj/wishboneModules"&gt;Wishbone modules&lt;/a&gt;:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
$ sudo easy_install wb_tippingbucket
$ sudo easy_install wb_tcpclient
&lt;/pre&gt;
&lt;p&gt;One or more of following packages might be required to successfully
finish the install:&lt;/p&gt;
&lt;blockquote&gt;
gcc, gcc-c++, make, python-devel, Cython&lt;/blockquote&gt;
&lt;p&gt;Once installed you can execute following command:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
$ metricfactory list
&lt;/pre&gt;
&lt;p&gt;That should return a list of all available modules. &amp;nbsp;You should see at
least TCPClient, TippingBucket, Hammer and Graphite.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="bootstrap"&gt;
&lt;h2&gt;Bootstrap&lt;/h2&gt;
&lt;p&gt;Starting Metricfactory requires a bootstrap file. &amp;nbsp;A bootstrap file is a
JSON formatted file containing the configuration of which modules to
initiate and which path events will follow through these module
instances.&lt;/p&gt;
&lt;p&gt;A base bootstrap file you can found &lt;a class="reference external" href="https://github.com/smetj/experiments/blob/master/metricfactory/hammerGraphite/hammer.json"&gt;here&lt;/a&gt;. &amp;nbsp;We will be adapting it to
suit our needs. &amp;nbsp;Going through the content it should give you an idea
what the possibilities are.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="scenario-1-submit-unbuffered-unique-metrics-to-carbon-relay"&gt;
&lt;h2&gt;Scenario 1: Submit unbuffered unique metrics to carbon-relay.&lt;/h2&gt;
&lt;p&gt;Let's say we have 1 carbon-relay instance running which forwards our
metrics to 1 or more carbon instance. &amp;nbsp;We want to verify whether all our
metrics actually arrive. &amp;nbsp;Each metric will be submitted as a separate
TCP connection. &amp;nbsp;This is quite inefficient, we should bundle metrics and
submit them in bulk but for the sake of testing we'll do so.&lt;/p&gt;
&lt;pre class="literal-block"&gt;
{
  &amp;quot;metrics&amp;quot;: {
    &amp;quot;enable&amp;quot;: true,
    &amp;quot;group&amp;quot;: &amp;quot;wishbone.metrics&amp;quot;,
    &amp;quot;interval&amp;quot;: 60,
    &amp;quot;module&amp;quot;: &amp;quot;Log&amp;quot;,
    &amp;quot;variables&amp;quot;: {
    }
  },
  &amp;quot;bootstrap&amp;quot;: {
    &amp;quot;hammer&amp;quot;: {
      &amp;quot;group&amp;quot;: &amp;quot;metricfactory.test&amp;quot;,
      &amp;quot;module&amp;quot;: &amp;quot;Hammer&amp;quot;,
      &amp;quot;variables&amp;quot;: {
        &amp;quot;mode&amp;quot;:&amp;quot;sequential&amp;quot;,
        &amp;quot;total&amp;quot;:0,
        &amp;quot;sleep&amp;quot;:0,
        &amp;quot;host&amp;quot;:100,
        &amp;quot;metric&amp;quot;:100,
        &amp;quot;value&amp;quot;:10000000
      }
    },
    &amp;quot;encodegraphite&amp;quot;: {
      &amp;quot;group&amp;quot;: &amp;quot;metricfactory.encoder&amp;quot;,
      &amp;quot;module&amp;quot;: &amp;quot;Graphite&amp;quot;,
      &amp;quot;variables&amp;quot;: {
        &amp;quot;prefix&amp;quot;:&amp;quot;hammer&amp;quot;
      }
    },
    &amp;quot;buffer&amp;quot;: {
      &amp;quot;group&amp;quot;: &amp;quot;wishbone.module&amp;quot;,
      &amp;quot;module&amp;quot;: &amp;quot;TippingBucket&amp;quot;,
      &amp;quot;variables&amp;quot;: {
        &amp;quot;events&amp;quot;: 100,
        &amp;quot;age&amp;quot;: 10
      }
    },
    &amp;quot;tcpout&amp;quot;: {
      &amp;quot;group&amp;quot;: &amp;quot;wishbone.iomodule&amp;quot;,
      &amp;quot;module&amp;quot;: &amp;quot;TCPClient&amp;quot;,
      &amp;quot;variables&amp;quot;: {
        &amp;quot;pool&amp;quot;: [&amp;quot;graphite-001:2013&amp;quot;]
      }
    }
  },
  &amp;quot;routingtable&amp;quot;: {
    &amp;quot;hammer.inbox&amp;quot;: [ &amp;quot;encodegraphite.inbox&amp;quot; ],
    &amp;quot;encodegraphite.outbox&amp;quot;: [ &amp;quot;tcpout.inbox&amp;quot; ]
  }
}
&lt;/pre&gt;
&lt;p&gt;The hammer module (line 11) is the module which actually generates the
metrics. &amp;nbsp;We initialize the module in sequential mode (line 15). &amp;nbsp;That
means each individual metric is unique in terms of
&lt;em&gt;hostname.metricname&lt;/em&gt;. &amp;nbsp;The amount of metrics to generate is determined
by the host (line 18) and metric (line 19) variables. &amp;nbsp;This means we're
generating 100 unique metrics for 100 different nodes resulting into a
total of 10000 metrics.&lt;/p&gt;
&lt;p&gt;The routing table (line 46) tells us events are travelling through the
modules in following order: hammer -&amp;gt; encodegraphite -&amp;gt; tcpout. &amp;nbsp;The
tcpout module (line 38) submits the metrics over TCP to the destination
defined with the pool variable (line 42).&lt;/p&gt;
&lt;p&gt;The buffer module (line 30) is initialized but not included in our
routing table. &amp;nbsp;That means it's not processing any metrics for the
moment. &amp;nbsp;We will come back to that in one of the following scenarios.&lt;/p&gt;
&lt;p&gt;Start a metricfactory in the foreground using following command:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
$ metricfactory debug --config hammer.json
&lt;/pre&gt;
&lt;p&gt;You can stop metricfactory by pressing CTRL+C.&lt;/p&gt;
&lt;p&gt;With this particular setup metricfactory will create 1 TCP connection
per metric. &amp;nbsp;So it might take a while until all metrics are actually
submitted. &amp;nbsp;Depending on the available resources your mileage may vary.&lt;/p&gt;
&lt;p&gt;&lt;a class="reference external" href="http://smetj.net/2013/04/28/testing-graphite-with-metricfactory/graphite1/"&gt;&lt;img alt="graphite1" src="http://smetj.net/wp-content/uploads/2013/04/graphite1.png" /&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;When reviewing the self generated Graphite metrics we can see we
actually have received 10000 metrics.&lt;/p&gt;
&lt;p&gt;When you have more than one carbon-relay server you can extend the
pool variable (line 42) accordingly.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="scenario-2-submit-buffered-unique-metrics-to-carbon-relay"&gt;
&lt;h2&gt;Scenario 2: Submit buffered unique metrics to carbon-relay.&lt;/h2&gt;
&lt;p&gt;You might want to limit the number of connections by grouping metrics
and submit them in bulk to carbon-relay. &amp;nbsp;We have already initialized
the buffer module (line 30). &amp;nbsp;The only thing left compared to our
previous scenario is to include the buffer module in our &lt;em&gt;routingtable&lt;/em&gt;
section (line 48-49).&lt;/p&gt;
&lt;pre class="literal-block"&gt;
{
  &amp;quot;metrics&amp;quot;: {
    &amp;quot;enable&amp;quot;: true,
    &amp;quot;group&amp;quot;: &amp;quot;wishbone.metrics&amp;quot;,
    &amp;quot;interval&amp;quot;: 60,
    &amp;quot;module&amp;quot;: &amp;quot;Log&amp;quot;,
    &amp;quot;variables&amp;quot;: {
    }
  },
  &amp;quot;bootstrap&amp;quot;: {
    &amp;quot;hammer&amp;quot;: {
      &amp;quot;group&amp;quot;: &amp;quot;metricfactory.test&amp;quot;,
      &amp;quot;module&amp;quot;: &amp;quot;Hammer&amp;quot;,
      &amp;quot;variables&amp;quot;: {
        &amp;quot;mode&amp;quot;:&amp;quot;sequential&amp;quot;,
        &amp;quot;total&amp;quot;:0,
        &amp;quot;sleep&amp;quot;:0,
        &amp;quot;host&amp;quot;:100,
        &amp;quot;metric&amp;quot;:100,
        &amp;quot;value&amp;quot;:10000000
      }
    },
    &amp;quot;encodegraphite&amp;quot;: {
      &amp;quot;group&amp;quot;: &amp;quot;metricfactory.encoder&amp;quot;,
      &amp;quot;module&amp;quot;: &amp;quot;Graphite&amp;quot;,
      &amp;quot;variables&amp;quot;: {
        &amp;quot;prefix&amp;quot;:&amp;quot;hammer&amp;quot;
      }
    },
    &amp;quot;buffer&amp;quot;: {
      &amp;quot;group&amp;quot;: &amp;quot;wishbone.module&amp;quot;,
      &amp;quot;module&amp;quot;: &amp;quot;TippingBucket&amp;quot;,
      &amp;quot;variables&amp;quot;: {
        &amp;quot;events&amp;quot;: 100,
        &amp;quot;age&amp;quot;: 10
      }
    },
    &amp;quot;tcpout&amp;quot;: {
      &amp;quot;group&amp;quot;: &amp;quot;wishbone.iomodule&amp;quot;,
      &amp;quot;module&amp;quot;: &amp;quot;TCPClient&amp;quot;,
      &amp;quot;variables&amp;quot;: {
        &amp;quot;pool&amp;quot;: [&amp;quot;graphite-001:2013&amp;quot;]
      }
    }
  },
  &amp;quot;routingtable&amp;quot;: {
    &amp;quot;hammer.inbox&amp;quot;: [ &amp;quot;encodegraphite.inbox&amp;quot; ],
    &amp;quot;encodegraphite.outbox&amp;quot;: [ &amp;quot;buffer.inbox&amp;quot; ],
    &amp;quot;buffer.outbox&amp;quot;: [ &amp;quot;tcpout.inbox&amp;quot; ]
  }
}
&lt;/pre&gt;
&lt;p&gt;The events variable (line 34) makes the buffer flush when 100 events are
available. &amp;nbsp;The age variable (line 35) make the buffer flush when the
last added metric added is X seconds old. &amp;nbsp;With this scenario we would
only require 10 TCP connections compared to 10000 to submit the same
number of metrics.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="scenario-3-generate-a-constant-stream-of-random-metrics"&gt;
&lt;h2&gt;Scenario 3: Generate a constant stream of random metrics.&lt;/h2&gt;
&lt;p&gt;To generate a continuous stream of random metrics we can set the &lt;em&gt;mode&lt;/em&gt;
variable (line 15) to random. &amp;nbsp;This gives a different meaning to the
host (line 18) and metric (line 19) variables. &amp;nbsp;They now become for each
metric the maximum value of a random integer to choose from starting
from 0. &amp;nbsp;Hostnames will have the format &lt;em&gt;host_1234&lt;/em&gt; and metrics
&lt;em&gt;metric_1234.&lt;/em&gt;&amp;nbsp; Depending upon your specific needs, you might want to
choose a higher value to avoid duplicate values being generated.&lt;/p&gt;
&lt;pre class="literal-block"&gt;
{
  &amp;quot;metrics&amp;quot;: {
    &amp;quot;enable&amp;quot;: true,
    &amp;quot;group&amp;quot;: &amp;quot;wishbone.metrics&amp;quot;,
    &amp;quot;interval&amp;quot;: 60,
    &amp;quot;module&amp;quot;: &amp;quot;Log&amp;quot;,
    &amp;quot;variables&amp;quot;: {
    }
  },
  &amp;quot;bootstrap&amp;quot;: {
    &amp;quot;hammer&amp;quot;: {
      &amp;quot;group&amp;quot;: &amp;quot;metricfactory.test&amp;quot;,
      &amp;quot;module&amp;quot;: &amp;quot;Hammer&amp;quot;,
      &amp;quot;variables&amp;quot;: {
        &amp;quot;mode&amp;quot;:&amp;quot;random&amp;quot;,
        &amp;quot;total&amp;quot;:0,
        &amp;quot;sleep&amp;quot;:0,
        &amp;quot;host&amp;quot;:1000,
        &amp;quot;metric&amp;quot;:1000,
        &amp;quot;value&amp;quot;:10000000
      }
    },
    &amp;quot;encodegraphite&amp;quot;: {
      &amp;quot;group&amp;quot;: &amp;quot;metricfactory.encoder&amp;quot;,
      &amp;quot;module&amp;quot;: &amp;quot;Graphite&amp;quot;,
      &amp;quot;variables&amp;quot;: {
        &amp;quot;prefix&amp;quot;:&amp;quot;hammer&amp;quot;
      }
    },
    &amp;quot;buffer&amp;quot;: {
      &amp;quot;group&amp;quot;: &amp;quot;wishbone.module&amp;quot;,
      &amp;quot;module&amp;quot;: &amp;quot;TippingBucket&amp;quot;,
      &amp;quot;variables&amp;quot;: {
        &amp;quot;events&amp;quot;: 100,
        &amp;quot;age&amp;quot;: 10
      }
    },
    &amp;quot;tcpout&amp;quot;: {
      &amp;quot;group&amp;quot;: &amp;quot;wishbone.iomodule&amp;quot;,
      &amp;quot;module&amp;quot;: &amp;quot;TCPClient&amp;quot;,
      &amp;quot;variables&amp;quot;: {
        &amp;quot;pool&amp;quot;: [&amp;quot;graphite-001:2013&amp;quot;]
      }
    }
  },
  &amp;quot;routingtable&amp;quot;: {
    &amp;quot;hammer.inbox&amp;quot;: [ &amp;quot;encodegraphite.inbox&amp;quot; ],
    &amp;quot;encodegraphite.outbox&amp;quot;: [ &amp;quot;buffer.inbox&amp;quot; ],
    &amp;quot;buffer.outbox&amp;quot;: [ &amp;quot;tcpout.inbox&amp;quot; ]
  }
}
&lt;/pre&gt;
&lt;p&gt;The sleep variable (line 17) determines how much time to wait between
generating each metric. That might be useful when you want to limit CPU
usage or control the interval between metrics. A value of 0 means
Metricfactory will drain your CPU trying to produce as much as possible.
Setting a value of 1 means one metric will be produced every second.
&amp;nbsp;When&amp;nbsp;you notice Metricfactory gradually consumes all memory available
that means data is produced at a higher rate than you can submit to
Graphite. In that case you might want to raise the events variable (line
34) which allows you to submit larger chunks of data per connection.&lt;/p&gt;
&lt;p&gt;&lt;img alt="graphite3" src="http://smetj.net/wp-content/uploads/2013/04/graphite3.png" /&gt;&lt;/p&gt;
&lt;p&gt;&lt;a class="reference external" href="http://smetj.net/2013/04/28/testing-graphite-with-metricfactory/graphite2/"&gt;The difference in Graphite throughput by changing the buffer
events variable (line 34) from 100 to 1000.&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Depending on your settings Metricfactory can generate a significant
amount of metrics. &amp;nbsp;You could even raise that by starting multiple
parallel processes:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
$ metricfactory debug --config hammer.json --instances 4
&lt;/pre&gt;
&lt;p&gt;This will start 4 parallel processes each executing exactly the same.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="conclusion"&gt;
&lt;h2&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;Generating a predictable number of metrics can be practical to verify whether
your Graphite setup behaves as expected under different scenarios. &amp;nbsp;It becomes
more&amp;nbsp;meaningful&amp;nbsp;if you have a more complex environment with a number of
relays, sharding and duplication policies. &amp;nbsp;By generating large batches of
continuous&amp;nbsp;data with different sizing it's possible to get an idea about the
throughput of your Graphite setup.&lt;/p&gt;
&lt;/div&gt;
</summary><category term="monitoringlove"></category><category term="graphite"></category><category term="metricfactory"></category><category term="python"></category></entry><entry><title>Using MetricFactory to get Hadoop metrics into Graphite.</title><link href="file:///home/smetj/projects/github/smetj.net/output/using-metricfactory-to-get-hadoop-metrics-into-graphite.html" rel="alternate"></link><updated>2013-01-10T00:40:00+01:00</updated><author><name>smetj</name></author><id>tag:file:///home/smetj/projects/github/smetj.net/output,2013-01-10:using-metricfactory-to-get-hadoop-metrics-into-graphite.html</id><summary type="html">&lt;p&gt;Without metrics we're flying blind and that's very much the case with
&amp;nbsp;&lt;a class="reference external" href="http://hadoop.apache.org/"&gt;Hadoop&lt;/a&gt;. &amp;nbsp;Hadoop is a well known framework to build reliable,
scalable&amp;nbsp;and distributed computing clusters. &amp;nbsp;The Hadoop framework &amp;nbsp;is a
complex environment which &amp;quot;out of the box&amp;quot; hardly offers any metrics
oversight on how the different components are performing.&lt;/p&gt;
&lt;p&gt;&lt;a class="reference external" href="http://graphite.wikidot.com/"&gt;Graphite&lt;/a&gt;&amp;nbsp;is king of the hill when it comes to graphing metrics with
open source. &amp;nbsp;Hadoop doesn't support Graphite's data format and way to
submit metrics, however it does natively support
the&amp;nbsp;&lt;a class="reference external" href="http://ganglia.sourceforge.net/"&gt;Ganglia&lt;/a&gt;&amp;nbsp;graphing framework. &amp;nbsp;That is something we are going to
use to our advantage.&lt;/p&gt;
&lt;p&gt;&lt;a class="reference external" href="https://github.com/smetj/metricfactory"&gt;MetricFactory&lt;/a&gt;&amp;nbsp;is a modular tool which allows you to build servers
which can do &amp;quot;stuff&amp;quot; with metrics. &amp;nbsp;In this case &amp;quot;stuff&amp;quot; means accepting
Ganglia metrics, convert and submit them to the Graphite framework.&lt;/p&gt;
&lt;p&gt;The information this blog post is just another way of doing things which
might suit your needs better than any other available options.&lt;/p&gt;
&lt;div class="section" id="hadoop-metrics"&gt;
&lt;h2&gt;Hadoop metrics&lt;/h2&gt;
&lt;p&gt;As we already mentioned Hadoop can generate Ganglia formatted metrics.
&amp;nbsp;Hadoop metrics are controlled by
/etc/hadoop/conf/hadoop-metrics.properties&lt;/p&gt;
&lt;p&gt;You should have at least following entries:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
dfs.class=org.apache.hadoop.metrics.ganglia.GangliaContext31
dfs.period=10
dfs.servers=metricfactory-001
&lt;/pre&gt;
&lt;pre class="literal-block"&gt;
mapred.class=org.apache.hadoop.metrics.ganglia.GangliaContext31
mapred.period=10
mapred.servers=metricfactory-001
&lt;/pre&gt;
&lt;pre class="literal-block"&gt;
jvm.class=org.apache.hadoop.metrics.ganglia.GangliaContext31
jvm.period=10
jvm.servers=metricfactory-001
&lt;/pre&gt;
&lt;pre class="literal-block"&gt;
rpc.class=org.apache.hadoop.metrics.ganglia.GangliaContext31
rpc.period=10
rpc.servers=metricfactory-001
&lt;/pre&gt;
&lt;p&gt;The rpc.period defines the interval to submit metrics. &amp;nbsp;In this case 10
seconds.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="graphite"&gt;
&lt;h2&gt;Graphite&lt;/h2&gt;
&lt;p&gt;The Graphite instance does nothing particular. &amp;nbsp;You can consult the
graphs by visiting following URL:
&lt;a class="reference external" href="http://"&gt;http://&lt;/a&gt;&lt;a class="reference external" href="http://graphite-001/dashboard/"&gt;http://graphite-001/dashboard/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a class="reference external" href="http://smetj.net/2013/01/10/using-metricfactory-to-get-hadoop-metrics-into-graphite/screenshot-from-2013-01-07-223750/"&gt;&lt;img alt="Screenshot from 2013-01-07 22:37:50" src="http://smetj.net/wp-content/uploads/2013/01/Screenshot-from-2013-01-07-223750-300x150.png" /&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="metricfactory"&gt;
&lt;h2&gt;MetricFactory&lt;/h2&gt;
&lt;p&gt;MetricFactory's setup is controlled through so called &lt;a class="reference external" href="https://github.com/smetj/experiments/tree/master/metricfactory"&gt;bootstrap
files&lt;/a&gt;. &amp;nbsp;These files contain&amp;nbsp;the information on which modules need to
be loaded, how they are initiated and how &amp;nbsp;they are connected to each
other.&lt;/p&gt;
&lt;p&gt;For this scenario we need to have at least:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;a class="reference external" href="https://github.com/smetj/wishbone/blob/master/wishbone/iomodules/udpserver.py"&gt;UDP input&lt;/a&gt; (The Ganglia metrics come in over UDP).&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="https://github.com/smetj/metricfactory/blob/master/metricfactory/decoders/decodeganglia.py"&gt;Ganglia decoder&lt;/a&gt;&amp;nbsp;(Deserialize the XDR format into a generic
format.)&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="https://github.com/smetj/metricfactory/blob/master/metricfactory/encoders/encodegraphite.py"&gt;Graphite encoder&lt;/a&gt; (Convert the generic format into a Graphite
format.)&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="https://github.com/smetj/wishbone/blob/master/wishbone/iomodules/tcpclient.py"&gt;A TCP client&lt;/a&gt; (Write the metrics into Graphite)&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="section" id="a-small-test"&gt;
&lt;h3&gt;A small test&lt;/h3&gt;
&lt;p&gt;First let's make a small test using &lt;a class="reference external" href="https://github.com/smetj/experiments/blob/master/metricfactory/ganglia2graphite/ganglia2graphite2stdout.json"&gt;this&lt;/a&gt; bootstrapfile. &amp;nbsp;Instead of
writing the converted data to Graphite, we're going to print it to
STDOUT. &amp;nbsp;Not very useful, although this way we can verify clearly
whether we have data coming in and whether the output format is as we
expect.&lt;/p&gt;
&lt;p&gt;We can start &amp;nbsp;MetricFactory with the debug option so it does not detach
into the background. &amp;nbsp;CTRL-C stops the process again:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
[vagrant&amp;#64;metricfactory-001 ~]$ metricfactory debug --config /home/vagrant/experiments/metricfactory/ganglia2graphite/ganglia2graphite2stdout.json
2013-01-07 22:38:06,150 INFO root: Starting MetricFactory in foreground.
2013-01-07 22:38:06,156 INFO root: Instance #0 started.
2013-01-07 22:38:06,158 INFO root: Started with pids: 3702, 3703
2013-01-07 22:38:06,165 INFO Intance #0:buffer: Initiated.
2013-01-07 22:38:06,168 INFO Intance #0:udpserver: started and listening on port 8649
2013-01-07 22:38:06,170 INFO Intance #0:ganglia: Initiated.
2013-01-07 22:38:06,171 INFO Intance #0:graphite: Initiated.
2013-01-07 22:38:06,172 INFO Intance #0:stdout: Initiated.
2013-01-07 22:38:06,174 INFO Intance #0:buffer: Started.
2013-01-07 22:38:06,174 INFO Intance #0:stdout: Started.
2013-01-07 22:38:06,175 INFO Intance #0:ganglia: Started.
2013-01-07 22:38:06,175 INFO Intance #0:graphite: Started.
0 - systems.hadoop-001.jvm.JobTracker.metrics.gcCount 159 1357598286.52
1 - systems.hadoop-001.jvm.JobTracker.metrics.gcTimeMillis 481 1357598286.52
2 - systems.hadoop-001.jvm.JobTracker.metrics.logError 0 1357598286.52
3 - systems.hadoop-001.jvm.JobTracker.metrics.logFatal 0 1357598286.52
4 - systems.hadoop-001.jvm.JobTracker.metrics.logInfo 57 1357598286.52
5 - systems.hadoop-001.jvm.JobTracker.metrics.logWarn 1 1357598286.52
6 - systems.hadoop-001.jvm.JobTracker.metrics.maxMemoryM 3866.6875 1357598286.52
7 - systems.hadoop-001.jvm.JobTracker.metrics.memHeapCommittedM 15.125 1357598286.52
8 - systems.hadoop-001.jvm.JobTracker.metrics.memHeapUsedM 7.0045853 1357598286.52
9 - systems.hadoop-001.jvm.JobTracker.metrics.memNonHeapCommittedM 23.1875 1357598286.52
10 - systems.hadoop-001.jvm.JobTracker.metrics.memNonHeapUsedM 19.089851 1357598286.52
11 - systems.hadoop-001.jvm.JobTracker.metrics.threadsBlocked 0 1357598286.52
12 - systems.hadoop-001.jvm.JobTracker.metrics.threadsNew 0 1357598286.52
... snip ...
&lt;/pre&gt;
&lt;/div&gt;
&lt;div class="section" id="a-standalone-instance"&gt;
&lt;h3&gt;A standalone instance&lt;/h3&gt;
&lt;p&gt;We can now start to write the metrics into Graphite. &amp;nbsp;For this we
require&amp;nbsp;&lt;a class="reference external" href="https://github.com/smetj/experiments/blob/master/metricfactory/ganglia2graphite/ganglia2graphite.json"&gt;a bootstrap file&lt;/a&gt; which &amp;nbsp;actually writes the data into
Graphite:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
[vagrant&amp;#64;metricfactory-001 ~]$ metricfactory debug --config /home/vagrant/experiments/metricfactory/ganglia2graphite/ganglia2graphite.json
&lt;/pre&gt;
&lt;/div&gt;
&lt;div class="section" id="multiple-instances"&gt;
&lt;h3&gt;Multiple instances&lt;/h3&gt;
&lt;p&gt;MetricFactory is build using the Wishbone library, which on its turn
uses Gevent with green threads on top of a libevent loop. &amp;nbsp;Something to
keep in mind when working with greenthreads on a libevent loop is that
they are great to deal with IO bound processing but not with CPU bound
processing. &amp;nbsp;Because of that (cutting corners here) our whole setup runs
inside 1 process which doesn't take advantage of a multiple CPU
architecture. &amp;nbsp;This can become problematic because every time we're
doing a CPU intensive task, the libevent loop stops, something we want
to avoid as much as possible.&lt;/p&gt;
&lt;p&gt;A WishBone based setup can be started with the --instances parameter,
which basically starts a number of identical processes thus taking
advantage of a multiple CPU architecture. In our case however we can not
take advantage of this since we require an UDP listener in our setup
hence we can't have multiple instances bind to that port at the same
time. &amp;nbsp;So let's get creative and&amp;nbsp;split the setup into 2 parts:&lt;/p&gt;
&lt;div class="section" id="a-decoder-with-multiple-instances"&gt;
&lt;h4&gt;A decoder with multiple instances&lt;/h4&gt;
&lt;p&gt;This setup creates 5 parallel instances. &amp;nbsp;Each instance accepts input
from its own Unix domain socket.&lt;/p&gt;
&lt;pre class="literal-block"&gt;
[vagrant&amp;#64;metricfactory-001 ~]$&amp;nbsp;metricfactory debug --config /home/vagrant/experiments/metricfactory/ganglia2graphite/uds-ganglia-graphite.json --instances 5 --pid /tmp/uds-ganglia-graphite.pid
&lt;/pre&gt;
&lt;/div&gt;
&lt;div class="section" id="a-receiver"&gt;
&lt;h4&gt;A receiver&lt;/h4&gt;
&lt;p&gt;Accepts all the data on UDP and distributes that evenly over multiple
decoders each listening on a domain socket.&lt;/p&gt;
&lt;pre class="literal-block"&gt;
[vagrant&amp;#64;metricfactory-001 ~]$ metricfactory debug --config /home/vagrant/experiments/metricfactory/ganglia2graphite/loadbalance-ganglia.json --pid /tmp/loadbalance-ganglia.pid
&lt;/pre&gt;
&lt;p&gt;&lt;em&gt;`The UDSclient module`_ can be initiated with &amp;quot;pool&amp;quot; set to &amp;quot;True&amp;quot;.When
enabled the defined path will be considered a directory containing one
or more Unix domain sockets. The client &amp;quot;round robins&amp;quot; over all domain
sockets found in that directory. Worth to mention is the buffer module,
which buffers the Graphite data and when full submits the batch.&lt;/em&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="conclusion"&gt;
&lt;h2&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;Using this setup we can accept Ganglia metrics over UDP from Hadoop,
convert using multiple parallel processes the metrics to Graphite format
in and submit the converted metrics in batches to Graphite. &amp;nbsp;I'm
planning to add more functionality to MetricFactory. &amp;nbsp;Currently it can
tackle mod_gearman and Ganglia data. &amp;nbsp;Using the examples in this
article you should be able to setup your own MetricFactory based setups
relatively easy. &amp;nbsp;If you require support you can submit a message to the
&lt;a class="reference external" href="https://groups.google.com/forum/?fromgroups#!forum/metricfactory"&gt;MetricFactory mailing list&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
</summary></entry><entry><title>After a long hiatus</title><link href="file:///home/smetj/projects/github/smetj.net/output/after-a-long-hiatus.html" rel="alternate"></link><updated>2012-09-30T23:46:00+02:00</updated><author><name>smetj</name></author><id>tag:file:///home/smetj/projects/github/smetj.net/output,2012-09-30:after-a-long-hiatus.html</id><summary type="html">&lt;p&gt;Finally after finishing a whole bunch of private &amp;quot;projects&amp;quot;, I'm able to
spend some more time again to the &lt;a class="reference external" href="https://github.com/smetj"&gt;various open source projects&lt;/a&gt; I've
been working on until now. &amp;nbsp;I have gathered a whole bunch of new ideas,
processed good and bad feedback, experienced that some ideas just don't
work out while others are quite encouraging.&lt;/p&gt;
&lt;p&gt;I haven't been totally unproductive though. &amp;nbsp;I have been able to spend
time writing the Python&amp;nbsp;&lt;a class="reference external" href="https://github.com/smetj/wishbone"&gt;Wishbone&lt;/a&gt;&amp;nbsp;library. &amp;nbsp;The Wishbone library is
a lightweight way of writing multiple gevent based parallel processes
which connect multiple modules through an internal message passing
interface into a clean workflow.&lt;/p&gt;
&lt;p&gt;I have also created &lt;a class="reference external" href="https://github.com/smetj/monfs"&gt;MonFS&lt;/a&gt;&amp;nbsp;which is a Fuse filesystem plugin allowing
you to store your Nagios (or compatible) configuration into a MongoDB
and mount that database as a read-only filesystem containing Nagios
configuration files.&lt;/p&gt;
&lt;p&gt;The projects which currently gets most attention is &lt;a class="reference external" href="https://github.com/smetj/molog/tree/wishbone_based"&gt;MoLog&lt;/a&gt;. &amp;nbsp;The
latest development which is a complete rewrite, is currently sitting in
the &lt;em&gt;molog_based&lt;/em&gt; branch. &amp;nbsp;I've split MoLog into 3 &amp;nbsp;parts: &amp;nbsp;The main
engine, a RESTful API and a CLI. &amp;nbsp;The main engine has been
rewritten&amp;nbsp;using the Wishbone and it seems to work reasonably fast even
without doing any optimization and without doing any profiling to
identify existing hot spots.&lt;/p&gt;
&lt;p&gt;It's time to roll up the sleeves and start to do some&amp;nbsp;useful&amp;nbsp;tinkering
and coding again.&lt;/p&gt;
</summary><category term="molog"></category><category term="monitoring"></category></entry><entry><title>Working with Moncli part2: Creating a simple request</title><link href="file:///home/smetj/projects/github/smetj.net/output/working-with-moncli-part2-creating-a-simple-request.html" rel="alternate"></link><updated>2012-03-11T22:12:00+01:00</updated><author><name>smetj</name></author><id>tag:file:///home/smetj/projects/github/smetj.net/output,2012-03-11:working-with-moncli-part2-creating-a-simple-request.html</id><summary type="html">&lt;p&gt;In our &lt;a class="reference external" href="http://smetj.net/2012/03/06/working-with-moncli-part1-creating-a-plugin/"&gt;previous post&lt;/a&gt;&amp;nbsp;we have covered how to &amp;nbsp;create an example plugin
which allows you to generate the size of directories as a metric. &amp;nbsp;A
plugin on itself doesn't do that much at all. &amp;nbsp;When a plugin is executed
it returns the values of that very moment. &amp;nbsp;Executing a plugin is done
by Moncli itself and we want to have control over that as much as
possible.&lt;/p&gt;
&lt;div class="section" id="moncli-request"&gt;
&lt;h2&gt;moncli_request&lt;/h2&gt;
&lt;p&gt;&lt;a class="reference external" href="http://wiki.smetj.net/wiki/Moncli_documentation#Request"&gt;A request is a JSON document&lt;/a&gt; which is submitted to the messagebroker
on which the Moncli clients are listening for incoming requests.
&amp;nbsp;Creating and submitting a request could be done&amp;nbsp;by hand, but that's not
pratical at all. &amp;nbsp;&lt;a class="reference external" href="https://github.com/smetj/moncli_request"&gt;Moncli_request&lt;/a&gt;&amp;nbsp;is a simple request generator tool
which generates and submits a valid JSON document to Moncli to work
with. &amp;nbsp;Let's generate a request for our dir_size plugin we created in
the previous article. &amp;nbsp;Moncli_request takes a base JSON document and
completes &amp;nbsp;it with the parameters you feed to it. &amp;nbsp;So let run through
the required steps:&lt;/p&gt;
&lt;ol class="arabic"&gt;
&lt;li&gt;&lt;p class="first"&gt;Install moncli_request from git:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
$ git clone https://smetj&amp;#64;github.com/smetj/moncli_request.git /opt/moncli_request
&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;Copy the skeleton base document over to a new default check called
DirSize:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
$ cp /opt/moncli_request/repository/skeleton /opt/moncli_request/repository/.default/DirSize
&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;Complete our newly created DirSize base document with the plugin name
and hash:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
{
 &amp;quot;plugin&amp;quot;:{
 &amp;quot;name&amp;quot;:&amp;quot;dir_size&amp;quot;,
 &amp;quot;hash&amp;quot;:&amp;quot;a1161fc0d2dfcd6b4e9f52651e88a1d0&amp;quot;,
 &amp;quot;timeout&amp;quot;:60
 },
 &amp;quot;report&amp;quot;:{
 &amp;quot;message&amp;quot;:&amp;quot;&amp;quot;
 },
 &amp;quot;request&amp;quot;:{
 &amp;quot;cycle&amp;quot;:60
 },
 &amp;quot;evaluators&amp;quot;:{
 },
 &amp;quot;tags&amp;quot;:[]
}
&lt;/pre&gt;
&lt;p&gt;The name is the name of the plugin we created in the previous post
and stored in Moncli's local repository. &amp;nbsp;This actually corresponds
to the directory name containing the plugin. &amp;nbsp;The hash is the md5sum
of the plugin. &amp;nbsp;Parameters is a list of parameters we want to feed to
the script.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;Now execute moncli_request without the --broker parameter. &amp;nbsp;This
will print the request which you can submit to Moncli through the
message broker on STDOUT:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
$ /opt/moncli_request/moncli_request --host indigo --subject 'DirSize' --parameters [\&amp;quot;\'/tmp/test/*\'\&amp;quot;]
{&amp;quot;request&amp;quot;:{&amp;quot;source&amp;quot;:&amp;quot;indigo&amp;quot;,&amp;quot;month&amp;quot;:3,&amp;quot;week_of_year&amp;quot;:10,&amp;quot;time&amp;quot;:&amp;quot;2012-03-11T19:58:54+01:00&amp;quot;,&amp;quot;day_of_year&amp;quot;:71,&amp;quot;uuid&amp;quot;:&amp;quot;DDB2AFC8-6BA3-11E1-B62D-8DA2DAFBAEBF&amp;quot;,&amp;quot;day&amp;quot;:11,&amp;quot;day_of_week&amp;quot;:7,&amp;quot;cycle&amp;quot;:60,&amp;quot;year&amp;quot;:2012},&amp;quot;plugin&amp;quot;:{&amp;quot;parameters&amp;quot;:[&amp;quot;'/tmp/test/*'&amp;quot;],&amp;quot;hash&amp;quot;:&amp;quot;a1161fc0d2dfcd6b4e9f52651e88a1d0&amp;quot;,&amp;quot;timeout&amp;quot;:60,&amp;quot;name&amp;quot;:&amp;quot;dir_size&amp;quot;},&amp;quot;report&amp;quot;:{&amp;quot;message&amp;quot;:&amp;quot;&amp;quot;},&amp;quot;destination&amp;quot;:{&amp;quot;subject&amp;quot;:&amp;quot;DirSize&amp;quot;,&amp;quot;name&amp;quot;:&amp;quot;indigo&amp;quot;},&amp;quot;evaluators&amp;quot;:{},&amp;quot;tags&amp;quot;:[]}
&lt;/pre&gt;
&lt;div&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;After verifying the content we can 'inject' the request into the
message broker on which Moncli is listening:&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;pre class="literal-block"&gt;
$ /opt/moncli_request/moncli_request --broker sandbox --host sandbox --subject 'DirSize' --parameters [\&amp;quot;\'/tmp/test/*\'\&amp;quot;]
A new Report Request (7373E8A2-6B6C-11E1-A438-D193DAFBAEBF) has been submitted.
&lt;/pre&gt;
&lt;p&gt;Keep in mind that the --broker parameter is the address/hostname of your
broker and the --host is the hostname of the host on which Moncli is
started. &amp;nbsp;Each started Moncli instance creates a queue in the broker
with its hostname as the queue name.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="report"&gt;
&lt;h2&gt;Report&lt;/h2&gt;
&lt;p&gt;When we consume the result from the broker (&lt;a class="reference external" href="http://smetj.net/2012/02/11/consuming-moncli-data-from-rabbitmq-using-krolyk/"&gt;see this post&lt;/a&gt;) we get
following result:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
{
   &amp;quot;evaluators&amp;quot;:{

   },
   &amp;quot;tags&amp;quot;:[

   ],
   &amp;quot;destination&amp;quot;:{
      &amp;quot;name&amp;quot;:&amp;quot;indigo&amp;quot;,
      &amp;quot;subject&amp;quot;:&amp;quot;DirSize&amp;quot;
   },
   &amp;quot;request&amp;quot;:{
      &amp;quot;uuid&amp;quot;:&amp;quot;3FF36DE4-6BA4-11E1-8B44-B4A2DAFBAEBF&amp;quot;,
      &amp;quot;year&amp;quot;:2012,
      &amp;quot;day_of_year&amp;quot;:71,
      &amp;quot;day_of_week&amp;quot;:7,
      &amp;quot;month&amp;quot;:3,
      &amp;quot;source&amp;quot;:&amp;quot;indigo&amp;quot;,
      &amp;quot;week_of_year&amp;quot;:10,
      &amp;quot;time&amp;quot;:&amp;quot;2012-03-11T20:01:38+01:00&amp;quot;,
      &amp;quot;day&amp;quot;:11,
      &amp;quot;cycle&amp;quot;:60
   },
   &amp;quot;report&amp;quot;:{
      &amp;quot;month&amp;quot;:3,
      &amp;quot;year&amp;quot;:2012,
      &amp;quot;timezone&amp;quot;:&amp;quot;+0100&amp;quot;,
      &amp;quot;message&amp;quot;:&amp;quot;&amp;quot;,
      &amp;quot;day&amp;quot;:11,
      &amp;quot;uuid&amp;quot;:&amp;quot;35672bb1-2cb8-46ea-8e23-bf5b98cbeaf4&amp;quot;,
      &amp;quot;day_of_year&amp;quot;:71,
      &amp;quot;day_of_week&amp;quot;:0,
      &amp;quot;source&amp;quot;:&amp;quot;indigo&amp;quot;,
      &amp;quot;week_of_year&amp;quot;:10,
      &amp;quot;time&amp;quot;:&amp;quot;2012-03-11T19:02:06+0100&amp;quot;
   },
   &amp;quot;plugin&amp;quot;:{
      &amp;quot;metrics&amp;quot;:{
         &amp;quot;pre_epoch&amp;quot;:1331488926.0,
         &amp;quot;/tmp/test/2&amp;quot;:&amp;quot;24576&amp;quot;,
         &amp;quot;/tmp/test/1&amp;quot;:&amp;quot;24576&amp;quot;,
         &amp;quot;pre_/tmp/test/1&amp;quot;:&amp;quot;24576&amp;quot;,
         &amp;quot;pre_/tmp/test/3&amp;quot;:&amp;quot;24576&amp;quot;,
         &amp;quot;pre_/tmp/test/2&amp;quot;:&amp;quot;24576&amp;quot;,
         &amp;quot;/tmp/test/3&amp;quot;:&amp;quot;24576&amp;quot;,
         &amp;quot;epoch&amp;quot;:1331488926.0
      },
      &amp;quot;raw&amp;quot;:[
         &amp;quot;/tmp/test/1:24576\n&amp;quot;,
         &amp;quot;/tmp/test/2:24576\n&amp;quot;,
         &amp;quot;/tmp/test/3:24576\n&amp;quot;
      ],
      &amp;quot;name&amp;quot;:&amp;quot;dir_size&amp;quot;,
      &amp;quot;verbose&amp;quot;:[

      ]
   }
}
&lt;/pre&gt;
&lt;/div&gt;
&lt;div class="section" id="conclusion"&gt;
&lt;h2&gt;Conclusion:&lt;/h2&gt;
&lt;p&gt;We have seen how to create a plugin and how to generate a request for
it. &amp;nbsp;We let Moncli execute the plugin by generating and submitting a
request with moncli_request and we have verified the incoming results.
&amp;nbsp;In this request we haven't done any evaluations which is something we
will cover in the next article in this series.&lt;/p&gt;
&lt;/div&gt;
</summary><category term="moncli"></category><category term="monitoringlove"></category></entry><entry><title>Moncli 0.2.5</title><link href="file:///home/smetj/projects/github/smetj.net/output/moncli-0-2-5.html" rel="alternate"></link><updated>2012-03-11T22:07:00+01:00</updated><author><name>smetj</name></author><id>tag:file:///home/smetj/projects/github/smetj.net/output,2012-03-11:moncli-0-2-5.html</id><summary type="html">&lt;p&gt;A new version of Moncli is released:&lt;/p&gt;
&lt;p&gt;&lt;a class="reference external" href="http://bit.ly/zE7XeN"&gt;Version 0.2.5&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;This release fixes 1 important bug and introduces a new feature:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Fixed bug which resulted in a growing number of never closing Moncli
processes.&lt;/li&gt;
&lt;li&gt;Writing to a logfile is replaced by writing to syslog only.&lt;/li&gt;
&lt;/ul&gt;
&lt;div&gt;&lt;p&gt;It is advised to upgrade to this version.&lt;/p&gt;
&lt;/div&gt;&lt;p&gt;For support please post a message to the&amp;nbsp;&lt;a class="reference external" href="https://groups.google.com/forum/?fromgroups#!forum/moncli"&gt;mailing list&lt;/a&gt;&amp;nbsp;or submit
a&amp;nbsp;&lt;a class="reference external" href="https://github.com/smetj/moncli/issues"&gt;bug report&lt;/a&gt;.&lt;/p&gt;
</summary><category term="moncli"></category></entry><entry><title>Working with Moncli part1: Creating a plugin</title><link href="file:///home/smetj/projects/github/smetj.net/output/working-with-moncli-part1-creating-a-plugin.html" rel="alternate"></link><updated>2012-03-06T23:25:00+01:00</updated><author><name>smetj</name></author><id>tag:file:///home/smetj/projects/github/smetj.net/output,2012-03-06:working-with-moncli-part1-creating-a-plugin.html</id><summary type="html">&lt;div class="section" id="producing-data"&gt;
&lt;h2&gt;Producing data&lt;/h2&gt;
&lt;p&gt;In the previous 2 posts we had an &lt;a class="reference external" href="http://smetj.net/2012/02/09/moncli-an-introduction/"&gt;introduction about Moncli&lt;/a&gt; and we
have seen how to&amp;nbsp;&lt;a class="reference external" href="http://smetj.net/2012/02/11/consuming-moncli-data-from-rabbitmq-using-krolyk/"&gt;consume Moncli data (reports) from the Message
broker with Krolyk&lt;/a&gt;&amp;nbsp;and process them. &amp;nbsp;Now its time to let Moncli
generate some data we can work with. &amp;nbsp;In the next couple of articles we
will go through the process of building a new plugin and use it to
generate metrics and perform different kind of evaluations.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="creating-a-simple-plugin"&gt;
&lt;h2&gt;Creating a simple plugin&lt;/h2&gt;
&lt;p&gt;One of the goals for Moncli was to create a framework which allows
people to easily create their own plugins. &amp;nbsp;Although Moncli already
comes with a &lt;a class="reference external" href="https://github.com/smetj/moncli/tree/master/lib/repository"&gt;set of plugins&lt;/a&gt; which provide basic system metrics they
will not cover all your needs, so we'll create one as an example.&lt;/p&gt;
&lt;p&gt;Let's say we want to measure and evaluate the disk space one or more
directories consume. &amp;nbsp;For this I create a small Bash/Perl oneliner which
looks like this:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
#!/bin/bash
du -s -b $1\|perl -n -e '/(\\d\*)\\s\*(.\*)/ &amp;amp;&amp;amp; print &amp;quot;$2:$1\\n&amp;quot;'
&lt;/pre&gt;
&lt;p&gt;This script accepts 1 parameter which is the directory of which we want
to process the content.&lt;/p&gt;
&lt;pre class="literal-block"&gt;
jelle&amp;#64;indigo:~$ ./dir_size.sh '/tmp/test/*'
/tmp/test/one:155656192
/tmp/test/three:4096
/tmp/test/two:583471104
jelle&amp;#64;indigo:~$
&lt;/pre&gt;
&lt;p&gt;Now we have to make sure Moncli can execute this new plugin. &amp;nbsp;The name
of the plugin is dir_size, so first we will make a new directory in the
&lt;a class="reference external" href="http://wiki.smetj.net/wiki/Moncli_documentation#local_repo"&gt;Moncli's repository directory&lt;/a&gt; which contains all plugins. &amp;nbsp;The name
of the directory is the name of our script:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
jelle&amp;#64;indigo:~$ mkdir /opt/moncli/lib/repository/dir_size
&lt;/pre&gt;
&lt;p&gt;Then we rename our script to the value of its md5sum and move it to the
directory we just created:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
jelle&amp;#64;indigo:~$ md5sum dir_size.sh
a1161fc0d2dfcd6b4e9f52651e88a1d0 dir_size.sh
jelle&amp;#64;indigo:~$ mv dir_size.sh /opt/moncli/lib/repository/dir_size/a1161fc0d2dfcd6b4e9f52651e88a1d0
jelle&amp;#64;indigo:~$
&lt;/pre&gt;
&lt;/div&gt;
&lt;div class="section" id="security"&gt;
&lt;h2&gt;Security&lt;/h2&gt;
&lt;p&gt;The reason why we store the script as its md5sum is for both security as
practical reasons. &amp;nbsp;Moncli knows which script to execute because it has
the name of the directory. &amp;nbsp;The request submitted to Moncli contains
besides the name of the plugin also the md5sum of the version to
execute. &amp;nbsp;If somebody changes the content of the script, then Moncli
will not execute it, because before executing the script Moncli looks
whether the filename of the script matches its hash. &amp;nbsp;Somebody could add
a new version of the script inside the directory with the correct hash,
but then you must define that hash in your request. &amp;nbsp;In other words, you
can have multiple versions of the plugin inside the directory.&lt;/p&gt;
&lt;p&gt;Our script is now ready to be used.&lt;/p&gt;
&lt;p&gt;In part2 we will cover how to generate a request so we can test and use
our newly created plugin.&lt;/p&gt;
&lt;/div&gt;
</summary><category term="monitoringlove"></category><category term="moncli"></category></entry><entry><title>Moncli 0.2.4</title><link href="file:///home/smetj/projects/github/smetj.net/output/moncli-0-2-4.html" rel="alternate"></link><updated>2012-03-05T18:28:00+01:00</updated><author><name>smetj</name></author><id>tag:file:///home/smetj/projects/github/smetj.net/output,2012-03-05:moncli-0-2-4.html</id><summary type="html">&lt;p&gt;A new version of Moncli is released:&lt;/p&gt;
&lt;p&gt;This release immediately follows&amp;nbsp;the 0.2.3 release to fix 2 issues which
got unnoticed during &amp;nbsp;that release:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;a class="reference external" href="https://github.com/smetj/moncli/issues/2"&gt;Moncli doesn't submit valid json data to the broker.&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="https://github.com/smetj/moncli/issues/3"&gt;traceback module not loaded&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Both issues have been tackled.&lt;/p&gt;
&lt;p&gt;For support please post a message to the &lt;a class="reference external" href="https://groups.google.com/forum/?fromgroups#!forum/moncli"&gt;mailing list&lt;/a&gt;&amp;nbsp;or submit a
&lt;a class="reference external" href="https://github.com/smetj/moncli/issues"&gt;bug report&lt;/a&gt;.&lt;/p&gt;
</summary><category term="moncli"></category><category term="release"></category></entry><entry><title>Moncli - An introduction</title><link href="file:///home/smetj/projects/github/smetj.net/output/moncli-an-introduction.html" rel="alternate"></link><updated>2012-02-09T00:20:00+01:00</updated><author><name>smetj</name></author><id>tag:file:///home/smetj/projects/github/smetj.net/output,2012-02-09:moncli-an-introduction.html</id><summary type="html">&lt;p&gt;&lt;a class="reference external" href="http://smetj.net/2012/02/09/moncli-an-introduction/moncli_architecture_1-2/"&gt;&lt;img alt="image0" src="http://smetj.net/wp-content/uploads/2012/02/Moncli_architecture_11-300x231.jpg" /&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;One of the classic tasks one has to deal with when working with a
monitoring framework is have the ability to retrieve metrics from an OS
or server which aren't available just like that over the network. There
are plenty of different techniques and a multitude of clients available
which offer this functionality. &amp;nbsp;Covering them falls out of the scope of
this post.&lt;/p&gt;
&lt;div class="section" id="so-why-another-monitoring-client"&gt;
&lt;h2&gt;So why another Monitoring Client?&lt;/h2&gt;
&lt;p&gt;When running into scalability problems with my Nagios setup, I realized
that the reason for this is the fact that Nagios always has to take the
initiative to poll a client. &amp;nbsp;This is in Nagios terminology called an
active check. &amp;nbsp;It's of course normal that a client receives instructions
on what it needs to do like which plugin to execute or which thresholds
to evaluate. &amp;nbsp;However, if you think about it, why do we have to repeat
the same question over and over again while in essence nothing has ever
changed between the current and the previous request? Isn't it normal we
ask a question once and say report back at this interval and carry on
until further notice?&lt;/p&gt;
&lt;p&gt;So why not offloading all (or most of) the scheduling effort a central
monitoring system has to perform to the monitoring clients running on
your hosts?&lt;/p&gt;
&lt;p&gt;If you would take it further, you could turn each of my monitoring
clients into an &amp;quot;independent miniature monitoring engine&amp;quot;. &amp;nbsp;This way you
could shift the load from a central system to the collective of clients
in the network. &amp;nbsp;This basically results in horizontal scalability and a
decentralized setup.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="requirements"&gt;
&lt;h2&gt;Requirements&lt;/h2&gt;
&lt;div class="section" id="open-and-rich-data-format"&gt;
&lt;h3&gt;Open and rich data format&lt;/h3&gt;
&lt;p&gt;All in- and outgoing communication should be done in an clear and open
data format, which offers the flexibility to transform it into any
other&amp;nbsp;desirable format which allows you to integrate the client with an
existing&amp;nbsp;platform but which in its turn also allows you to move away
from it. &amp;nbsp;All &lt;a class="reference external" href="http://wiki.smetj.net/wiki/Moncli_documentation#Request"&gt;incoming&lt;/a&gt;&amp;nbsp;to and &lt;a class="reference external" href="http://wiki.smetj.net/wiki/Moncli_documentation#Reports"&gt;outgoing&lt;/a&gt;&amp;nbsp;data from Moncli is in JSON
format. This makes sure that Moncli data is manipulated easily.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="scheduling"&gt;
&lt;h3&gt;Scheduling&lt;/h3&gt;
&lt;p&gt;As said, the client needs to be able to schedule a request at an
&lt;a class="reference external" href="http://wiki.smetj.net/wiki/Moncli_documentation#cycle"&gt;interval of choice&lt;/a&gt;. When the client restarts, it should remember its
scheduled requests and carry on from the moment it's alive again. Moncli
has a build in scheduler which &lt;a class="reference external" href="http://wiki.smetj.net/wiki/Moncli_documentation#cache"&gt;writes its schedule to disk&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="flexible-messaging"&gt;
&lt;h3&gt;Flexible messaging.&lt;/h3&gt;
&lt;p&gt;Since Moncli has its own scheduler, it has to submit the check results
somehow in a trustworthy way without actually having to care much about
who consumes the data when and where. Moncli submits check results into
the &lt;a class="reference external" href="http://www.rabbitmq.com/"&gt;RabbitMQ&lt;/a&gt; message broker, which offers a great deal of
flexibility.&lt;/p&gt;
&lt;p&gt;Moncli &lt;a class="reference external" href="http://wiki.smetj.net/wiki/Moncli_documentation#Communication"&gt;listens&lt;/a&gt; on the message broker infrastructure for incoming
requests. Each Moncli client registers a queue using its FQDN as a name
on the message broker infrastructure from where it receives the requests
it should execute.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="simple-manageable-but-safe-plugin-design"&gt;
&lt;h3&gt;Simple, manageable but safe plugin design&lt;/h3&gt;
&lt;p&gt;Metrics have to come from somewhere. When Moncli executes a request, it
actually executes a locally stored plugin. &lt;a class="reference external" href="http://wiki.smetj.net/wiki/Moncli_documentation#Plugins"&gt;All this plugin needs to do
is create a list of key/value pairs&lt;/a&gt;. This significantly lowers the
difficulty and time required to create new plugins which also allows
less experienced people to write plugins. Moncli will only execute
&lt;a class="reference external" href="http://wiki.smetj.net/wiki/Moncli_documentation#local_repo"&gt;locally stored plugins&lt;/a&gt; which have a hash which matches the one in the
request. When a plugin with such a hash isn't found locally, it will try
to download an update or new version from &lt;a class="reference external" href="http://wiki.smetj.net/wiki/Moncli_documentation#remote_repo"&gt;a central location&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="evaluation-of-metrics"&gt;
&lt;h3&gt;Evaluation of metrics&lt;/h3&gt;
&lt;p&gt;Nagios plugins require you to build in the evaluation of thresholds in
them by feeding the plugin the warning and critical values. &amp;nbsp;Moncli also
performs the evaluation of metrics on the client side but takes another
approach. &amp;nbsp;Instead of doing threshold evaluation in the plugin, Moncli
does the evaluation itself, based upon the &lt;a class="reference external" href="http://wiki.smetj.net/wiki/Moncli_documentation#thresholds"&gt;thresholds&lt;/a&gt; one provides in
combination with a an evaluator.&lt;/p&gt;
&lt;p&gt;There are currently 2 &lt;a class="reference external" href="http://wiki.smetj.net/wiki/Moncli_documentation#Evaluator_definitions"&gt;types of evaluators&lt;/a&gt; (more planned):&lt;/p&gt;
&lt;p&gt;Formulas: calculations using the keys/values returned by the plugin.
Regexes: Simple regex matching on the output of a plugin (not key
value pairs)&lt;/p&gt;
&lt;p&gt;It's optional to define evaluators in a request. &amp;nbsp;In this case, Moncli
just becomes a metrics collector.&lt;/p&gt;
&lt;p&gt;A good starting point to figure out what the possibilities of Moncli are
is done by looking through &amp;nbsp;the in- and outgoing data format of Moncli
called &lt;a class="reference external" href="http://wiki.smetj.net/wiki/Moncli_documentation#Request"&gt;requests&lt;/a&gt; and &lt;a class="reference external" href="http://wiki.smetj.net/wiki/Moncli_documentation#Reports"&gt;reports&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;A second post will be about consuming and processing of Moncli data from
RabbitMQ.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
</summary><category term="moncli"></category><category term="monitoringlove"></category><category term="rabbitmq"></category></entry><entry><title>Monitoring and metric collection across teams.</title><link href="file:///home/smetj/projects/github/smetj.net/output/monitoring-and-metrics-collection-across-teams.html" rel="alternate"></link><updated>2012-01-29T17:02:00+01:00</updated><author><name>smetj</name></author><id>tag:file:///home/smetj/projects/github/smetj.net/output,2012-01-29:monitoring-and-metrics-collection-across-teams.html</id><summary type="html">&lt;p&gt;There' s currently a lot of activity going on the monitoring and
metrics collection landscape and I couldn't be more happy about that as
it's on of those things which also keep me busy in a professional way.
When looking at the growth of information, blogs and projects I can see
that I share many of the problems I'm confronted with, with many people
out there.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Day to day operations&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;One of driving forces in my search of solutions has always been about
making sure that whoever uses it does not have to be a rocket scientist
or somebody who is soaked into the subject and aware of all the perils
that come with monitoring and metrics collection in general. &amp;nbsp;I'm not
only talking about who is going to use the application, but also about
the people who are involved in it some way or the other and who have
because of that expectations from it. &amp;nbsp;I find it very important to have
tools in place which can also be maintained and worked on by &amp;quot;mortal
souls&amp;quot; and basically just get things done without too much hassle.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Single point of ...&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Once having a monitoring or metrics collection framework in place in a
company you can see all kinds of people getting&amp;nbsp;enthusiastic about it.
&amp;nbsp;People from different technical teams within your company start to see
the&amp;nbsp;possibilities&amp;nbsp;and the benefits. &amp;nbsp;Networking engineers, business
applications admins, OS engineers, software engineers,... &amp;nbsp;They all want
data into that framework and have it presented and evaluated, which is
great but as they're busy with their own daily operations, they hardly
have the time to deal with the practical side of things, so quite often,
they expect this will be done by the monitoring guy or team.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Free membership&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;One of my rules of thumbs is that as a monitoring solution provider you
will have to make sure that it's trivial for engineers to create their
own data and submit it into the monitoring environment and have it
evaluated. &amp;nbsp;This not only makes sure that you, the monitoring guy, is
not&amp;nbsp;burdened with the endless work of creating all sorts of plugins
which deliver the information they want but it also makes sure they are
more involved in the whole process, so their expectations are on par and
they will feel more involved and responsible for their part, which is
generally a good thing.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;You're not an island&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Bottom line by making sure your tool facilitates participation, does not
only spread the work giving you more time to work on something more
useful, it also makes sure that the people or teams with requirements
are more involved and responsible themselves for what they want, which
is something everybody benefits from in the long run.&lt;/p&gt;
</summary><category term="company"></category><category term="monitoring"></category><category term="tools"></category></entry></feed>